{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "479b00c2-af54-49f8-b1bf-c859dc5efa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import openai\n",
    "import os\n",
    "import itertools\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import dspy\n",
    "from dsp.utils import deduplicate\n",
    "from dspy.teleprompt import BootstrapFewShot, LabeledFewShot, BayesianSignatureOptimizer, BootstrapFewShotWithRandomSearch\n",
    "from dspy.evaluate import answer_exact_match, answer_passage_match\n",
    "from dspy.evaluate.evaluate import Evaluate\n",
    "from dsp.utils import deduplicate\n",
    "from dspy.primitives import module\n",
    "\n",
    "from copy import copy\n",
    "import random\n",
    "import json\n",
    "import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4226f-c8b9-4fa0-aabf-2aac0458aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall dspy-ai -y\n",
    "# !pip install git+https://github.com/stanfordnlp/dspy.git\n",
    "# !pip install dspy-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b4356-7567-45e2-aafd-247d4d76f6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70908433-8b09-4845-84c6-40ad5e76872f",
   "metadata": {},
   "source": [
    "# LM and RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279840c5-c30d-4a1b-aa24-59c9458d4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting lm and rm in dspy\n",
    "openai_key = '<api key>'\n",
    "colbert_server = 'http://index.contextual.ai:8893/api/search'\n",
    "\n",
    "lm = dspy.OpenAI(model='gpt-3.5-turbo', api_key=openai_key)\n",
    "rm = dspy.ColBERTv2(url=colbert_server)\n",
    "dspy.settings.configure(lm=lm, rm=rm)\n",
    "\n",
    "# llama = dspy.OllamaLocal(    \n",
    "#     model=\"llama2:latest\", \n",
    "#     stop=['---','Explanation:','<|im_start|>','<|im_end|>'],\n",
    "#     model_type = \"chat\")\n",
    "# rm = dspy.ColBERTv2(url=colbert_server)\n",
    "# dspy.settings.configure(lm=llama, rm=rm)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e9e1e-edd5-4351-923e-cd16c99c58f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ce2a6bf-e54d-4538-83a7-73d6aa1a297c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c56fd-7196-4705-8cff-b8ae975ac01a",
   "metadata": {},
   "source": [
    "## SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924304a8-fdf4-4a5b-978c-db13c3e5b613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example({'question': 'Where was the Muslim Brotherhood founded?', 'answer': 'Ismailiyah, Egypt'}) (input_keys={'question'}),\n",
       " Example({'question': 'How many types of science fiction have been impacted by Tesla?', 'answer': 'several'}) (input_keys={'question'}),\n",
       " Example({'question': \"How man of Grainger Town's 450 buildings are listed?\", 'answer': '244'}) (input_keys={'question'}),\n",
       " Example({'question': 'Where was the new media day event for Super Bowl 50 held?', 'answer': 'SAP Center in San Jose.'}) (input_keys={'question'}),\n",
       " Example({'question': 'How old was Newton during Super Bowl 50?', 'answer': '26'}) (input_keys={'question'}),\n",
       " Example({'question': \"At what university's facility did the Panthers practice?\", 'answer': 'San Jose State'}) (input_keys={'question'}),\n",
       " Example({'question': 'What distinguishes stromal thylakoids?', 'answer': 'are in contact with the stroma'}) (input_keys={'question'}),\n",
       " Example({'question': 'What date were the top two stadium choices for Super Bowl 50 announced?', 'answer': 'October 16, 2012'}) (input_keys={'question'}),\n",
       " Example({'question': \"Before which military campaign did Chagatai publicly dispute Jochi's paternity?\", 'answer': 'invasion of the Khwarezmid Empire'}) (input_keys={'question'}),\n",
       " Example({'question': 'Of what were materials that left little residue thought to contain?', 'answer': 'phlogiston'}) (input_keys={'question'}),\n",
       " Example({'question': 'What three things are needed for construction to take place?', 'answer': 'planning,[citation needed] design, and financing'}) (input_keys={'question'}),\n",
       " Example({'question': 'How much money is being spent on other Super Bowl-related events?', 'answer': '$2 million'}) (input_keys={'question'}),\n",
       " Example({'question': 'What is the nickname for the \"Millennial Northern Hemisphere temperature reconstruction\" graph?', 'answer': 'the \"hockey stick graph\"'}) (input_keys={'question'}),\n",
       " Example({'question': 'At what temperature will oxygen condense?', 'answer': '90.20 K'}) (input_keys={'question'}),\n",
       " Example({'question': 'When was the color crimson adopted at Harvard as official color?', 'answer': '1875'}) (input_keys={'question'}),\n",
       " Example({'question': 'What is the Chinese name for the Yuan dynasty?', 'answer': 'Yuán Cháo'}) (input_keys={'question'}),\n",
       " Example({'question': 'What is the density of all primes compatible with a modulo 9?', 'answer': '1/6'}) (input_keys={'question'}),\n",
       " Example({'question': 'Which year did the price of oil drop to $10 per barrel?', 'answer': '1980s'}) (input_keys={'question'}),\n",
       " Example({'question': 'Which British sculptor whose work include the Queen Victoria memorial in front of Buckingham Palace is included in the V&A collection?', 'answer': 'Thomas Brock'}) (input_keys={'question'}),\n",
       " Example({'question': 'Who backed policies that have solutions that sound good but have poor prospects?', 'answer': 'congresses and presidents'}) (input_keys={'question'})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset download and split\n",
    "def get_squad_split(squad, split=\"validation\"):\n",
    "    data = zip(*[squad[split][field] for field in squad[split].features])\n",
    "    exs = [dspy.Example(question=q, answer=a['text'][0]).with_inputs(\"question\")\n",
    "           for eid, title, context, q, a in data]\n",
    "    return exs\n",
    "    \n",
    "squad = load_dataset(\"squad\")\n",
    "squad_train = get_squad_split(squad, split=\"train\")\n",
    "squad_dev = get_squad_split(squad)\n",
    "dev_exs = random.sample(squad_dev, k=20)\n",
    "dev_exs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "317b91a8-8271-4ba2-aee8-acf04496ac6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many people were estimated by authorities ...</td>\n",
       "      <td>[3,000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Until the Reformation, what was the establishe...</td>\n",
       "      <td>[Roman Catholicism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did the war start up again?</td>\n",
       "      <td>[March 1969]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Buddhist teachings are often full of para...</td>\n",
       "      <td>[Zen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which work did Welch express his belief tha...</td>\n",
       "      <td>[Encyclopaedia of Islam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What type of church is Northwestern University...</td>\n",
       "      <td>[Methodist Episcopal Church]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What air sports event did Brasilia host in 2003?</td>\n",
       "      <td>[the 14th Hang Gliding World Championship]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many single have been sold by American Ido...</td>\n",
       "      <td>[120 million]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do the wrestlers treat the audience?</td>\n",
       "      <td>[The audience is recognized and acknowledged b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In which country is Ephesus?</td>\n",
       "      <td>[Turkey]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What did the mysteries seem to threaten that m...</td>\n",
       "      <td>[morality and unity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How many subordinate divisions did the Nationa...</td>\n",
       "      <td>[three]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How much RAM did the first Maciuntosh board have?</td>\n",
       "      <td>[64 kilobytes (kB)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What states assisting Japan was Thailand a par...</td>\n",
       "      <td>[Axis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>When did the French authorities adopted the pr...</td>\n",
       "      <td>[Since the presidency of François Mitterrand (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What part of the government controls the judic...</td>\n",
       "      <td>[executive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What tool did Hoover use to find bootleggers?</td>\n",
       "      <td>[wiretapping]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How many plays can the offence run without gai...</td>\n",
       "      <td>[three]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>After WWII what was the coming out ceremony re...</td>\n",
       "      <td>[less formal afternoon receptions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Genetic engineering allows what?</td>\n",
       "      <td>[molecular components of the brain to be alter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What did previous religious orders do for a li...</td>\n",
       "      <td>[farms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What did Hayek believe the Chilean government ...</td>\n",
       "      <td>[a liberal government]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>When did the government of Aragon  degree the ...</td>\n",
       "      <td>[2011]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is the maximum amount of players allowed?</td>\n",
       "      <td>[eleven]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What was the name of the conflict between Soma...</td>\n",
       "      <td>[the Ogaden War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What did Agnes Shea give to the Chinese in ret...</td>\n",
       "      <td>[a message stick]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Who was given the grandiose title?</td>\n",
       "      <td>[Sonam Gyatso]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What does the mouth of the Qiantang River form?</td>\n",
       "      <td>[Hangzhou Bay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What expedition found nine meteorites in 1969?</td>\n",
       "      <td>[Japanese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What part of the southern population worked as...</td>\n",
       "      <td>[landless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What does the body interpret from the gene fee...</td>\n",
       "      <td>[time of the day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Which of CBC's channels were required to be re...</td>\n",
       "      <td>[52 to 69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What is Lionel Messi's goal total in all compe...</td>\n",
       "      <td>[474]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Performance of classical music requires profic...</td>\n",
       "      <td>[harmonic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>How many slaves at most were under the command...</td>\n",
       "      <td>[150,000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Who does Ibn Sina's philosophy owe much to?</td>\n",
       "      <td>[al-Farabi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What is intermarriage typically seen as?</td>\n",
       "      <td>[rejection of Judaism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What ethnice groups did the Qing thin made up ...</td>\n",
       "      <td>[Han and non-Han peoples]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>What algae is the ancestor of true plants?</td>\n",
       "      <td>[Charophyta]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>How many species of game fish have hunting sea...</td>\n",
       "      <td>[at least 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>What happens to members who disagree with the ...</td>\n",
       "      <td>[expelled and shunned]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Who shared the first homosexual kiss on EastEn...</td>\n",
       "      <td>[Colin Russell and Guido Smith]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What do French historians commonly call the Ag...</td>\n",
       "      <td>[Siècle des Lumières (Century of Enlightenments)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What is the largest of the cemeteries created ...</td>\n",
       "      <td>[Cimetière parisien de Saint-Ouen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>The salinity of what in the region was long re...</td>\n",
       "      <td>[Soil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Were was the hydraulic crane initially used?</td>\n",
       "      <td>[Tyneside docks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What year did the U.S. go to war, leading to w...</td>\n",
       "      <td>[1917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>What emperors visited Nanjing more than once?</td>\n",
       "      <td>[the Kangxi and Qianlong emperors]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>What types of trees grow near rivers in wester...</td>\n",
       "      <td>[pinyon pines, red cedar (junipers), and ponde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>What does the abbreviated electrical character...</td>\n",
       "      <td>[three numeric digits and a letter]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   How many people were estimated by authorities ...   \n",
       "1   Until the Reformation, what was the establishe...   \n",
       "2                    When did the war start up again?   \n",
       "3   What Buddhist teachings are often full of para...   \n",
       "4   In which work did Welch express his belief tha...   \n",
       "5   What type of church is Northwestern University...   \n",
       "6    What air sports event did Brasilia host in 2003?   \n",
       "7   How many single have been sold by American Ido...   \n",
       "8            How do the wrestlers treat the audience?   \n",
       "9                        In which country is Ephesus?   \n",
       "10  What did the mysteries seem to threaten that m...   \n",
       "11  How many subordinate divisions did the Nationa...   \n",
       "12  How much RAM did the first Maciuntosh board have?   \n",
       "13  What states assisting Japan was Thailand a par...   \n",
       "14  When did the French authorities adopted the pr...   \n",
       "15  What part of the government controls the judic...   \n",
       "16      What tool did Hoover use to find bootleggers?   \n",
       "17  How many plays can the offence run without gai...   \n",
       "18  After WWII what was the coming out ceremony re...   \n",
       "19                   Genetic engineering allows what?   \n",
       "20  What did previous religious orders do for a li...   \n",
       "21  What did Hayek believe the Chilean government ...   \n",
       "22  When did the government of Aragon  degree the ...   \n",
       "23     What is the maximum amount of players allowed?   \n",
       "24  What was the name of the conflict between Soma...   \n",
       "25  What did Agnes Shea give to the Chinese in ret...   \n",
       "26                 Who was given the grandiose title?   \n",
       "27    What does the mouth of the Qiantang River form?   \n",
       "28     What expedition found nine meteorites in 1969?   \n",
       "29  What part of the southern population worked as...   \n",
       "30  What does the body interpret from the gene fee...   \n",
       "31  Which of CBC's channels were required to be re...   \n",
       "32  What is Lionel Messi's goal total in all compe...   \n",
       "33  Performance of classical music requires profic...   \n",
       "34  How many slaves at most were under the command...   \n",
       "35        Who does Ibn Sina's philosophy owe much to?   \n",
       "36           What is intermarriage typically seen as?   \n",
       "37  What ethnice groups did the Qing thin made up ...   \n",
       "38         What algae is the ancestor of true plants?   \n",
       "39  How many species of game fish have hunting sea...   \n",
       "40  What happens to members who disagree with the ...   \n",
       "41  Who shared the first homosexual kiss on EastEn...   \n",
       "42  What do French historians commonly call the Ag...   \n",
       "43  What is the largest of the cemeteries created ...   \n",
       "44  The salinity of what in the region was long re...   \n",
       "45       Were was the hydraulic crane initially used?   \n",
       "46  What year did the U.S. go to war, leading to w...   \n",
       "47      What emperors visited Nanjing more than once?   \n",
       "48  What types of trees grow near rivers in wester...   \n",
       "49  What does the abbreviated electrical character...   \n",
       "\n",
       "                                               answer  \n",
       "0                                             [3,000]  \n",
       "1                                 [Roman Catholicism]  \n",
       "2                                        [March 1969]  \n",
       "3                                               [Zen]  \n",
       "4                            [Encyclopaedia of Islam]  \n",
       "5                        [Methodist Episcopal Church]  \n",
       "6          [the 14th Hang Gliding World Championship]  \n",
       "7                                       [120 million]  \n",
       "8   [The audience is recognized and acknowledged b...  \n",
       "9                                            [Turkey]  \n",
       "10                               [morality and unity]  \n",
       "11                                            [three]  \n",
       "12                                [64 kilobytes (kB)]  \n",
       "13                                             [Axis]  \n",
       "14  [Since the presidency of François Mitterrand (...  \n",
       "15                                        [executive]  \n",
       "16                                      [wiretapping]  \n",
       "17                                            [three]  \n",
       "18                 [less formal afternoon receptions]  \n",
       "19  [molecular components of the brain to be alter...  \n",
       "20                                            [farms]  \n",
       "21                             [a liberal government]  \n",
       "22                                             [2011]  \n",
       "23                                           [eleven]  \n",
       "24                                   [the Ogaden War]  \n",
       "25                                  [a message stick]  \n",
       "26                                     [Sonam Gyatso]  \n",
       "27                                     [Hangzhou Bay]  \n",
       "28                                         [Japanese]  \n",
       "29                                         [landless]  \n",
       "30                                  [time of the day]  \n",
       "31                                         [52 to 69]  \n",
       "32                                              [474]  \n",
       "33                                         [harmonic]  \n",
       "34                                          [150,000]  \n",
       "35                                        [al-Farabi]  \n",
       "36                             [rejection of Judaism]  \n",
       "37                          [Han and non-Han peoples]  \n",
       "38                                       [Charophyta]  \n",
       "39                                      [at least 17]  \n",
       "40                             [expelled and shunned]  \n",
       "41                    [Colin Russell and Guido Smith]  \n",
       "42  [Siècle des Lumières (Century of Enlightenments)]  \n",
       "43                 [Cimetière parisien de Saint-Ouen]  \n",
       "44                                             [Soil]  \n",
       "45                                   [Tyneside docks]  \n",
       "46                                             [1917]  \n",
       "47                 [the Kangxi and Qianlong emperors]  \n",
       "48  [pinyon pines, red cedar (junipers), and ponde...  \n",
       "49                [three numeric digits and a letter]  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squad_train_df = pd.json_normalize(squad['train'])[['question', 'answers.text']]\n",
    "squad_dev_df = squad_train_df.sample(n=50, random_state=1).reset_index(drop=True)\n",
    "squad_dev_df.rename({'answers.text': 'answer'}, axis=1, inplace=True)\n",
    "squad_dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e0862-debf-4da6-8071-18cd85bfab83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e64b157b-972b-45bf-bda8-4226ea2d292f",
   "metadata": {},
   "source": [
    "## HaluEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77b0b002-0b8f-4219-a75d-366bb6d29b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_halueval_split(dataset):\n",
    "    data = zip(*[dataset['data'][field] for field in dataset['data'].features])\n",
    "    exs = [dspy.Example(question=question, answer=right_ans, halu=halu_ans).with_inputs(\"question\")\n",
    "           for knowledge, question, right_ans, halu_ans in data]\n",
    "    return exs\n",
    "\n",
    "halueval_qa = load_dataset('pminervini/HaluEval', 'qa')\n",
    "halu_ds = get_halueval_split(halueval_qa)\n",
    "halu_dev = random.sample(halu_ds, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7600e32-b596-48ee-a38c-6d7eb961643d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'Gary Groth is editor in chief of an American magazine of news and criticism pertaining to comic books, comic strips and graphic novels, as well as co-founder of what?', 'answer': 'Fantagraphics Books', 'halu': 'Gary Groth is also a co-founder of Marvel Comics.'}) (input_keys={'question'})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halu_dev[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7eebc-6949-4b8e-8e15-fea0c6ffca41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd4c82-e763-48f4-b772-2e4364f78837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4878259e-fdbc-438d-81d1-5ea151ffcc1a",
   "metadata": {},
   "source": [
    "# Evalation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac13fe51-326b-479d-9cdd-8ed2d08d7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import answer_exact_match\n",
    "from dspy.evaluate.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9346eece-3005-4011-af80-e5f985a94661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_exact_match(dspy.Example(answer=\"STAGE 2!\"), dspy.Prediction(answer=\"stage 2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da30e416-1f7b-43a3-bfaa-b3b5dfbd8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_evaluater = Evaluate(\n",
    "    devset=dev_exs, # 200 examples\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d9a8638-0c02-4726-a429-36844ce19cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_evaluater = Evaluate(\n",
    "    devset=dev_exs[: 15],\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ee1141e-e445-432c-a794-de11e9aea696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny_evaluater(basic_openqa_model, metric=answer_exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf4ba9-2af0-4aec-8098-e730d0a8ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461418ff-6a66-433a-81d9-f632037b495d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4fe55f-aae4-4cc6-bbdd-32bdd9704f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2af5fb59-70a4-4fab-b07e-e668e1218bcb",
   "metadata": {},
   "source": [
    "## Segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59beb76-9f81-4fa7-8176-41a00a65f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "try:\n",
    "    nltk.download(\"punkt\", quiet=True)\n",
    "except FileExistsError:  # multiprocessing race condition\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b54302f4-2792-4584-a43e-7e2f1a628cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceSplitter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # use NLTK to split a text string into sentences for now\n",
    "    def split_into_sentences(self, text):\n",
    "        return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd70e29-7bb8-4b9b-9cfd-082158dfdf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b8a4f2-21bb-4098-b8c5-49027be6f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Gary Zukav | Gary Zukav Gary Zukav (born October 17, 1942) is an American spiritual teacher and the author of four consecutive New York Times Best Sellers. Gary Zukav was born in Port Arthur, Texas, and spent his early childhood in San Antonio and Houston. His family moved to Pittsburg, Kansas, while he was in fourth grade.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec17ee7-6946-45d8-873b-a8d01880cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gary Zukav | Gary Zukav Gary Zukav (born October 17, 1942) is an American spiritual teacher and the author of four consecutive New York Times Best Sellers.',\n",
       " 'Gary Zukav was born in Port Arthur, Texas, and spent his early childhood in San Antonio and Houston.',\n",
       " 'His family moved to Pittsburg, Kansas, while he was in fourth grade.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = splitter.split_into_sentences(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b219936-ef1a-41bf-89a8-90c573850c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556388b5-ef89-44fd-8d54-fd46d54cb9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fddeb-1b66-4605-8e93-2e58816b3621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db0cf8-5b1c-45df-8014-9bc09605e779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6a450b3-e531-4d0c-b7c1-9b9d1084fdba",
   "metadata": {},
   "source": [
    "### Signatures testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c4ed6e1-2df5-4b17-b731-51c5796993ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singnatures\n",
    "class BasicQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField() #desc=\"often between 1 and 5 words\")\n",
    "\n",
    "# class QASignature(dspy.Signature):\n",
    "#     __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "#     question = dspy.InputField()\n",
    "#     answer = dspy.OutputField(\n",
    "#         desc=\"return mostly in english, short answers (limited to less than 8 words), no conversaztional response, no complete sentence\")\n",
    "\n",
    "# class ContextQASignature(dspy.Signature):\n",
    "#     __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "#     context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "#     question = dspy.InputField()\n",
    "#     answer = dspy.OutputField(\n",
    "#         desc=\"return mostly in english, short answers (limited to less than 8 words), no conversaztional response, no complete sentence\")\n",
    "\n",
    "# MultiHop\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    __doc__ = \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    claim = dspy.InputField()\n",
    "    query = dspy.OutputField(desc = \"A short question uniquely answered by the context.\")\n",
    "\n",
    "class Summarizer(dspy.Signature):\n",
    "    __doc__ = \"\"\"Summarize the main points of the text.\"\"\"\n",
    "    context = dspy.InputField()\n",
    "    summary = dspy.OutputField(desc = \"do not start with 'Context:' or 2'Summary:'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7082ce-a95d-4fc5-b1d9-65b38057b676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d13e1ca-73b8-404e-b346-5b6d3acc0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hawaii and Alaska'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_predictor = dspy.Predict(BasicQASignature)\n",
    "ans = sig_predictor(question=\"Which U.S. states border no U.S. states?\")\n",
    "ans.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0953b5aa-e7f0-46f8-ae96-6715552528c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cot_predictor = dspy.ChainOfThought(\"question -> answer\")\n",
    "cot_predictor = dspy.ChainOfThought(BasicQASignature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "393f8e1b-1765-4aee-aad9-0049bdd924a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    rationale='Answer: The Seat of the Soul received the American Book Award in 1989.',\n",
       "    answer='The Seat of the Soul received the American Book Award in 1989.'\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response = basic_predictor(question=\"Which award did Gary Zukav's first book receive?\")\n",
    "response = cot_predictor(question=\"Which award did Gary Zukav's first book receive?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b3081d7-6f1e-4cf0-9353-35b8ca38d021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: The Seat of the Soul received the American Book Award in 1989.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c03c8fc2-6d6f-4952-83cb-18844411e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# basic_predictor = dspy.ChainOfThought(BasicQASignature)\n",
    "# response = basic_predictor(question=\"Which award did Gary Zukav's first book receive?\")\n",
    "# response.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8320171-3b66-4c86-ab11-491bcb3d78c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7963cd2c-bc63-481f-a687-31bbff07e50d",
   "metadata": {},
   "source": [
    "# RAG pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2446df-34da-460f-9217-3fcc0e457cad",
   "metadata": {},
   "source": [
    "## Pipeline for initial query "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81235d-be4a-427e-82ac-08ed15ea429f",
   "metadata": {},
   "source": [
    "### Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c58360aa-a7c5-49ba-88ec-168d32dab20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc = 'do not repeat the question, only show final answer') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21222a59-6736-4142-8028-ec71c68eb6a8",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d3ef3d12-b5f6-4e25-b77e-4665b9251c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOpenQaRAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(BasicQASignature)\n",
    "        self.split = SentenceSplitter() \n",
    "    \n",
    "    def forward(self, question):\n",
    "        prediction = self.generate_answer(question=question)\n",
    "        response = prediction.answer\n",
    "        claims = self.split.split_into_sentences(response)\n",
    "        return claims\n",
    "\n",
    "# with retrieval\n",
    "class ContextOpenQaRAG(dspy.Module):\n",
    "    def __init__(self, num_passages=1):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.Predict(ContextQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0d68d162-43ad-400b-8aee-e29aaa62edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_openqa_model = BasicOpenQaRAG()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c387bbcd-4bd9-476c-90e2-76acf87d9a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The American Book Award']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims = basic_openqa_model(question=\"Which award did Gary Zukav's first book receive?\")\n",
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7c8014d8-b9c5-48b6-8f82-8372d3be2d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827fcbf7-1972-4c51-8e8e-21fa6014c5d1",
   "metadata": {},
   "source": [
    "## Pipelines for hallucination verification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887a214-97c2-4c2e-ad55-bf4c8c70e887",
   "metadata": {},
   "source": [
    "### Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5d1580dd-9b5e-4f7c-aba4-efc5f0c95a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer if the claim is supported by the context.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    claim = dspy.InputField()\n",
    "    answer = dspy.OutputField(\n",
    "        desc=\"return binary response, yes or no.\")\n",
    "\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    __doc__ = \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    claim = dspy.InputField()\n",
    "    query = dspy.OutputField(desc = \"A short question uniquely answered by the context.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f064455-1e64-4bff-8603-69f71c5046b6",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d67ff200-c82d-47f6-af69-5e5c2812b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaluCheckRAG(dspy.Module):\n",
    "    def __init__(self, num_passages=1):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(ContextQASignature)\n",
    "\n",
    "    def forward(self, claim):\n",
    "        context = self.retrieve(claim).passages\n",
    "        prediction = self.generate_answer(context=context, claim=claim)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "        # return dspy.Prediction(answer=prediction.answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "77be2da2-eed8-44d4-b4d9-e08989980907",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHopRAG(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
    "        super().__init__()\n",
    "        self.generate_question = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = dspy.ChainOfThought(ContextQASignature)\n",
    "        self.max_hops = max_hops\n",
    "    \n",
    "    def forward(self, claim):\n",
    "        context = []\n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_question[hop](context=context, claim=claim).query\n",
    "            passages = self.retrieve(query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        pred = self.generate_answer(context=context, claim=claim)\n",
    "        return dspy.Prediction(context=context, answer=pred.answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "590afcbe-626e-441c-8db7-57903f4ae147",
   "metadata": {},
   "outputs": [],
   "source": [
    "halu_check_model = HaluCheckRAG()\n",
    "multihop_halu_model = MultiHopRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "88262ae9-dcf5-4701-9abb-84aa81609941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=['American Book Awards | for 1984, and were renamed \"National\" in 1987. The American Book Award is also unrelated to the American Booksellers Association (ABA), although that organization maintains a complete list of award winners that is readily available. Since the 1970s that trade group is also unrelated to the National Book Awards, which it established in 1936 and jointly re-established them as book industry awards in 1950. 2016 2017 American Book Awards The 38th Annual American Book Awards were presented October 22, 2017 at the San Francisco Jazz Center. The winners were as follows: For seven years 1980 to 1986, there were two'],\n",
       "    answer='No'\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = halu_check_model(claim=claims[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35d2785e-ed2d-47d3-ad2c-3ecd61b1160e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=['National Book Award for Young People\\'s Literature | the US from December 1 to November 30. The National Book Foundation accepts nominations from publishers until June 15, requires mailing nominated books to the panelists by August 1, and announces five finalists in October. The winner is announced on the day of the final ceremony in November. The award is $10,000 and a bronze sculpture; other finalists get $1000, a medal, and a citation written by the panel. There were 230 books nominated for the 2010 award. Books for \"children\" were first recognized by the National Book Awards in 1969 (publication year 1968). Through 1979 there was a single', 'National Book Award for Poetry | National Book Foundation accepts nominations from publishers until June 15, requires mailing nominated books to the panelists by August 1, and announces five finalists in October. The winner is announced on the day of the final ceremony in November. The award is $10,000 and a bronze sculpture; other finalists get $1000, a medal, and a citation written by the panel. There were 148 nominations for the 2010 award. The winner is listed first followed by the four other finalists (from 1987) or other runners-up. National Book Award for Poetry The National Book Award for Poetry is one of four annual', 'National Book Award | Foundation was established in 1988 to administer and enhance the National Book Awards and \"move beyond [them] into the fields of education and literacy\", primarily by sponsoring public appearances by writers. Its mission is \"to celebrate the best of American literature, to expand its audience, and to enhance the cultural value of good writing in America.\" In 2010, there were 1,115 books nominated for the four award categories, led by the Nonfiction category with 435 nominations. The 2011 ceremony was held on November 16 in New York City. National Book Awards are currently given to one book (author) annually in', 'National Book Award | 1941 and the \"New York Times\" frankly called it \"a sort of consolation prize that the booksellers hope will draw attention to his work\". The winning authors and books were selected by a nationwide poll of booksellers (ABA members); during the 1937/38 cycle, ballots were received from 319 stores, triple the number who voted in the first rendition early in 1936. In a 1941 advertisement, the Booksellers described the \"significance of the awards\" thus: In effect, his ballot says, \"Of all the books of the year these are the three I enjoyed most – \"in two ways\"! I enjoyed reading', 'National Book Award | National Book Award The National Book Awards are a set of annual U.S. literary awards. At the final National Book Awards Ceremony every November, the National Book Foundation presents the National Book Awards and two lifetime achievement awards to authors. The National Book Awards were established in 1936 by the American Booksellers Association, abandoned during World War II, and re-established by three book industry organizations in 1950. Non-U.S. authors and publishers were eligible for the pre-war awards. Now they are presented to U.S. authors for books published in the United States roughly during the award year. The nonprofit National Book', 'National Book Award | process itself needs to be reformed to attract more attention.\" National Book Award The National Book Awards are a set of annual U.S. literary awards. At the final National Book Awards Ceremony every November, the National Book Foundation presents the National Book Awards and two lifetime achievement awards to authors. The National Book Awards were established in 1936 by the American Booksellers Association, abandoned during World War II, and re-established by three book industry organizations in 1950. Non-U.S. authors and publishers were eligible for the pre-war awards. Now they are presented to U.S. authors for books published in the United'],\n",
       "    answer='Yes'\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = multihop_halu_model(claim=claims[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "15df555f-32eb-48be-829b-80780cd6c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(claims, model):\n",
    "    halu = False\n",
    "    for c in claims:\n",
    "        if halu == True:\n",
    "            return True\n",
    "        else:\n",
    "            prediction = model(claim = c)\n",
    "            if prediction.answer == 'No':\n",
    "                halu = True\n",
    "    return halu, prediction.context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "384b093d-315b-4da8-8a4c-e79df6cecaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 'National Book Award | National Book Award The National Book Awards are a set of annual U.S. literary awards. At the final National Book Awards Ceremony every November, the National Book Foundation presents the National Book Awards and two lifetime achievement awards to authors. The National Book Awards were established in 1936 by the American Booksellers Association, abandoned during World War II, and re-established by three book industry organizations in 1950. Non-U.S. authors and publishers were eligible for the pre-war awards. Now they are presented to U.S. authors for books published in the United States roughly during the award year. The nonprofit National Book')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halu_check_model = HaluCheckRAG()\n",
    "multihop_halu_model = MultiHopRAG()\n",
    "\n",
    "verify(claims, halu_check_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a7b6f834-8e80-4d46-89d9-65f3abd27907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many people were estimated by authorities ...</td>\n",
       "      <td>[3,000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Until the Reformation, what was the establishe...</td>\n",
       "      <td>[Roman Catholicism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did the war start up again?</td>\n",
       "      <td>[March 1969]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Buddhist teachings are often full of para...</td>\n",
       "      <td>[Zen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which work did Welch express his belief tha...</td>\n",
       "      <td>[Encyclopaedia of Islam]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                    answer\n",
       "0  How many people were estimated by authorities ...                   [3,000]\n",
       "1  Until the Reformation, what was the establishe...       [Roman Catholicism]\n",
       "2                   When did the war start up again?              [March 1969]\n",
       "3  What Buddhist teachings are often full of para...                     [Zen]\n",
       "4  In which work did Welch express his belief tha...  [Encyclopaedia of Islam]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d18df-ef73-47f9-b13b-b5869af71bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2e7b8a8c-4392-4549-99ec-5c9165ebe832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df):\n",
    "    df['initial_response'] = df['question'].apply(lambda x:basic_openqa_model(question=x))\n",
    "    df['claims'] = df['initial_response'].apply(lambda x:splitter.split_into_sentences(x[0]))\n",
    "    df['hallucination'] = df['claims'].apply(lambda x:verify(x, halu_check_model)[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90e3ac9e-476d-4880-9ac1-db3cae54d206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>initial_response</th>\n",
       "      <th>claims</th>\n",
       "      <th>hallucination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many people were estimated by authorities ...</td>\n",
       "      <td>[3,000]</td>\n",
       "      <td>[Approximately 800 people.]</td>\n",
       "      <td>[Approximately 800 people.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Until the Reformation, what was the establishe...</td>\n",
       "      <td>[Roman Catholicism]</td>\n",
       "      <td>[Catholicism]</td>\n",
       "      <td>[Catholicism]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did the war start up again?</td>\n",
       "      <td>[March 1969]</td>\n",
       "      <td>[2001]</td>\n",
       "      <td>[2001]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Buddhist teachings are often full of para...</td>\n",
       "      <td>[Zen]</td>\n",
       "      <td>[Zen teachings.]</td>\n",
       "      <td>[Zen teachings.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which work did Welch express his belief tha...</td>\n",
       "      <td>[Encyclopaedia of Islam]</td>\n",
       "      <td>[The Quran]</td>\n",
       "      <td>[The Quran]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What type of church is Northwestern University...</td>\n",
       "      <td>[Methodist Episcopal Church]</td>\n",
       "      <td>[Northwestern University is associated with th...</td>\n",
       "      <td>[Northwestern University is associated with th...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What air sports event did Brasilia host in 2003?</td>\n",
       "      <td>[the 14th Hang Gliding World Championship]</td>\n",
       "      <td>[World Air Games]</td>\n",
       "      <td>[World Air Games]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many single have been sold by American Ido...</td>\n",
       "      <td>[120 million]</td>\n",
       "      <td>[Over 33 million singles.]</td>\n",
       "      <td>[Over 33 million singles.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do the wrestlers treat the audience?</td>\n",
       "      <td>[The audience is recognized and acknowledged b...</td>\n",
       "      <td>[With respect and appreciation.]</td>\n",
       "      <td>[With respect and appreciation.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In which country is Ephesus?</td>\n",
       "      <td>[Turkey]</td>\n",
       "      <td>[Turkey]</td>\n",
       "      <td>[Turkey]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What did the mysteries seem to threaten that m...</td>\n",
       "      <td>[morality and unity]</td>\n",
       "      <td>[Political stability.]</td>\n",
       "      <td>[Political stability.]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How many subordinate divisions did the Nationa...</td>\n",
       "      <td>[three]</td>\n",
       "      <td>[Five]</td>\n",
       "      <td>[Five]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How much RAM did the first Maciuntosh board have?</td>\n",
       "      <td>[64 kilobytes (kB)]</td>\n",
       "      <td>[128 KB]</td>\n",
       "      <td>[128 KB]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What states assisting Japan was Thailand a par...</td>\n",
       "      <td>[Axis]</td>\n",
       "      <td>[World War II.]</td>\n",
       "      <td>[World War II.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>When did the French authorities adopted the pr...</td>\n",
       "      <td>[Since the presidency of François Mitterrand (...</td>\n",
       "      <td>[1950]</td>\n",
       "      <td>[1950]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What part of the government controls the judic...</td>\n",
       "      <td>[executive]</td>\n",
       "      <td>[Executive branch]</td>\n",
       "      <td>[Executive branch]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What tool did Hoover use to find bootleggers?</td>\n",
       "      <td>[wiretapping]</td>\n",
       "      <td>[Wiretapping.]</td>\n",
       "      <td>[Wiretapping.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How many plays can the offence run without gai...</td>\n",
       "      <td>[three]</td>\n",
       "      <td>[Four plays]</td>\n",
       "      <td>[Four plays]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>After WWII what was the coming out ceremony re...</td>\n",
       "      <td>[less formal afternoon receptions]</td>\n",
       "      <td>[Debutante ball]</td>\n",
       "      <td>[Debutante ball]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Genetic engineering allows what?</td>\n",
       "      <td>[molecular components of the brain to be alter...</td>\n",
       "      <td>[Genetic engineering allows for the manipulati...</td>\n",
       "      <td>[Genetic engineering allows for the manipulati...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What did previous religious orders do for a li...</td>\n",
       "      <td>[farms]</td>\n",
       "      <td>[They were often involved in agriculture and m...</td>\n",
       "      <td>[They were often involved in agriculture and m...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What did Hayek believe the Chilean government ...</td>\n",
       "      <td>[a liberal government]</td>\n",
       "      <td>[A dictatorship.]</td>\n",
       "      <td>[A dictatorship.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>When did the government of Aragon  degree the ...</td>\n",
       "      <td>[2011]</td>\n",
       "      <td>[In 2010.]</td>\n",
       "      <td>[In 2010.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is the maximum amount of players allowed?</td>\n",
       "      <td>[eleven]</td>\n",
       "      <td>[10 players.]</td>\n",
       "      <td>[10 players.]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What was the name of the conflict between Soma...</td>\n",
       "      <td>[the Ogaden War]</td>\n",
       "      <td>[Ogaden War]</td>\n",
       "      <td>[Ogaden War]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What did Agnes Shea give to the Chinese in ret...</td>\n",
       "      <td>[a message stick]</td>\n",
       "      <td>[Opium]</td>\n",
       "      <td>[Opium]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Who was given the grandiose title?</td>\n",
       "      <td>[Sonam Gyatso]</td>\n",
       "      <td>[Napoleon Bonaparte]</td>\n",
       "      <td>[Napoleon Bonaparte]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What does the mouth of the Qiantang River form?</td>\n",
       "      <td>[Hangzhou Bay]</td>\n",
       "      <td>[A tidal bore.]</td>\n",
       "      <td>[A tidal bore.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What expedition found nine meteorites in 1969?</td>\n",
       "      <td>[Japanese]</td>\n",
       "      <td>[Antarctic Search for Meteorites expedition]</td>\n",
       "      <td>[Antarctic Search for Meteorites expedition]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What part of the southern population worked as...</td>\n",
       "      <td>[landless]</td>\n",
       "      <td>[African Americans]</td>\n",
       "      <td>[African Americans]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What does the body interpret from the gene fee...</td>\n",
       "      <td>[time of the day]</td>\n",
       "      <td>[The body interprets the gene feedback loop to...</td>\n",
       "      <td>[The body interprets the gene feedback loop to...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Which of CBC's channels were required to be re...</td>\n",
       "      <td>[52 to 69]</td>\n",
       "      <td>[CBC's French-language television network, Ici...</td>\n",
       "      <td>[CBC's French-language television network, Ici...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What is Lionel Messi's goal total in all compe...</td>\n",
       "      <td>[474]</td>\n",
       "      <td>[Lionel Messi has scored over 700 career goals...</td>\n",
       "      <td>[Lionel Messi has scored over 700 career goals...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Performance of classical music requires profic...</td>\n",
       "      <td>[harmonic]</td>\n",
       "      <td>[Music theory and technique.]</td>\n",
       "      <td>[Music theory and technique.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>How many slaves at most were under the command...</td>\n",
       "      <td>[150,000]</td>\n",
       "      <td>[Around 70,000 slaves.]</td>\n",
       "      <td>[Around 70,000 slaves.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Who does Ibn Sina's philosophy owe much to?</td>\n",
       "      <td>[al-Farabi]</td>\n",
       "      <td>[Aristotle]</td>\n",
       "      <td>[Aristotle]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What is intermarriage typically seen as?</td>\n",
       "      <td>[rejection of Judaism]</td>\n",
       "      <td>[A blending of cultures and traditions.]</td>\n",
       "      <td>[A blending of cultures and traditions.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What ethnice groups did the Qing thin made up ...</td>\n",
       "      <td>[Han and non-Han peoples]</td>\n",
       "      <td>[Manchus and Han Chinese.]</td>\n",
       "      <td>[Manchus and Han Chinese.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>What algae is the ancestor of true plants?</td>\n",
       "      <td>[Charophyta]</td>\n",
       "      <td>[Charophytes]</td>\n",
       "      <td>[Charophytes]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>How many species of game fish have hunting sea...</td>\n",
       "      <td>[at least 17]</td>\n",
       "      <td>[Over 100 species.]</td>\n",
       "      <td>[Over 100 species.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>What happens to members who disagree with the ...</td>\n",
       "      <td>[expelled and shunned]</td>\n",
       "      <td>[They may be excommunicated.]</td>\n",
       "      <td>[They may be excommunicated.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Who shared the first homosexual kiss on EastEn...</td>\n",
       "      <td>[Colin Russell and Guido Smith]</td>\n",
       "      <td>[Colin and Guido]</td>\n",
       "      <td>[Colin and Guido]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What do French historians commonly call the Ag...</td>\n",
       "      <td>[Siècle des Lumières (Century of Enlightenments)]</td>\n",
       "      <td>[The French historians commonly call the Age o...</td>\n",
       "      <td>[The French historians commonly call the Age o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What is the largest of the cemeteries created ...</td>\n",
       "      <td>[Cimetière parisien de Saint-Ouen]</td>\n",
       "      <td>[Arlington National Cemetery]</td>\n",
       "      <td>[Arlington National Cemetery]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>The salinity of what in the region was long re...</td>\n",
       "      <td>[Soil]</td>\n",
       "      <td>[The salinity of soil in the region was long r...</td>\n",
       "      <td>[The salinity of soil in the region was long r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Were was the hydraulic crane initially used?</td>\n",
       "      <td>[Tyneside docks]</td>\n",
       "      <td>[Europe.]</td>\n",
       "      <td>[Europe.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What year did the U.S. go to war, leading to w...</td>\n",
       "      <td>[1917]</td>\n",
       "      <td>[1918]</td>\n",
       "      <td>[1918]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>What emperors visited Nanjing more than once?</td>\n",
       "      <td>[the Kangxi and Qianlong emperors]</td>\n",
       "      <td>[Emperor Zhu Yuanzhang and Emperor Yongle.]</td>\n",
       "      <td>[Emperor Zhu Yuanzhang and Emperor Yongle.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>What types of trees grow near rivers in wester...</td>\n",
       "      <td>[pinyon pines, red cedar (junipers), and ponde...</td>\n",
       "      <td>[Cottonwood and willow trees.]</td>\n",
       "      <td>[Cottonwood and willow trees.]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>What does the abbreviated electrical character...</td>\n",
       "      <td>[three numeric digits and a letter]</td>\n",
       "      <td>[Dielectric type, capacitance value, and volta...</td>\n",
       "      <td>[Dielectric type, capacitance value, and volta...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   How many people were estimated by authorities ...   \n",
       "1   Until the Reformation, what was the establishe...   \n",
       "2                    When did the war start up again?   \n",
       "3   What Buddhist teachings are often full of para...   \n",
       "4   In which work did Welch express his belief tha...   \n",
       "5   What type of church is Northwestern University...   \n",
       "6    What air sports event did Brasilia host in 2003?   \n",
       "7   How many single have been sold by American Ido...   \n",
       "8            How do the wrestlers treat the audience?   \n",
       "9                        In which country is Ephesus?   \n",
       "10  What did the mysteries seem to threaten that m...   \n",
       "11  How many subordinate divisions did the Nationa...   \n",
       "12  How much RAM did the first Maciuntosh board have?   \n",
       "13  What states assisting Japan was Thailand a par...   \n",
       "14  When did the French authorities adopted the pr...   \n",
       "15  What part of the government controls the judic...   \n",
       "16      What tool did Hoover use to find bootleggers?   \n",
       "17  How many plays can the offence run without gai...   \n",
       "18  After WWII what was the coming out ceremony re...   \n",
       "19                   Genetic engineering allows what?   \n",
       "20  What did previous religious orders do for a li...   \n",
       "21  What did Hayek believe the Chilean government ...   \n",
       "22  When did the government of Aragon  degree the ...   \n",
       "23     What is the maximum amount of players allowed?   \n",
       "24  What was the name of the conflict between Soma...   \n",
       "25  What did Agnes Shea give to the Chinese in ret...   \n",
       "26                 Who was given the grandiose title?   \n",
       "27    What does the mouth of the Qiantang River form?   \n",
       "28     What expedition found nine meteorites in 1969?   \n",
       "29  What part of the southern population worked as...   \n",
       "30  What does the body interpret from the gene fee...   \n",
       "31  Which of CBC's channels were required to be re...   \n",
       "32  What is Lionel Messi's goal total in all compe...   \n",
       "33  Performance of classical music requires profic...   \n",
       "34  How many slaves at most were under the command...   \n",
       "35        Who does Ibn Sina's philosophy owe much to?   \n",
       "36           What is intermarriage typically seen as?   \n",
       "37  What ethnice groups did the Qing thin made up ...   \n",
       "38         What algae is the ancestor of true plants?   \n",
       "39  How many species of game fish have hunting sea...   \n",
       "40  What happens to members who disagree with the ...   \n",
       "41  Who shared the first homosexual kiss on EastEn...   \n",
       "42  What do French historians commonly call the Ag...   \n",
       "43  What is the largest of the cemeteries created ...   \n",
       "44  The salinity of what in the region was long re...   \n",
       "45       Were was the hydraulic crane initially used?   \n",
       "46  What year did the U.S. go to war, leading to w...   \n",
       "47      What emperors visited Nanjing more than once?   \n",
       "48  What types of trees grow near rivers in wester...   \n",
       "49  What does the abbreviated electrical character...   \n",
       "\n",
       "                                               answer  \\\n",
       "0                                             [3,000]   \n",
       "1                                 [Roman Catholicism]   \n",
       "2                                        [March 1969]   \n",
       "3                                               [Zen]   \n",
       "4                            [Encyclopaedia of Islam]   \n",
       "5                        [Methodist Episcopal Church]   \n",
       "6          [the 14th Hang Gliding World Championship]   \n",
       "7                                       [120 million]   \n",
       "8   [The audience is recognized and acknowledged b...   \n",
       "9                                            [Turkey]   \n",
       "10                               [morality and unity]   \n",
       "11                                            [three]   \n",
       "12                                [64 kilobytes (kB)]   \n",
       "13                                             [Axis]   \n",
       "14  [Since the presidency of François Mitterrand (...   \n",
       "15                                        [executive]   \n",
       "16                                      [wiretapping]   \n",
       "17                                            [three]   \n",
       "18                 [less formal afternoon receptions]   \n",
       "19  [molecular components of the brain to be alter...   \n",
       "20                                            [farms]   \n",
       "21                             [a liberal government]   \n",
       "22                                             [2011]   \n",
       "23                                           [eleven]   \n",
       "24                                   [the Ogaden War]   \n",
       "25                                  [a message stick]   \n",
       "26                                     [Sonam Gyatso]   \n",
       "27                                     [Hangzhou Bay]   \n",
       "28                                         [Japanese]   \n",
       "29                                         [landless]   \n",
       "30                                  [time of the day]   \n",
       "31                                         [52 to 69]   \n",
       "32                                              [474]   \n",
       "33                                         [harmonic]   \n",
       "34                                          [150,000]   \n",
       "35                                        [al-Farabi]   \n",
       "36                             [rejection of Judaism]   \n",
       "37                          [Han and non-Han peoples]   \n",
       "38                                       [Charophyta]   \n",
       "39                                      [at least 17]   \n",
       "40                             [expelled and shunned]   \n",
       "41                    [Colin Russell and Guido Smith]   \n",
       "42  [Siècle des Lumières (Century of Enlightenments)]   \n",
       "43                 [Cimetière parisien de Saint-Ouen]   \n",
       "44                                             [Soil]   \n",
       "45                                   [Tyneside docks]   \n",
       "46                                             [1917]   \n",
       "47                 [the Kangxi and Qianlong emperors]   \n",
       "48  [pinyon pines, red cedar (junipers), and ponde...   \n",
       "49                [three numeric digits and a letter]   \n",
       "\n",
       "                                     initial_response  \\\n",
       "0                         [Approximately 800 people.]   \n",
       "1                                       [Catholicism]   \n",
       "2                                              [2001]   \n",
       "3                                    [Zen teachings.]   \n",
       "4                                         [The Quran]   \n",
       "5   [Northwestern University is associated with th...   \n",
       "6                                   [World Air Games]   \n",
       "7                          [Over 33 million singles.]   \n",
       "8                    [With respect and appreciation.]   \n",
       "9                                            [Turkey]   \n",
       "10                             [Political stability.]   \n",
       "11                                             [Five]   \n",
       "12                                           [128 KB]   \n",
       "13                                    [World War II.]   \n",
       "14                                             [1950]   \n",
       "15                                 [Executive branch]   \n",
       "16                                     [Wiretapping.]   \n",
       "17                                       [Four plays]   \n",
       "18                                   [Debutante ball]   \n",
       "19  [Genetic engineering allows for the manipulati...   \n",
       "20  [They were often involved in agriculture and m...   \n",
       "21                                  [A dictatorship.]   \n",
       "22                                         [In 2010.]   \n",
       "23                                      [10 players.]   \n",
       "24                                       [Ogaden War]   \n",
       "25                                            [Opium]   \n",
       "26                               [Napoleon Bonaparte]   \n",
       "27                                    [A tidal bore.]   \n",
       "28       [Antarctic Search for Meteorites expedition]   \n",
       "29                                [African Americans]   \n",
       "30  [The body interprets the gene feedback loop to...   \n",
       "31  [CBC's French-language television network, Ici...   \n",
       "32  [Lionel Messi has scored over 700 career goals...   \n",
       "33                      [Music theory and technique.]   \n",
       "34                            [Around 70,000 slaves.]   \n",
       "35                                        [Aristotle]   \n",
       "36           [A blending of cultures and traditions.]   \n",
       "37                         [Manchus and Han Chinese.]   \n",
       "38                                      [Charophytes]   \n",
       "39                                [Over 100 species.]   \n",
       "40                      [They may be excommunicated.]   \n",
       "41                                  [Colin and Guido]   \n",
       "42  [The French historians commonly call the Age o...   \n",
       "43                      [Arlington National Cemetery]   \n",
       "44  [The salinity of soil in the region was long r...   \n",
       "45                                          [Europe.]   \n",
       "46                                             [1918]   \n",
       "47        [Emperor Zhu Yuanzhang and Emperor Yongle.]   \n",
       "48                     [Cottonwood and willow trees.]   \n",
       "49  [Dielectric type, capacitance value, and volta...   \n",
       "\n",
       "                                               claims  hallucination  \n",
       "0                         [Approximately 800 people.]          False  \n",
       "1                                       [Catholicism]          False  \n",
       "2                                              [2001]          False  \n",
       "3                                    [Zen teachings.]          False  \n",
       "4                                         [The Quran]          False  \n",
       "5   [Northwestern University is associated with th...          False  \n",
       "6                                   [World Air Games]          False  \n",
       "7                          [Over 33 million singles.]          False  \n",
       "8                    [With respect and appreciation.]          False  \n",
       "9                                            [Turkey]          False  \n",
       "10                             [Political stability.]           True  \n",
       "11                                             [Five]          False  \n",
       "12                                           [128 KB]          False  \n",
       "13                                    [World War II.]          False  \n",
       "14                                             [1950]          False  \n",
       "15                                 [Executive branch]          False  \n",
       "16                                     [Wiretapping.]          False  \n",
       "17                                       [Four plays]          False  \n",
       "18                                   [Debutante ball]          False  \n",
       "19  [Genetic engineering allows for the manipulati...          False  \n",
       "20  [They were often involved in agriculture and m...           True  \n",
       "21                                  [A dictatorship.]          False  \n",
       "22                                         [In 2010.]          False  \n",
       "23                                      [10 players.]           True  \n",
       "24                                       [Ogaden War]          False  \n",
       "25                                            [Opium]          False  \n",
       "26                               [Napoleon Bonaparte]          False  \n",
       "27                                    [A tidal bore.]          False  \n",
       "28       [Antarctic Search for Meteorites expedition]          False  \n",
       "29                                [African Americans]          False  \n",
       "30  [The body interprets the gene feedback loop to...          False  \n",
       "31  [CBC's French-language television network, Ici...          False  \n",
       "32  [Lionel Messi has scored over 700 career goals...           True  \n",
       "33                      [Music theory and technique.]          False  \n",
       "34                            [Around 70,000 slaves.]          False  \n",
       "35                                        [Aristotle]          False  \n",
       "36           [A blending of cultures and traditions.]          False  \n",
       "37                         [Manchus and Han Chinese.]          False  \n",
       "38                                      [Charophytes]          False  \n",
       "39                                [Over 100 species.]          False  \n",
       "40                      [They may be excommunicated.]          False  \n",
       "41                                  [Colin and Guido]           True  \n",
       "42  [The French historians commonly call the Age o...          False  \n",
       "43                      [Arlington National Cemetery]          False  \n",
       "44  [The salinity of soil in the region was long r...          False  \n",
       "45                                          [Europe.]          False  \n",
       "46                                             [1918]          False  \n",
       "47        [Emperor Zhu Yuanzhang and Emperor Yongle.]          False  \n",
       "48                     [Cottonwood and willow trees.]          False  \n",
       "49  [Dielectric type, capacitance value, and volta...          False  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(squad_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ca639-8084-4044-bba0-d8d7eb45b35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c170ceef-9879-443f-a7bf-d24fef605ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fe226-1164-4931-9bc9-75c1b85824d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5737b60-13fd-4bec-b093-6374bcc8af6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "656c5d98-5443-42ed-ad87-3a9d6e250422",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b13612d8-92a6-4908-872e-b6af9179b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "def bootstrap_optimize(model):\n",
    "    teleprompter = BootstrapFewShot(metric=validate_context_and_answer) \n",
    "    optimized_program = teleprompter.compile(model, trainset=dev_exs)\n",
    "    return optimized_program\n",
    "\n",
    "def bootstrap_rm_optimize(model):\n",
    "    teleprompter = BootstrapFewShotWithRandomSearch(\n",
    "          metric=validate_context_and_answer\n",
    "        , num_candidate_programs = 2\n",
    "        , max_bootstrapped_demos= 2\n",
    "        , max_labeled_demos= 2) \n",
    "    optimized_program = teleprompter.compile(model, trainset=dev_exs)\n",
    "    return optimized_program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206615d4-2162-475c-84ac-16cab0e3a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_halu_check_model = bootstrap_rm_optimize(halu_check_model) \n",
    "optimized_multihop_halu_model = bootstrap_rm_optimize(multihop_halu_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13e9b7-d14a-4433-993f-afcd5e254480",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_openqa_model = bootstrap_rm_optimize(basic_openqa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96fac6-20d6-4760-998c-77f0869531c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f414fd-deb4-4bf8-af22-619a3410f7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d061b2-9d27-4c59-8a11-d9a6a068390a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c4d0b-8c15-4a5e-b436-b8ac29e5d4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc55de-91ae-4ea3-b4fd-557b5a06b402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5be85-d1f3-4183-aa23-6df8d5460647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "175377fd-8ced-4d2c-9d81-943d618e136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bakeoff_submission(model):\n",
    "    \"\"\"\"\n",
    "    The argument `model` is a `dspy.Module`. The return value of its\n",
    "    `forward` method must have an `answer` attribute.\n",
    "    \"\"\"\n",
    "\n",
    "    filename = os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")\n",
    "\n",
    "    # This should become a mapping from questions (str) to response\n",
    "    # dicts from your system.\n",
    "    gens = {}\n",
    "\n",
    "    with open(filename) as f:\n",
    "        questions = f.read().splitlines()\n",
    "    # questions = questions[:100]\n",
    "    # Here we loop over the questions, run the system `model`, and\n",
    "    # store its `answer` value as the prediction:\n",
    "    for question in tqdm.tqdm(questions):\n",
    "        gens[question] = model(question=question).answer\n",
    "\n",
    "    # Quick tests we advise you to run:\n",
    "    # 1. Make sure `gens` is a dict with the questions as the keys:\n",
    "    assert all(question in gens for q in questions)\n",
    "    # 2. Make sure the values are str:\n",
    "    assert all(isinstance(d, str) for d in gens.values())\n",
    "\n",
    "    # And finally the output file:\n",
    "    with open(\"cs224u-openqa-bakeoff-entry.json\", \"wt\") as f:\n",
    "        json.dump(gens, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceff1a4-a241-4213-acc2-62a18adc0dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cc17de9f-32f2-4c9b-8bfc-11faa9faee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = MultiHopRAG()\n",
    "# loaded_model.load(\"gpt_optimized_model.sav\")\n",
    "# gpt_optimized_model.save(\"gpt_optimized_model.sav\")\n",
    "gpt_optimized_model.save = open_qa_model.save\n",
    "gpt_optimized_model.save(\"gpt_optimized_model.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f2af2-1f54-4720-8daa-3948560e326d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9c19b-145d-42a9-a736-872369cb0cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08291842-3ee1-4b15-82e9-0803b4d75e1d",
   "metadata": {},
   "source": [
    "### Michael's model (for ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b302c7-f761-41bb-bdd7-a14bf096b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flexible_optimize(model, config_optimizer=None, optimizer=BootstrapFewShotWithRandomSearch, metric=answer_passage_match, trainset=squad_train, devset=squad_dev, n_samples=30):\n",
    "    if config_optimizer is None:\n",
    "        config_optimizer = {}\n",
    "    return optimizer(metric=metric, **config_optimizer).compile(model, trainset=sample(trainset, n_samples))\n",
    "\n",
    "log_format = '%(funcName)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(format=log_format, level=logging.INFO, stream=sys.stdout, force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a short and concise search query that will help answer a complex question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()\n",
    "    \n",
    "class SummarizeSignature(dspy.Signature):\n",
    "    # __doc__ = \"\"\"Reply with a concise summary of the key facts and statements from the following text.\"\"\"\n",
    "    __doc__ = \"\"\"Summarize the following text in one paragraph focusing on key facts and statements.\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    summary = dspy.OutputField()\n",
    "    \n",
    "class ContextQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "    \n",
    "class FlexibleRAG(dspy.Module):\n",
    "    def __init__(self, \n",
    "                 passages_per_hop=3, \n",
    "                 max_hops=2,\n",
    "                 summarize_retrieved_passages_per_hop=True,\n",
    "                 summarize_whole_context=False,\n",
    "                 module_gen_answer=dspy.Predict, \n",
    "                 signature_gen_answer=ContextQASignature,\n",
    "                 module_summarize=dspy.Predict,\n",
    "                 signature_summarize=SummarizeSignature,\n",
    "                 module_gen_query=dspy.Predict,\n",
    "                 signature_gen_query=GenerateSearchQuery,\n",
    "                 loglevel=logging.INFO):\n",
    "        super().__init__()    \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(loglevel)    \n",
    "        self.max_hops = max_hops\n",
    "        self.summarize_retrieved_passages_per_hop = summarize_retrieved_passages_per_hop\n",
    "        self.summarize_whole_context = summarize_whole_context\n",
    "        self.summarize = None\n",
    "        self.generate_query = None\n",
    "        if module_summarize is not None and signature_summarize is not None:\n",
    "            self.summarize = module_summarize(signature_summarize)\n",
    "        if module_gen_query is not None and signature_gen_query is not None:\n",
    "            self.generate_query = [module_gen_query(signature_gen_query) for _ in range(max_hops)]            \n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = module_gen_answer(signature_gen_answer)\n",
    "    \n",
    "    def get_context(self, question):\n",
    "        if self.generate_query is not None:\n",
    "            context = []\n",
    "            for hop in range(self.max_hops):\n",
    "                self.logger.debug(f'{hop=}')\n",
    "                query = self.generate_query[hop](context=context, question=question).query            \n",
    "                self.logger.debug(f'{query=}')\n",
    "                passages = self.retrieve(query).passages\n",
    "                if self.summarize_retrieved_passages_per_hop and self.summarize is not None:\n",
    "                    # Summarize every passage to ease generation of answer and reduce context size\n",
    "                    passages = [self.get_summary(passage) for passage in passages]                   \n",
    "                context = deduplicate(context + passages)\n",
    "                self.logger.debug(f'{context=}')\n",
    "        else:\n",
    "            context = self.retrieve(question).passages\n",
    "        return context\n",
    "            \n",
    "    def get_summary(self, context):\n",
    "        if self.summarize is not None:\n",
    "            summary = self.summarize(context=context).summary\n",
    "            self.logger.debug(f'{context=}')\n",
    "            self.logger.debug(f'{summary=}')\n",
    "            return summary\n",
    "        else:\n",
    "            return context        \n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.get_context(question=question)  \n",
    "        if self.summarize_whole_context and self.summarize is not None:  \n",
    "            summary = self.get_summary(context=context)\n",
    "        else:\n",
    "            summary = context\n",
    "        prediction = self.generate_answer(context=summary, question=question)        \n",
    "        self.logger.debug(f'{question=}')\n",
    "        self.logger.debug(f'{context=}')\n",
    "        self.logger.debug(f'{summary=}')\n",
    "        self.logger.debug(f'{prediction.answer=}')\n",
    "        return dspy.Prediction(context=summary, answer=prediction.answer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe339f55-0b43-4b28-8e48-ceca94e26683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c90d4196-1923-49d2-9790-2ba1822d62cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573520d-8554-4717-b6ca-999e6dc36ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403eceac-7e23-4d5d-ac14-374c66fbf5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073820d5-028e-445b-b2b7-0911c9806181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
