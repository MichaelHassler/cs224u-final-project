{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf85bea0-68bf-4405-96ec-37579b2e9587",
   "metadata": {},
   "source": [
    "# Homework and bakeoff: Few-shot OpenQA with DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28e9bf5-7956-4c63-9129-7f2cbc468075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts and Omar Khattab\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5d964-a45c-496a-bb46-8f31d7b2d591",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/master/hw_openqa.ipynb)\n",
    "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/cgpotts/cs224u/blob/master/hw_openqa.ipynb)\n",
    "\n",
    "If Colab is opened with this badge, please **save a copy to drive** (from the File menu) before running the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8570fc5-2ac0-4c0e-b350-71990937ebd8",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da2d82-8c54-4d41-a59d-891f83f85f6e",
   "metadata": {},
   "source": [
    "The goal of this homework is to explore retrieval-augmented in-context learning. This is an exciting area that brings together a number of recent task ideas and modeling innovations. We will use the [DSPy programming library](http://dspy.ai) to build systems in this new mode.\n",
    "\n",
    "Our core task is __open-domain question answering (OpenQA)__. In this task, all that is given by the dataset is a question text, and the task is to answer that question. By contrast, in many modern QA tasks, the dataset provides a text and a gold passage, usually with a firm guarantee that the answer will be a substring of the passage.\n",
    "\n",
    "OpenQA is substantially harder than standard QA. The usual strategy is to use a _retriever_ to find passages in a large collection of texts and train a _reader_ to find answers in those passages. This means we have no guarantee that the retrieved passage will contain the answer we need. If we don't retrieve a passage containing the answer, our reader has no hope of succeeding. Although this is challenging, it is much more realistic and widely applicable than standard QA. After all, with the right retriever, an OpenQA system could be deployed over the entire Web.\n",
    "\n",
    "The task posed by this homework is harder even than OpenQA. We are calling this task __few-shot OpenQA__. The defining feature of this task is that the reader is simply a frozen, general purpose language model. It accepts string inputs (prompts) and produces text in response. It is not trained to answer questions per se, and nothing about its structure ensures that it will respond with a substring of the prompt corresponding to anything like an answer.\n",
    "\n",
    "__Few-shot QA__ (but not OpenQA!) is explored in the famous GPT-3 paper ([Brown et al. 2020](https://arxiv.org/abs/2005.14165)). The authors are able to get traction on the problem using GPT-3, an incredible finding. Our task here – __few-shot OpenQA__ – pushes this even further by retrieving passages to use in the prompt rather than assuming that the gold passage can be used in the prompt. If we can make this work, then it should be a major step towards flexibly and easily deploying QA technologies in new domains.\n",
    "\n",
    "In summary:\n",
    "\n",
    "| Task             | Passage given | Task-specific reader training |Task-specific retriever training  | \n",
    "|-----------------:|:-------------:|:-----------------------------:|:--------------------------------:|\n",
    "| QA               | yes           | yes                           | n/a                              |\n",
    "| OpenQA           | no            | yes                           | maybe                            |\n",
    "| Few-shot QA      | yes           | no                            | n/a                              |\n",
    "| Few-shot OpenQA  | no            | no                            | maybe                            | \n",
    "\n",
    "Just to repeat: your mission is to explore the final line in this table. The core notebook and assignment don't address the issue of training the retriever in a task-specific way, but this is something you could pursue for a final project; [the ColBERT codebase](https://github.com/stanford-futuredata/ColBERT) makes easy.\n",
    "\n",
    "It is a requirement of the bake-off that a general-purpose language model be used. In particular, trained QA systems cannot be used at all, and no fine-tuning is allowed either. See the original system question at the bottom of this message for guidance on which models are allowed.\n",
    "\n",
    "Note: the models we are working with here are _big_. This poses a challenge that is increasingly common in NLP: you have to pay one way or another. You can pay to use the GPT-3 API, or you can pay to use a local model on a heavy-duty cluster computer, or you can pay with time by using a local model on a more modest computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd32bb4-067f-4cd6-943f-3e5574400beb",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149bcb0f-bc76-4277-a359-742d6dcee063",
   "metadata": {},
   "source": [
    "We have sought to make this notebook self-contained and easy to use on a personal computer, on Google Colab, and in Sagemaker Studio. For personal computer use, we assume you have already done everything in [setup.ipynb](setup.ipynb]). For cloud usage, the next few code blocks should handle all set-up steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b983bb-a20a-4c2a-9eee-9c553dd8c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import datasets\n",
    "    root_path = '.'\n",
    "except ModuleNotFoundError:\n",
    "    !git clone https://github.com/cgpotts/cs224u/\n",
    "    !pip install -r cs224u/requirements.txt\n",
    "    root_path = 'dspy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04cb488-cd40-4f9d-b884-8ff83b012042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import openai\n",
    "import os\n",
    "import dspy\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6298ae",
   "metadata": {},
   "source": [
    "Save the API keys in a `.env` file in the local root directory as follows. Then, `load_dotenv()` will make them available to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c642de1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the API keys in a `.env` file in the local root directory\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9da704b-d27b-480a-93b5-e16cf7c51803",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')  # or replace with your API key (optional)\n",
    "\n",
    "colbert_server = 'http://index.contextual.ai:8893/api/search'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562fc500-bbab-48b7-a704-67c6d57bb09b",
   "metadata": {},
   "source": [
    "Here we establish the Language module `lm` and Retriever module `rm` that we will be using. The defaults for `lm` are just for development. You may want to develop using an inexpensive model and then do your final evalautions wih an expensive one. DSPy has support for a wide range of model APIs and local models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c118b014-e13f-433d-ad60-074636c7e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.OpenAI(model='gpt-3.5-turbo', api_key=openai_key)\n",
    "\n",
    "rm = dspy.ColBERTv2(url=colbert_server)\n",
    "\n",
    "dspy.settings.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711785d7-6bb9-4041-92e6-cc5f9308477e",
   "metadata": {},
   "source": [
    "Here's a command you can run to see which OpenAI models are available; OpenAI has entered into an increasingly closed mode where many older models are not available, so there are likely to be some surprises lurking here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a859fbb-e985-4031-b8ed-34f3b034db8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4-vision-preview',\n",
       " 'dall-e-3',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'text-embedding-3-large',\n",
       " 'gpt-3.5-turbo-instruct-0914',\n",
       " 'dall-e-2',\n",
       " 'whisper-1',\n",
       " 'tts-1-hd-1106',\n",
       " 'tts-1-hd',\n",
       " 'babbage-002',\n",
       " 'text-embedding-ada-002',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-3.5-turbo',\n",
       " 'text-embedding-3-small',\n",
       " 'gpt-3.5-turbo-0301',\n",
       " 'gpt-3.5-turbo-instruct',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'tts-1',\n",
       " 'tts-1-1106',\n",
       " 'gpt-4-0125-preview',\n",
       " 'gpt-3.5-turbo-1106',\n",
       " 'gpt-4',\n",
       " 'gpt-4-turbo-preview',\n",
       " 'gpt-4-0613',\n",
       " 'gpt-3.5-turbo-16k-0613',\n",
       " 'davinci-002',\n",
       " 'gpt-4-1106-preview']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d['id'] for d in openai.Model.list()['data']]\n",
    "# Adapt to current API\n",
    "# client = openai.OpenAI(api_key=openai_key)\n",
    "# [d.id for d in client.models.list().data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b3dc2-87d7-4b8b-b603-ee567e008710",
   "metadata": {},
   "source": [
    "## SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de295d35-fea5-46d2-9a01-022ad88e54cd",
   "metadata": {},
   "source": [
    "Our core development dataset is [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/). We chose this dataset because it is well-known and widely used, and it is large enough to support lots of meaningful development work, without, though, being so large as to require lots of compute power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eaf2fd0-d060-4100-8702-f7311efd6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36965402-e3da-4531-b7e9-4b12cebcdf30",
   "metadata": {},
   "source": [
    "The following utility just reads a SQuAD split in as a list of `dspy.Example` instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ad3e0b-7662-43b8-9409-a1a57442458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squad_split(squad, split=\"validation\"):\n",
    "    \"\"\"\n",
    "    Use `split='train'` for the train split.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dspy.Example with attributes question, answer\n",
    "\n",
    "    \"\"\"\n",
    "    data = zip(*[squad[split][field] for field in squad[split].features])\n",
    "    exs = [dspy.Example(question=q, answer=a['text'][0]).with_inputs(\"question\")\n",
    "           for eid, title, context, q, a in data]\n",
    "    return exs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3847d38-4e70-46b7-bf46-4c8b784c5ee5",
   "metadata": {},
   "source": [
    "### SQuAD train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c91e1-586b-4747-be39-3092e60f182f",
   "metadata": {},
   "source": [
    "To build few-shot prompts, we will often sample SQuAD train examples, so we load that split here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c4feba-d580-4984-a449-0b92a53ef13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train = get_squad_split(squad, split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab8c41-8eae-4d15-ad4d-e28b3c58eb4a",
   "metadata": {},
   "source": [
    "### SQuAD dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37198b33-c47b-4e0e-af8b-c00860658cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dev = get_squad_split(squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b8fab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10570"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(squad_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40c768-57cc-4a07-a3ef-5e34262b0ace",
   "metadata": {},
   "source": [
    "### SQuAD dev sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636601b5-c7ad-4177-a6d6-f3afdb0bedae",
   "metadata": {},
   "source": [
    "Evaluations are expensive in this new era! Here's a small sample to use for dev assessments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ccdd0e-de78-440d-bfbe-358c12eada5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "dev_exs = random.sample(squad_dev, k=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28265d01-890d-4f04-b518-da0e8a1cb235",
   "metadata": {},
   "source": [
    "## DSPy basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b9d12-fc8c-4aae-b09e-0d72a4aa54f5",
   "metadata": {},
   "source": [
    "### LM usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278daac-11f9-4327-a06f-1c408a06a71d",
   "metadata": {},
   "source": [
    "Here's the most basic way to use the LM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02364ed6-3c6d-4eaf-849a-2d9e30d84b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gary Zukav\\'s first book, \"The Dancing Wu Li Masters: An Overview of the New Physics,\" received the 1979 American Book Award for Science.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Which award did Gary Zukav's first book receive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356d9a8-750b-4383-bc5b-4173ca5c13ac",
   "metadata": {},
   "source": [
    "Keyword arguments to the underlying LM are passed through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19ab8deb-3b9d-4f57-bd70-7c170be294c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hawaii and Alaska are the two U.S. states that do not share a border with any other U.S. state.',\n",
       " 'Hawaii and Alaska do not border any other U.S. states.',\n",
       " 'Hawaii and Alaska are the only two U.S. states that do not share a border with any other U.S. state.',\n",
       " 'There are three U.S. states that do not share a border with any other U.S. states. They are Alaska, Hawaii, and Connecticut. Alaska and Hawaii are both located outside the contiguous United States, while Connecticut is located in New England and is surrounded by the states of Massachusetts, New York, and Rhode Island.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Which U.S. states border no U.S. states?\", temperature=0.9, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e8d99-6d49-420d-ab5d-cc01b53cd4a1",
   "metadata": {},
   "source": [
    "With `lm.inspect_history`, we can see the most recent language model calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7cb5a5-3a3f-4e78-b9af-488fadc896ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Which U.S. states border no U.S. states?\u001b[32m Hawaii and Alaska are the two U.S. states that do not share a border with any other U.S. state.\u001b[0m\u001b[31m \t (and 3 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0f2df-df1f-422d-bff3-6c4a3d947f6e",
   "metadata": {},
   "source": [
    "### Signature-based prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0888a2a-fcaa-44b0-beef-b097c856c74b",
   "metadata": {},
   "source": [
    "In DSPy, __signatures__ are declarative statements about what we want the model to do. In the following `\"question -> answer\"` is the signature (the most basic QA signature one could write), and `dspy.Predict` is used to turn this into a complete QA system: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11f04cba-7d46-4680-a154-a0062243618e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_predictor = dspy.Predict(\"question -> answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994fc10-8c28-4836-bd7c-008a9a3d34e4",
   "metadata": {},
   "source": [
    "Here we use `basic_predictor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfe102d0-c0e5-45ad-aae8-51f6ea6e70f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer=\"Question: Which award did Gary Zukav's first book receive?\\nAnswer: The Seat of the Soul received the 1989 Book of the Year award from the American Book Awards.\"\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_predictor(question=\"Which award did Gary Zukav's first book receive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad1a1b-d422-46df-8b03-4054bfec5fc1",
   "metadata": {},
   "source": [
    "And here is the prompt that was given to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af4f86db-97d5-4742-8468-4627de12f181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which award did Gary Zukav's first book receive?\n",
      "Answer:\u001b[32m Question: Which award did Gary Zukav's first book receive?\n",
      "Answer: The Seat of the Soul received the 1989 Book of the Year award from the American Book Awards.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845f62b-8af3-4fa2-af8d-f4ddd1181f30",
   "metadata": {},
   "source": [
    "In many cases, we will want more control over the prompt. Writing a small custom `dspy.Signature` class is the easiest way to accomplish this. In the following, we just just tweak the initial instruction and provide some formatting guidance for the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9dda770-e7ca-4682-b283-d4f4525adb68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83f7297a-b174-4566-8748-6b66d515ed25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sig_predictor = dspy.Predict(BasicQASignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30a02d55-fac7-43c3-851b-3e21f06df14d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Maine, Hawaii'\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_predictor(question=\"Which U.S. states border no U.S. states?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f613c05-ec78-4129-ac44-71bac4e253ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which U.S. states border no U.S. states?\n",
      "Answer:\u001b[32m Maine, Hawaii\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56169f83-0df6-46dc-b617-fadff1b96132",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244aed0-403e-4707-a9eb-e29fc1e4dc57",
   "metadata": {},
   "source": [
    "One of the hallmarks of DSPy is that it adopts design patterns from PyTorch. The main example of this is DSPy's use of the `Module` as the basic unit for writing simple and complex programs. Here is a very basic module for QA that makes use of `BasicQASignature` as we defined it just above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "506c9946-fee4-4dc3-a05e-767f85c25292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(BasicQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        return self.generate_answer(question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c921aaed-6351-443d-8478-6e9a64b49d45",
   "metadata": {},
   "source": [
    "As with PyTorch, the `forward` methos is called when we want to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67f65b7-0fea-40a3-ac78-795926025653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_qa_model = BasicQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7044ec84-f76a-4af4-93f5-a82579237868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='National Book Award'\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_qa_model(question=\"Which award did Gary Zukav's first book receive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9961c89-914a-4736-8a01-1a3cd401821a",
   "metadata": {
    "tags": []
   },
   "source": [
    "The modular design of DSPy starts to become apparent now. If you want to change the above to use chain of thought instead of regular predictions, you need only change `dspy.Predict` to `dspy.ChainOfThought`, and similarly for `dspy.ReAct`, `dspy.ProgramOfThought`, or a module you wrote yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9dac4-9495-448d-ad4b-38ab7260915b",
   "metadata": {},
   "source": [
    "### Teleprompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5200696-808f-4061-878c-26aa20701d58",
   "metadata": {},
   "source": [
    "The QA system we've defined so far is a zero-shot system. To change it into a few-shot system, we will rely on a DSPy __teleprompter__. This will allow us to flexibly move between the zero-shot and few-shot formulations. The following code achieves this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdab9850-1d4d-4e04-b389-6ef55fd0b425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cache/compiler\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import LabeledFewShot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72045705-2f27-46fe-b7bc-801a7d2e9ae4",
   "metadata": {},
   "source": [
    "Here we instantiate a `LabeledFewShot` teleprompter that will add three demonstrations. These will be sampled randomly from the set of train examples we provide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "befc8c18-fc64-4947-800d-6455dee90b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fewshot_teleprompter = LabeledFewShot(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b512d9-ec54-49ca-ab7a-900dc2eea6cc",
   "metadata": {},
   "source": [
    "And then we call `compile` on `basic_qa_model` as we defined it above. This returns a new module that we use like any other in DSPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b327b603-2943-4bcc-b498-1fbafafefd0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_fewshot_qa_model = fewshot_teleprompter.compile(basic_qa_model, trainset=squad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "921ec7f1-ed44-48a3-9c92-0e22911688f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='American Book Award'\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_fewshot_qa_model(question=\"Which award did Gary Zukav's first book receive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180cdaa-dd34-4e0d-8455-e394bfde9fcc",
   "metadata": {},
   "source": [
    "With `inspect_history`, we can see that prompts now contain demonstrations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9507fe6-1cc7-4c0a-8520-cc3812a07c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: What group did Paul VI address in New York in 1965?\n",
      "Answer: United Nations\n",
      "\n",
      "---\n",
      "\n",
      "Question: What did Sander's study show in terms of black law students rankings?\n",
      "Answer: half of all black law students rank near the bottom of their class after the first year of law school\n",
      "\n",
      "---\n",
      "\n",
      "Question: What problems does linguistic anthropology bring linguistic methods to bear on?\n",
      "Answer: anthropological\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which award did Gary Zukav's first book receive?\n",
      "Answer:\u001b[32m American Book Award\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba48440-4a65-41e8-b397-7b79f65fa0fe",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8734a-49a1-4093-a2fb-09bb7d2f2859",
   "metadata": {},
   "source": [
    "Our evaluation metric is a standard one for SQuAD and related tasks: exact match of the answer (EM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f052a79f-ad9f-4f3e-a195-809567e2eea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dspy.evaluate import answer_exact_match\n",
    "from dspy.evaluate.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7341a846-5158-4acf-8aa5-aca61ef40174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_exact_match(dspy.Example(answer=\"STAGE 2!\"), dspy.Prediction(answer=\"stage 2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640e5bf-823f-4cdb-92da-a28f5cea7760",
   "metadata": {},
   "source": [
    "In DSPy, `Evaluate` objects provide a uniform interface for running evaluations. Here are two for us to use in development. The first will evaluate on all of `dev_exs` and should provide a meaningful picture of how a system is doing. It could be expensive to use it a lot, though. The second is for debugging and is probably too small to give a reliable estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6a3b58b-c114-4316-b8d7-2d8049132c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev_evaluater = Evaluate(\n",
    "    devset=dev_exs, # 200 examples\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72fd504e-4684-445d-b0cc-363cd1685b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiny_evaluater = Evaluate(\n",
    "    devset=dev_exs[: 15],\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d88a6c-55b6-4994-9413-1a2301c94903",
   "metadata": {},
   "source": [
    "Here is a tiny (debugging-oriented) evaluation of our few-shot QA sytem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f736065-39f2-4d76-a258-e852767dbb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 15  (13.3): 100%|██████████| 15/15 [00:00<00:00, 105.67it/s]\n",
      "/home/michael/.cache/pypoetry/virtualenvs/cs224u-projects-GPC47Gm_-py3.10/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:142: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 15  (13.3%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2ede th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f2ede td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f2ede_row0_col0, #T_f2ede_row0_col1, #T_f2ede_row0_col2, #T_f2ede_row0_col3, #T_f2ede_row1_col0, #T_f2ede_row1_col1, #T_f2ede_row1_col2, #T_f2ede_row1_col3, #T_f2ede_row2_col0, #T_f2ede_row2_col1, #T_f2ede_row2_col2, #T_f2ede_row2_col3, #T_f2ede_row3_col0, #T_f2ede_row3_col1, #T_f2ede_row3_col2, #T_f2ede_row3_col3, #T_f2ede_row4_col0, #T_f2ede_row4_col1, #T_f2ede_row4_col2, #T_f2ede_row4_col3 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2ede\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f2ede_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_f2ede_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_f2ede_level0_col2\" class=\"col_heading level0 col2\" >pred_answer</th>\n",
       "      <th id=\"T_f2ede_level0_col3\" class=\"col_heading level0 col3\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2ede_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f2ede_row0_col0\" class=\"data row0 col0\" >In 1517 who was Luther's bishop?</td>\n",
       "      <td id=\"T_f2ede_row0_col1\" class=\"data row0 col1\" >Albert of Mainz</td>\n",
       "      <td id=\"T_f2ede_row0_col2\" class=\"data row0 col2\" >Albert of Mainz</td>\n",
       "      <td id=\"T_f2ede_row0_col3\" class=\"data row0 col3\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2ede_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f2ede_row1_col0\" class=\"data row1 col0\" >When was the construction that changed the Rhine's Delta?</td>\n",
       "      <td id=\"T_f2ede_row1_col1\" class=\"data row1 col1\" >20th Century</td>\n",
       "      <td id=\"T_f2ede_row1_col2\" class=\"data row1 col2\" >13th century</td>\n",
       "      <td id=\"T_f2ede_row1_col3\" class=\"data row1 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2ede_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f2ede_row2_col0\" class=\"data row2 col0\" >How many companies were registered in Warsaw in 2006?</td>\n",
       "      <td id=\"T_f2ede_row2_col1\" class=\"data row2 col1\" >304,016</td>\n",
       "      <td id=\"T_f2ede_row2_col2\" class=\"data row2 col2\" >over 100,000</td>\n",
       "      <td id=\"T_f2ede_row2_col3\" class=\"data row2 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2ede_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f2ede_row3_col0\" class=\"data row3 col0\" >What is the CJEU's duty?</td>\n",
       "      <td id=\"T_f2ede_row3_col1\" class=\"data row3 col1\" >to \"ensure that in the interpretation and application of the Treaties the law is observed\"</td>\n",
       "      <td id=\"T_f2ede_row3_col2\" class=\"data row3 col2\" >interpret EU law</td>\n",
       "      <td id=\"T_f2ede_row3_col3\" class=\"data row3 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2ede_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f2ede_row4_col0\" class=\"data row4 col0\" >What would a teacher do for someone who is cocky?</td>\n",
       "      <td id=\"T_f2ede_row4_col1\" class=\"data row4 col1\" >deflate</td>\n",
       "      <td id=\"T_f2ede_row4_col2\" class=\"data row4 col2\" >challenge them</td>\n",
       "      <td id=\"T_f2ede_row4_col3\" class=\"data row4 col3\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc1cb7bb7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 10 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13.33"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_evaluater(basic_fewshot_qa_model, metric=answer_exact_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1b41d-760c-4f28-8a2d-7f037b4f9d97",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4c8f4-a537-4d9b-9500-f881fceef1de",
   "metadata": {},
   "source": [
    "The final major component of our systems is retrieval. When we defined `rm`, we connected to a remote ColBERT index and retriever system that we can now use for search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dfd114-96cf-468a-bac3-d3d39d6f3ca6",
   "metadata": {},
   "source": [
    "The basic `dspy.retrieve` method returns only passages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8f4cafc-f5db-41c0-9561-ecde61331666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = dspy.Retrieve(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "891fc391-c177-4da7-9332-ab20cdba3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = retriever(\"Which award did Gary Zukav's first book receive?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abdac37b-b5fe-421c-826f-4fd699cb2e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    passages=['Gary Zukav | Gary Zukav Gary Zukav (born October 17, 1942) is an American spiritual teacher and the author of four consecutive New York Times Best Sellers. Beginning in 1998, he appeared more than 30 times on \"The Oprah Winfrey Show\" to discuss transformation in human consciousness concepts presented in his book \"The Seat of the Soul\". His first book, \"The Dancing Wu Li Masters\" (1979), won a U.S. National Book Award. Gary Zukav was born in Port Arthur, Texas, and spent his early childhood in San Antonio and Houston. His family moved to Pittsburg, Kansas, while he was in fourth grade. In', 'The Dancing Wu Li Masters | The Dancing Wu Li Masters The Dancing Wu Li Masters is a 1979 book by Gary Zukav, a popular science work exploring modern physics, and quantum phenomena in particular. It was awarded a 1980 U.S. National Book Award in category of Science. Although it explores empirical topics in modern physics research, \"The Dancing Wu Li Masters\" gained attention for leveraging metaphors taken from eastern spiritual movements, in particular the Huayen school of Buddhism with the monk Fazang\\'s treatise on The Golden Lion, to explain quantum phenomena and has been regarded by some reviewers as a New Age work, although the', 'Markus Zusak | a runner-up for the Printz Award in America. \"The Book Thief\" was published in 2005 and has since been translated into more than 30 languages. \"The Book Thief\" was adapted as a film of the same name in 2013. \"The Messenger\" (\"I Am the Messenger\" in the United States) was published in 2002 and was one of Zusak\\'s first novels. This novel has won awards such as the New South Wales Premier\\'s Literary Awards: Ethel Turner Prize for Young People\\'s Literature. In March 2016 Zusak talked about his unfinished novel \"Bridge of Clay.\" He stated that the book was 90%']\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1f577-408c-4ede-9e27-65a24aafca5f",
   "metadata": {},
   "source": [
    "If we need passages with scores and other metadata, we can call `rm` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37f4ff3d-de41-4fc7-8943-6dfd894dd1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pid': 7182463,\n",
       "  'prob': 1.0,\n",
       "  'rank': 1,\n",
       "  'score': 24.77630615234375,\n",
       "  'text': 'Gary Zukav | Gary Zukav Gary Zukav (born October 17, 1942) is an American spiritual teacher and the author of four consecutive New York Times Best Sellers. Beginning in 1998, he appeared more than 30 times on \"The Oprah Winfrey Show\" to discuss transformation in human consciousness concepts presented in his book \"The Seat of the Soul\". His first book, \"The Dancing Wu Li Masters\" (1979), won a U.S. National Book Award. Gary Zukav was born in Port Arthur, Texas, and spent his early childhood in San Antonio and Houston. His family moved to Pittsburg, Kansas, while he was in fourth grade. In',\n",
       "  'long_text': 'Gary Zukav | Gary Zukav Gary Zukav (born October 17, 1942) is an American spiritual teacher and the author of four consecutive New York Times Best Sellers. Beginning in 1998, he appeared more than 30 times on \"The Oprah Winfrey Show\" to discuss transformation in human consciousness concepts presented in his book \"The Seat of the Soul\". His first book, \"The Dancing Wu Li Masters\" (1979), won a U.S. National Book Award. Gary Zukav was born in Port Arthur, Texas, and spent his early childhood in San Antonio and Houston. His family moved to Pittsburg, Kansas, while he was in fourth grade. In'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm(\"Which award did Gary Zukav's first book receive?\", k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2017ee-1375-4251-a24f-7f792852ffac",
   "metadata": {},
   "source": [
    "## Few-shot OpenQA with context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c0997-e624-4fc0-824d-e13066978b0a",
   "metadata": {},
   "source": [
    "Let's build on the above core concepts to define a basic retrieval-augmented generation (RAG) program. This program solves the core task of few-shot OpenQA task and will serve as the basis for the homework questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714dd71-02aa-4e84-840f-807b4e501732",
   "metadata": {},
   "source": [
    "We begin with a signature that takes context into account but is otherwise just like `BasicQASignature` above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcd35bc4-9bbc-4286-ad6b-d7474b51423e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContextQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de481d-d4dd-42c3-99c1-7a112c7f521f",
   "metadata": {},
   "source": [
    "And here is a complete program/system for the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f84481c9-6e6a-4331-a5e1-cf2b9e27b082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=1):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.Predict(ContextQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c4c1ddd-455e-4ad5-b1b1-bf1267364660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag_model = RAG(num_passages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fce28fa-aa8a-4cec-a07a-5365a5eb32df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=['Gary Zukav | Gary Zukav Gary Zukav (born October 17, 1942) is an American spiritual teacher and the author of four consecutive New York Times Best Sellers. Beginning in 1998, he appeared more than 30 times on \"The Oprah Winfrey Show\" to discuss transformation in human consciousness concepts presented in his book \"The Seat of the Soul\". His first book, \"The Dancing Wu Li Masters\" (1979), won a U.S. National Book Award. Gary Zukav was born in Port Arthur, Texas, and spent his early childhood in San Antonio and Houston. His family moved to Pittsburg, Kansas, while he was in fourth grade. In', 'The Dancing Wu Li Masters | The Dancing Wu Li Masters The Dancing Wu Li Masters is a 1979 book by Gary Zukav, a popular science work exploring modern physics, and quantum phenomena in particular. It was awarded a 1980 U.S. National Book Award in category of Science. Although it explores empirical topics in modern physics research, \"The Dancing Wu Li Masters\" gained attention for leveraging metaphors taken from eastern spiritual movements, in particular the Huayen school of Buddhism with the monk Fazang\\'s treatise on The Golden Lion, to explain quantum phenomena and has been regarded by some reviewers as a New Age work, although the', 'Markus Zusak | a runner-up for the Printz Award in America. \"The Book Thief\" was published in 2005 and has since been translated into more than 30 languages. \"The Book Thief\" was adapted as a film of the same name in 2013. \"The Messenger\" (\"I Am the Messenger\" in the United States) was published in 2002 and was one of Zusak\\'s first novels. This novel has won awards such as the New South Wales Premier\\'s Literary Awards: Ethel Turner Prize for Young People\\'s Literature. In March 2016 Zusak talked about his unfinished novel \"Bridge of Clay.\" He stated that the book was 90%'],\n",
       "    answer='U.S. National Book Award'\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_model(question=\"Which award did Gary Zukav's first book receive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873286e4-aaa7-4359-a5f2-04f8cbcceac8",
   "metadata": {},
   "source": [
    "An optional tiny evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25715550-2ba8-44bb-9a11-ca3bc3e0af56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 15  (13.3): 100%|██████████| 15/15 [00:00<00:00, 107.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 15  (13.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/michael/.cache/pypoetry/virtualenvs/cs224u-projects-GPC47Gm_-py3.10/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:142: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7e498 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7e498 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7e498_row0_col0, #T_7e498_row0_col1, #T_7e498_row0_col2, #T_7e498_row0_col3, #T_7e498_row0_col4, #T_7e498_row1_col0, #T_7e498_row1_col1, #T_7e498_row1_col2, #T_7e498_row1_col3, #T_7e498_row1_col4, #T_7e498_row2_col0, #T_7e498_row2_col1, #T_7e498_row2_col2, #T_7e498_row2_col3, #T_7e498_row2_col4, #T_7e498_row3_col0, #T_7e498_row3_col1, #T_7e498_row3_col2, #T_7e498_row3_col3, #T_7e498_row3_col4, #T_7e498_row4_col0, #T_7e498_row4_col1, #T_7e498_row4_col2, #T_7e498_row4_col3, #T_7e498_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7e498\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7e498_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_7e498_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_7e498_level0_col2\" class=\"col_heading level0 col2\" >context</th>\n",
       "      <th id=\"T_7e498_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
       "      <th id=\"T_7e498_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7e498_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7e498_row0_col0\" class=\"data row0 col0\" >In 1517 who was Luther's bishop?</td>\n",
       "      <td id=\"T_7e498_row0_col1\" class=\"data row0 col1\" >Albert of Mainz</td>\n",
       "      <td id=\"T_7e498_row0_col2\" class=\"data row0 col2\" >[\"Paul Speratus | Ellwangen, Priest of the Diocese of Augsburg). Early studies took him to Paris and Italy, as well as (probably) Freiburg and Vienna....</td>\n",
       "      <td id=\"T_7e498_row0_col3\" class=\"data row0 col3\" >George of the Palatinate</td>\n",
       "      <td id=\"T_7e498_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e498_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7e498_row1_col0\" class=\"data row1 col0\" >When was the construction that changed the Rhine's Delta?</td>\n",
       "      <td id=\"T_7e498_row1_col1\" class=\"data row1 col1\" >20th Century</td>\n",
       "      <td id=\"T_7e498_row1_col2\" class=\"data row1 col2\" >['Rhine | rivers and streams. Many rivers have been closed (\"dammed\") and now serve as drainage channels for the numerous polders. The construction of Delta...</td>\n",
       "      <td id=\"T_7e498_row1_col3\" class=\"data row1 col3\" >second half of the 20th Century</td>\n",
       "      <td id=\"T_7e498_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e498_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7e498_row2_col0\" class=\"data row2 col0\" >How many companies were registered in Warsaw in 2006?</td>\n",
       "      <td id=\"T_7e498_row2_col1\" class=\"data row2 col1\" >304,016</td>\n",
       "      <td id=\"T_7e498_row2_col2\" class=\"data row2 col2\" >['Warsaw | such as Sydney, Istanbul, Amsterdam or Seoul. Warsaw, especially its city centre (\"Śródmieście\"), is home not only to many national institutions and government...</td>\n",
       "      <td id=\"T_7e498_row2_col3\" class=\"data row2 col3\" >304,016</td>\n",
       "      <td id=\"T_7e498_row2_col4\" class=\"data row2 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e498_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7e498_row3_col0\" class=\"data row3 col0\" >What is the CJEU's duty?</td>\n",
       "      <td id=\"T_7e498_row3_col1\" class=\"data row3 col1\" >to \"ensure that in the interpretation and application of the Treaties the law is observed\"</td>\n",
       "      <td id=\"T_7e498_row3_col2\" class=\"data row3 col2\" >['European Union law | elected by the judges for three years. While TEU article 19(3) says the Court of Justice is the ultimate court to...</td>\n",
       "      <td id=\"T_7e498_row3_col3\" class=\"data row3 col3\" >To ensure the law is observed.</td>\n",
       "      <td id=\"T_7e498_row3_col4\" class=\"data row3 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e498_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7e498_row4_col0\" class=\"data row4 col0\" >What would a teacher do for someone who is cocky?</td>\n",
       "      <td id=\"T_7e498_row4_col1\" class=\"data row4 col1\" >deflate</td>\n",
       "      <td id=\"T_7e498_row4_col2\" class=\"data row4 col2\" >['Teacher | for the individual students accordingly. For example, an experienced teacher and parent described the place of a teacher in learning as follows: \"The...</td>\n",
       "      <td id=\"T_7e498_row4_col3\" class=\"data row4 col3\" >Deflate the cocky.</td>\n",
       "      <td id=\"T_7e498_row4_col4\" class=\"data row4 col4\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc1ced3fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 10 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13.33"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_evaluater(rag_model, metric=answer_exact_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb28556-d901-4b6b-8a7d-93040203294d",
   "metadata": {},
   "source": [
    "## Question 1: Optimizing RAG [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f481081-3e16-4ccd-b379-c7e0c3011286",
   "metadata": {},
   "source": [
    "We used `RAG` above as a zero-shot system. We could turn it into a few-shot system by using `LabeledFewShot` as we did in [the teleprompting section](#Teleprompting) above, but this may actually be problematic: if we randomly sample demonstrations with retrieved passages, we might be instructing the model with a lot of cases where the context passage isn't helping (and may actually be actively misleading the model). \n",
    "\n",
    "What we'd like to do is select demonstrations where the model gets the answer correct and the context passage does contain the answer. To do this, we will use the DSPy `BootstrapFewShot` optimizer. There are two steps for this: (1) defining a metric and (2) running the optimizer.\n",
    "\n",
    "__Note__: The code for this question can be found in the DSPy tutorials, and you should feel free to make use of that code. The goal is to help you understand the design patterns and overall logic of optimizing DSPy programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ae027-f51a-4607-822f-2a721acde73c",
   "metadata": {},
   "source": [
    "__Task 1__: Complete `validate_context_and_answer` according to the specification in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad09f428-1a68-4cef-9e7a-7c6faf9244a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    \"\"\"Return True if `example.answer` matches `pred.answer` according\n",
    "    to `dspy.evaluate.answer_exact_match` and `pred.context` contains\n",
    "    `example.answer` according to `dspy.evaluate.answer_exact_match`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example: dspy.Example \n",
    "        with attributes `answer` and `context`\n",
    "    pred: dspy.Example \n",
    "        with attributes `answer` and `context`\n",
    "    trace : None (included for dspy internal compatibility)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "\n",
    "    \"\"\"\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0918c5f-2864-4856-adcf-ccb94aca6108",
   "metadata": {},
   "source": [
    "A test you can use to check your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddbca59c-7c11-4e4b-bec3-18a2ecde563b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_validate_context_and_answer(func):\n",
    "    examples = [\n",
    "        (\n",
    "            dspy.Example(question=\"Q1\", answer=\"B\"),\n",
    "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"B\"),\n",
    "            True\n",
    "        ),\n",
    "        # Context doesn't contain answer, but predicted answer is correct.\n",
    "        (\n",
    "            dspy.Example(question=\"Q1\", answer=\"D\"),\n",
    "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"D\"),\n",
    "            False\n",
    "        ),\n",
    "        # Context contains answer, but predicted answer is not correct.\n",
    "        (\n",
    "            dspy.Example(question=\"Q1\", answer=\"C\"),\n",
    "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"D\"),\n",
    "            False\n",
    "        )\n",
    "    ]\n",
    "    errcount = 0\n",
    "    for ex, pred, result in examples:\n",
    "        predicted = func(ex, pred, trace=None)\n",
    "        if predicted != result:\n",
    "            errcount += 1\n",
    "            print(f\"Error for `{func.__name__}`: \"\n",
    "                  f\"Expected inputs\\n\\t{ex}\\n\\t{pred} to return {result}.\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors detected for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38aa3141-ae8f-4bc6-a26e-64d108537612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected for `validate_context_and_answer`\n"
     ]
    }
   ],
   "source": [
    "test_validate_context_and_answer(validate_context_and_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091ca79-ccbe-4429-bfe7-c4f1de118adf",
   "metadata": {
    "tags": []
   },
   "source": [
    "__Task 2__: Complete `bootstrap_optimize` according to the specification in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "129e7e92-033e-4f38-b309-94dac2b66d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "def bootstrap_optimize(model):\n",
    "    \"\"\"Use `BootstrapFewShot` to optimize `model`, with the metric set\n",
    "    to `validate_context_and_answer` as defined above and default\n",
    "    values for all other keyword arguments to `BootstrapFewShot`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: dspy.Module\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dspy.Module, the optimized version of `model`\n",
    "\n",
    "    \"\"\"\n",
    "    return BootstrapFewShot(metric=validate_context_and_answer).compile(model, trainset=dev_exs)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26af22-6d7d-4456-9e30-8f80f5b0b401",
   "metadata": {},
   "source": [
    "A test you can use to check your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30dd9f56-31cc-4e45-8bc2-0fe56c3806a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_bootstrap_optimize(func):\n",
    "    model = RAG()\n",
    "    compiled = func(model)\n",
    "    if not hasattr(compiled, \"_compiled\") or not compiled._compiled:\n",
    "        print(f\"Error for `{func.__name__}`: \"\n",
    "               \"The return value is not a compiled program.\")\n",
    "        return None\n",
    "    state = compiled.dump_state()\n",
    "    if not state['generate_answer']['demos']:\n",
    "        print(f\"Error for `{func.__name__}`: \"\n",
    "               \"The compiled program has no `demos`.\")\n",
    "        return None\n",
    "    print(f\"No errors detected for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "733c1c31-9c68-4d2a-a1c3-4eed0e1caa6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:00<00:01, 119.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 10 examples in round 0.\n",
      "No errors detected for `bootstrap_optimize`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_bootstrap_optimize(bootstrap_optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971ffd0-a563-4d56-a896-0735a63ae92f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2: Multi-passage summarization [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e4d85-05d7-4bc2-beaf-2434d4fe41da",
   "metadata": {},
   "source": [
    "The `dspy.Retrieve` layer in our `RAG` retrieves `k` passages, where `k` is under the control of the user. One hypothesis one might have is that it would be good to summarize these passages before using them as evidence. This seems especially likely to help in scenarios where the question can be answered only by synthesizing information across documents – it might be too much to ask the language model to do both synthesizing and answering in a single step.\n",
    "\n",
    "The current question maps out a basic strategy for summarization. The heart of it is a new signature called `SummarizeSignature`. This can be used on its own with a simple `dspy.Predict` call, and we'll incorporate it into a RAG program in the next question.\n",
    "\n",
    "For this question, though, your task is just to complete `SummarizeSignature`. The requirements are as follows:\n",
    "\n",
    "1. A `__doc__` value that gives an instruction that seems to work well. You can decide what to say here.\n",
    "2. A `dspy.InputField` named `context`. You can decide whether to use the `desc` parameter.\n",
    "3. A `dspy.OutputField` named `summary`. You can decide whether to use the `desc` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7c080a6-d2e1-4d7a-ac60-5ef3a6931ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SummarizeSignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Reply with a short, clear, and concise summary of the key facts and statements from the following text.\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    summary = dspy.OutputField()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6091f20-1cae-4e04-bd50-929271ae6a18",
   "metadata": {},
   "source": [
    "Here's a simple test that just checks for the required pieces in a basic way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "428c971a-2dcd-4344-afa0-8e52938ca4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_SummarizeSignature(sigclass):\n",
    "    fields = sigclass.fields\n",
    "    expected_fieldnames = ['context', 'summary']\n",
    "    fieldnames = sorted([field.input_variable for field in fields])\n",
    "    errcount = 0\n",
    "    if expected_fieldnames != fieldnames:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{sigclass.__name__}`: \"\n",
    "              f\"Expected fieldnames {expected_fieldnames}, got {fieldnames}.\")\n",
    "    if not sigclass.__doc__:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{sigclass.__name__}`: No docstring specified.\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors detected for `{sigclass.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fec39e4d-b3ca-4355-9695-c9f61a24f3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected for `SummarizeSignature`\n"
     ]
    }
   ],
   "source": [
    "test_SummarizeSignature(SummarizeSignature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ee5d0-2bd6-4cb0-873c-21f963a78555",
   "metadata": {},
   "source": [
    "Here is the simplest way to use `SummarizeSignature`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e8129a3-90fb-4810-b18b-84e75525dd16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizer = dspy.Predict(SummarizeSignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8bfdb34-07d8-4488-a1ed-1b4788a2a119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    summary='Context: Information about the Guarani language and its dialects in South America.\\nSummary: Guarani is an indigenous language spoken in Paraguay and neighboring countries, with different dialects like Eastern Bolivian Guarani and Mbyá in Argentina. The language is widely spoken by the Guarani people across South America, with over four million speakers in total.'\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(context=retriever(\"Where is Guarani spoken?\").passages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7a44f-c50d-4674-9fbb-fcf216222e3a",
   "metadata": {},
   "source": [
    "## Question 3: Summarizing RAG [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812e189-2778-442f-81b1-577c303445a8",
   "metadata": {},
   "source": [
    "Your task for this question is to modify `RAG` as defined above so that the retrieved passages are summarized before being passed to `generate_answer`. \n",
    "\n",
    "Here is the `RAG` system copied from above with the class name changed to the one we will use for this new system. Your task is to add the summarization step. This should be very straightforward given the modular design that DSPy supports and encourages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa956847-d6ff-40cf-bf02-9043863e548e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SummarizingRAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        # Please name your summarization later `summarize` so that we\n",
    "        # can check for its presence.\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.summarize = dspy.Predict(SummarizeSignature)\n",
    "        self.generate_answer = dspy.Predict(ContextQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        summary = self.summarize(context=context).summary\n",
    "        prediction = self.generate_answer(context=summary, question=question)\n",
    "        return dspy.Prediction(context=summary, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b65d8-14ca-4dbe-a815-a0d00940b0b4",
   "metadata": {},
   "source": [
    "A simple test for this design spec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "824f063d-1735-4bf3-9337-e9728a5b7800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_SummarizingRAG(classname):\n",
    "    model = classname(num_passages=3)\n",
    "    errcount = 0\n",
    "    if not hasattr(model, \"summarize\"):\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{classname.__name__}`: \"\n",
    "              f\"Expected a layer called 'summarize'\")\n",
    "    context = model.retrieve(\"What are some foods?\").passages\n",
    "    pred = model(\"What are some foods?\")\n",
    "    if context == pred.context:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{classname.__name__}`: \"\n",
    "              \"The model seems to be using raw retrieved contexts \"\n",
    "              \"for predictions rather than summarizing them.\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors detected for `{classname.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e1d38c4-540c-4473-b464-0061b5b8a09c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected for `SummarizingRAG`\n"
     ]
    }
   ],
   "source": [
    "test_SummarizingRAG(SummarizingRAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3b6ad-b960-4b8f-8137-a9b90953b2fc",
   "metadata": {},
   "source": [
    "Model usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95e03778-5a7f-4119-ac62-f4965bfe9a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizing_rag_model = SummarizingRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5077370b-156f-4738-948b-86d832b2ebbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context='Gary Zukav is an American spiritual teacher and author of four New York Times Best Sellers, known for discussing transformation in human consciousness on \"The Oprah Winfrey Show\". His first book, \"The Dancing Wu Li Masters\", won a U.S. National Book Award in 1979. Markus Zusak is an Australian author known for his books \"The Book Thief\" and \"The Messenger\", with \"The Book Thief\" being translated into over 30 languages and adapted into a film in 2013. Zusak has also discussed his unfinished novel \"Bridge of Clay\".',\n",
       "    answer='U.S. National Book Award'\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizing_rag_model(question=\"Which award did Gary Zukav's first book receive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ebc3e9-7baf-4e1c-81a0-8c1e3588a882",
   "metadata": {},
   "source": [
    "Note: if you decide to use `BootstrapFewShot` on this, be sure not to use the metric we defined above, which requires that the passage embeds the correct answer as a substring. Now that we are summarizing, this is unlikely to hold, even if the answers are good ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19655d70-007c-4a41-9f3b-e20df9c5169b",
   "metadata": {},
   "source": [
    "## Question 4: Your original system [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d268f-70e1-4325-a2ff-7361d73788b9",
   "metadata": {},
   "source": [
    "This question asks you to design your own few-shot OpenQA system. All of the code above can be used and modified for this, and the requirement is just that you try something new that goes beyond what we've done so far. \n",
    "\n",
    "Terms for the bake-off:\n",
    "\n",
    "* You can make free use of SQuAD and other publicly available data.\n",
    "\n",
    "* The LM must be an autoregressive language model. No trained QA components can be used. This includes general purpose LMs that have been fine-tuned for QA. (We have obviously waded into some vague territory here. The spirit of this is to make use of frozen, general-purpose models. We welcome questions about exactly how this is defined, since it could be instructive to explore this.)\n",
    "\n",
    "Here are some ideas for the original system:\n",
    "\n",
    "* We have relied almost entirely on `dspy.Predict`. Drop-in replacements include `dspy.ChainOfThought` and `dspy.ReAct`.\n",
    "\n",
    "* We have used only one retriever. DSPy supports other retrieval mechanisms, including retrieval using [You.com](https://you.com/).\n",
    "\n",
    "* DSPy includes additional optimizers. Two that are worth trying are `SignatureOptimizer` for automatic prompt exploration and `BootstrapFewShotWithRandomSearch`, which combines `LabeledFewShot` and `BootstrapFewShot`,\n",
    "\n",
    "* Our one-step summarization procedure from Question 3 doesn't change the query to the retriever. We might want it to change as we gather evidence. This is a common design principle for multi-hop OpenQA systems.\n",
    "\n",
    "__Original system instructions__:\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b557f3c3-ee72-480e-9d99-9095372f99c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 5 traces per predictor.\n",
      "Will attempt to train 3 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 200  (60.0): 100%|██████████| 200/200 [00:07<00:00, 28.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 200  (60.0%)\n",
      "Score: 60.0 for set: [0, 0, 0, 0]\n",
      "New best score: 60.0 for seed -3\n",
      "Scores so far: [60.0]\n",
      "Best score: 60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 200  (60.0): 100%|██████████| 200/200 [00:07<00:00, 28.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 200  (60.0%)\n",
      "Score: 60.0 for set: [5, 5, 5, 5]\n",
      "Scores so far: [60.0, 60.0]\n",
      "Best score: 60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:00<00:00, 352.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 64  (67.2):  32%|███▏      | 63/200 [00:02<00:04, 32.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 200  (59.0): 100%|██████████| 200/200 [00:08<00:00, 22.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 200  (59.0%)\n",
      "Score: 59.0 for set: [5, 5, 5, 5]\n",
      "Scores so far: [60.0, 60.0, 59.0]\n",
      "Best score: 60.0\n",
      "Average of max per entry across top 1 scores: 0.6\n",
      "Average of max per entry across top 2 scores: 0.79\n",
      "Average of max per entry across top 3 scores: 0.855\n",
      "Average of max per entry across top 5 scores: 0.855\n",
      "Average of max per entry across top 8 scores: 0.855\n",
      "Average of max per entry across top 9999 scores: 0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:01, 134.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 95  (67.4):  47%|████▋     | 94/200 [00:03<00:02, 51.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58749, Requested 4811. Please try again in 3.56s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58749, Requested 4811. Please try again in 3.56s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58543, Requested 4872. Please try again in 3.415s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58543, Requested 4872. Please try again in 3.415s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56915, Requested 4872. Please try again in 1.787s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56915, Requested 4872. Please try again in 1.787s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56761, Requested 5003. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56761, Requested 5003. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56756, Requested 4811. Please try again in 1.567s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56756, Requested 4811. Please try again in 1.567s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56468, Requested 4824. Please try again in 1.292s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56468, Requested 4824. Please try again in 1.292s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55452, Requested 4811. Please try again in 263ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55452, Requested 4811. Please try again in 263ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59700, Requested 5003. Please try again in 4.703s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59700, Requested 5003. Please try again in 4.703s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59473, Requested 5021. Please try again in 4.494s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59473, Requested 5021. Please try again in 4.494s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59482, Requested 4678. Please try again in 4.16s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59482, Requested 4678. Please try again in 4.16s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59459, Requested 4824. Please try again in 4.283s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59459, Requested 4824. Please try again in 4.283s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59045, Requested 4678. Please try again in 3.723s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59045, Requested 4678. Please try again in 3.723s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58927, Requested 4824. Please try again in 3.751s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58927, Requested 4824. Please try again in 3.751s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58752, Requested 4811. Please try again in 3.563s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58752, Requested 4811. Please try again in 3.563s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58537, Requested 4678. Please try again in 3.215s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58537, Requested 4678. Please try again in 3.215s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58519, Requested 5021. Please try again in 3.54s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58519, Requested 5021. Please try again in 3.54s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58428, Requested 5003. Please try again in 3.431s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58428, Requested 5003. Please try again in 3.431s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 65 / 96  (67.7):  48%|████▊     | 95/200 [00:09<00:02, 51.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56500, Requested 5021. Please try again in 1.521s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56500, Requested 5021. Please try again in 1.521s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56016, Requested 4811. Please try again in 827ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56016, Requested 4811. Please try again in 827ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.3 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59001, Requested 5021. Please try again in 4.022s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59001, Requested 5021. Please try again in 4.022s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58902, Requested 5003. Please try again in 3.905s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58902, Requested 5003. Please try again in 3.905s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58590, Requested 4678. Please try again in 3.268s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58590, Requested 4678. Please try again in 3.268s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58377, Requested 4824. Please try again in 3.201s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58377, Requested 4824. Please try again in 3.201s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56811, Requested 4482. Please try again in 1.293s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56811, Requested 4482. Please try again in 1.293s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55930, Requested 4482. Please try again in 412ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55930, Requested 4482. Please try again in 412ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 65 / 96  (67.7):  48%|████▊     | 96/200 [00:14<00:02, 51.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55205, Requested 4811. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 17.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55205, Requested 4811. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 17.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58425, Requested 5021. Please try again in 3.446s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58425, Requested 5021. Please try again in 3.446s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.1 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 97  (68.0):  48%|████▊     | 97/200 [00:16<01:15,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57000, Requested 5003. Please try again in 2.003s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57000, Requested 5003. Please try again in 2.003s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.8 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59129, Requested 4678. Please try again in 3.807s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59129, Requested 4678. Please try again in 3.807s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.3 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58822, Requested 4824. Please try again in 3.646s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58822, Requested 4824. Please try again in 3.646s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.8 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56791, Requested 4859. Please try again in 1.65s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56791, Requested 4859. Please try again in 1.65s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56025, Requested 4859. Please try again in 884ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56025, Requested 4859. Please try again in 884ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55703, Requested 4859. Please try again in 562ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55703, Requested 4859. Please try again in 562ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 98  (68.4):  49%|████▉     | 98/200 [00:23<01:51,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58021, Requested 4824. Please try again in 2.845s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58021, Requested 4824. Please try again in 2.845s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.9 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57010, Requested 3274. Please try again in 284ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57010, Requested 3274. Please try again in 284ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56650, Requested 4859. Please try again in 1.509s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56650, Requested 4859. Please try again in 1.509s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.5 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56656, Requested 4874. Please try again in 1.53s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56656, Requested 4874. Please try again in 1.53s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55973, Requested 4874. Please try again in 847ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55973, Requested 4874. Please try again in 847ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58665, Requested 4859. Please try again in 3.524s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58665, Requested 4859. Please try again in 3.524s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 68 / 99  (68.7):  49%|████▉     | 98/200 [00:31<01:51,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58098, Requested 5021. Please try again in 3.119s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 14.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58098, Requested 5021. Please try again in 3.119s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 14.1 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57484, Requested 4824. Please try again in 2.308s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 34.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57484, Requested 4824. Please try again in 2.308s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 34.4 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56638, Requested 4811. Please try again in 1.449s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56638, Requested 4811. Please try again in 1.449s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59019, Requested 4811. Please try again in 3.83s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 107.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59019, Requested 4811. Please try again in 3.83s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 107.0 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59021, Requested 5003. Please try again in 4.024s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59021, Requested 5003. Please try again in 4.024s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 68 / 99  (68.7):  50%|████▉     | 99/200 [00:34<01:50,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57181, Requested 4859. Please try again in 2.04s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57181, Requested 4859. Please try again in 2.04s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56929, Requested 4723. Please try again in 1.652s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56929, Requested 4723. Please try again in 1.652s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55921, Requested 4723. Please try again in 644ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55921, Requested 4723. Please try again in 644ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57556, Requested 5003. Please try again in 2.559s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 62.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57556, Requested 5003. Please try again in 2.559s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 62.5 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 69 / 100  (69.0):  50%|█████     | 100/200 [00:39<03:43,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58680, Requested 5021. Please try again in 3.701s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58680, Requested 5021. Please try again in 3.701s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 101  (69.3):  50%|█████     | 101/200 [00:47<04:30,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57206, Requested 5021. Please try again in 2.227s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 88.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57206, Requested 5021. Please try again in 2.227s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 88.5 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56587, Requested 4866. Please try again in 1.453s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56587, Requested 4866. Please try again in 1.453s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56048, Requested 4859. Please try again in 907ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 38.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56048, Requested 4859. Please try again in 907ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 38.0 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55780, Requested 4866. Please try again in 646ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55780, Requested 4866. Please try again in 646ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55247, Requested 4866. Please try again in 113ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55247, Requested 4866. Please try again in 113ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72 / 103  (69.9):  52%|█████▏    | 103/200 [01:04<04:25,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56845, Requested 4674. Please try again in 1.519s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56845, Requested 4674. Please try again in 1.519s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56347, Requested 4674. Please try again in 1.021s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56347, Requested 4674. Please try again in 1.021s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59473, Requested 4824. Please try again in 4.297s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 22.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59473, Requested 4824. Please try again in 4.297s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 22.0 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 104  (70.2):  52%|█████▏    | 104/200 [01:07<06:19,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57526, Requested 3265. Please try again in 791ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57526, Requested 3265. Please try again in 791ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57227, Requested 3265. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57227, Requested 3265. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56740, Requested 4889. Please try again in 1.629s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56740, Requested 4889. Please try again in 1.629s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56361, Requested 4889. Please try again in 1.25s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56361, Requested 4889. Please try again in 1.25s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55506, Requested 4889. Please try again in 395ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55506, Requested 4889. Please try again in 395ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 106  (68.9):  53%|█████▎    | 106/200 [01:23<07:38,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56855, Requested 4503. Please try again in 1.358s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56855, Requested 4503. Please try again in 1.358s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55720, Requested 4503. Please try again in 223ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55720, Requested 4503. Please try again in 223ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59385, Requested 4859. Please try again in 4.244s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 81.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59385, Requested 4859. Please try again in 4.244s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 81.8 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 107  (68.2):  53%|█████▎    | 106/200 [01:30<07:38,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57899, Requested 4503. Please try again in 2.402s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57899, Requested 4503. Please try again in 2.402s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57490, Requested 3234. Please try again in 724ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57490, Requested 3234. Please try again in 724ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57146, Requested 4503. Please try again in 1.649s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57146, Requested 4503. Please try again in 1.649s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.5 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56974, Requested 3234. Please try again in 208ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56974, Requested 3234. Please try again in 208ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 107  (68.2):  54%|█████▎    | 107/200 [01:34<07:33,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55966, Requested 4505. Please try again in 470ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55966, Requested 4505. Please try again in 470ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58620, Requested 4503. Please try again in 3.123s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58620, Requested 4503. Please try again in 3.123s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 108  (68.5):  54%|█████▍    | 108/200 [01:37<08:21,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.4 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57461, Requested 4486. Please try again in 1.947s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57461, Requested 4486. Please try again in 1.947s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56637, Requested 4486. Please try again in 1.123s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56637, Requested 4486. Please try again in 1.123s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56006, Requested 5003. Please try again in 1.009s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 83.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56006, Requested 5003. Please try again in 1.009s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 83.6 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55584, Requested 4503. Please try again in 87ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 31.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55584, Requested 4503. Please try again in 87ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 31.1 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 75 / 109  (68.8):  55%|█████▍    | 109/200 [01:44<08:38,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57293, Requested 3242. Please try again in 535ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57293, Requested 3242. Please try again in 535ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56854, Requested 3242. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56854, Requested 3242. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55359, Requested 5038. Please try again in 397ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55359, Requested 5038. Please try again in 397ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 110  (69.1):  55%|█████▌    | 110/200 [01:54<08:32,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56726, Requested 4826. Please try again in 1.552s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56726, Requested 4826. Please try again in 1.552s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55873, Requested 4826. Please try again in 699ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55873, Requested 4826. Please try again in 699ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 111  (68.5):  56%|█████▌    | 111/200 [01:58<09:16,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57154, Requested 3218. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57154, Requested 3218. Please try again in 372ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57297, Requested 4806. Please try again in 2.103s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57297, Requested 4806. Please try again in 2.103s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56251, Requested 4806. Please try again in 1.057s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56251, Requested 4806. Please try again in 1.057s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55655, Requested 4806. Please try again in 461ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55655, Requested 4806. Please try again in 461ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77 / 112  (68.8):  56%|█████▌    | 112/200 [02:07<09:51,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57293, Requested 4820. Please try again in 2.113s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57293, Requested 4820. Please try again in 2.113s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56763, Requested 4820. Please try again in 1.583s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56763, Requested 4820. Please try again in 1.583s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55449, Requested 4820. Please try again in 269ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55449, Requested 4820. Please try again in 269ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 113  (69.0):  56%|█████▋    | 113/200 [02:14<09:41,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58055, Requested 4503. Please try again in 2.558s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 44.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58055, Requested 4503. Please try again in 2.558s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 44.9 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57308, Requested 3229. Please try again in 537ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57308, Requested 3229. Please try again in 537ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59681, Requested 5021. Please try again in 4.702s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 21.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59681, Requested 5021. Please try again in 4.702s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 21.8 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57788, Requested 4500. Please try again in 2.288s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57788, Requested 4500. Please try again in 2.288s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57451, Requested 4500. Please try again in 1.951s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57451, Requested 4500. Please try again in 1.951s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56002, Requested 4500. Please try again in 502ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56002, Requested 4500. Please try again in 502ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58555, Requested 4500. Please try again in 3.055s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58555, Requested 4500. Please try again in 3.055s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 114  (68.4):  57%|█████▋    | 114/200 [02:22<10:09,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58382, Requested 4500. Please try again in 2.882s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58382, Requested 4500. Please try again in 2.882s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.5 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56301, Requested 4704. Please try again in 1.005s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56301, Requested 4704. Please try again in 1.005s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55678, Requested 4704. Please try again in 382ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55678, Requested 4704. Please try again in 382ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 79 / 115  (68.7):  57%|█████▊    | 115/200 [02:28<09:35,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58108, Requested 4704. Please try again in 2.812s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58108, Requested 4704. Please try again in 2.812s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57084, Requested 3215. Please try again in 299ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57084, Requested 3215. Please try again in 299ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57593, Requested 4704. Please try again in 2.297s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57593, Requested 4704. Please try again in 2.297s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57063, Requested 4801. Please try again in 1.864s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57063, Requested 4801. Please try again in 1.864s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56439, Requested 4801. Please try again in 1.24s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56439, Requested 4801. Please try again in 1.24s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 116  (69.0):  58%|█████▊    | 116/200 [02:35<09:43,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58292, Requested 4704. Please try again in 2.996s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58292, Requested 4704. Please try again in 2.996s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.1 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57551, Requested 3216. Please try again in 767ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57551, Requested 3216. Please try again in 767ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59504, Requested 5021. Please try again in 4.525s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 278.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59504, Requested 5021. Please try again in 4.525s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 278.6 seconds after 10 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57980, Requested 4647. Please try again in 2.627s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57980, Requested 4647. Please try again in 2.627s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56767, Requested 4647. Please try again in 1.414s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56767, Requested 4647. Please try again in 1.414s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55479, Requested 4647. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55479, Requested 4647. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59106, Requested 4704. Please try again in 3.81s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59106, Requested 4704. Please try again in 3.81s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.2 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 117  (68.4):  58%|█████▊    | 117/200 [02:43<09:46,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57572, Requested 4849. Please try again in 2.421s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57572, Requested 4849. Please try again in 2.421s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57264, Requested 4849. Please try again in 2.113s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57264, Requested 4849. Please try again in 2.113s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55584, Requested 4849. Please try again in 433ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55584, Requested 4849. Please try again in 433ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 118  (67.8):  59%|█████▉    | 118/200 [02:50<09:42,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58134, Requested 4704. Please try again in 2.838s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 62.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58134, Requested 4704. Please try again in 2.838s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 62.4 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57845, Requested 4859. Please try again in 2.704s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 248.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57845, Requested 4859. Please try again in 2.704s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 248.1 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 121  (67.8):  60%|██████    | 121/200 [03:07<07:13,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57546, Requested 3229. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57546, Requested 3229. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56966, Requested 3238. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56966, Requested 3238. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59023, Requested 3238. Please try again in 2.261s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59023, Requested 3238. Please try again in 2.261s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57157, Requested 4831. Please try again in 1.988s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57157, Requested 4831. Please try again in 1.988s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56977, Requested 3238. Please try again in 215ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56977, Requested 3238. Please try again in 215ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56835, Requested 4831. Please try again in 1.666s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56835, Requested 4831. Please try again in 1.666s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56119, Requested 4831. Please try again in 950ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56119, Requested 4831. Please try again in 950ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55708, Requested 4831. Please try again in 539ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55708, Requested 4831. Please try again in 539ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 122  (68.0):  61%|██████    | 122/200 [03:18<09:10,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56738, Requested 3308. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56738, Requested 3308. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56271, Requested 4940. Please try again in 1.211s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56271, Requested 4940. Please try again in 1.211s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55631, Requested 4940. Please try again in 571ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55631, Requested 4940. Please try again in 571ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 123  (67.5):  62%|██████▏   | 123/200 [03:24<08:53,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58452, Requested 4940. Please try again in 3.392s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58452, Requested 4940. Please try again in 3.392s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57071, Requested 3277. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57071, Requested 3277. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56298, Requested 4940. Please try again in 1.238s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56298, Requested 4940. Please try again in 1.238s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57428, Requested 4727. Please try again in 2.155s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57428, Requested 4727. Please try again in 2.155s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56988, Requested 4727. Please try again in 1.715s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56988, Requested 4727. Please try again in 1.715s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55878, Requested 4727. Please try again in 605ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55878, Requested 4727. Please try again in 605ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 124  (67.7):  62%|██████▏   | 124/200 [03:32<09:02,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58379, Requested 4727. Please try again in 3.106s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58379, Requested 4727. Please try again in 3.106s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57383, Requested 3230. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57383, Requested 3230. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59592, Requested 3230. Please try again in 2.822s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59592, Requested 3230. Please try again in 2.822s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58787, Requested 3230. Please try again in 2.017s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58787, Requested 3230. Please try again in 2.017s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57089, Requested 4665. Please try again in 1.754s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57089, Requested 4665. Please try again in 1.754s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59541, Requested 4665. Please try again in 4.206s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59541, Requested 4665. Please try again in 4.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56910, Requested 4665. Please try again in 1.575s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56910, Requested 4665. Please try again in 1.575s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56848, Requested 4843. Please try again in 1.691s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56848, Requested 4843. Please try again in 1.691s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56020, Requested 4843. Please try again in 863ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56020, Requested 4843. Please try again in 863ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55988, Requested 4727. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55988, Requested 4727. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55723, Requested 4843. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55723, Requested 4843. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59143, Requested 4843. Please try again in 3.986s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59143, Requested 4843. Please try again in 3.986s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 125  (68.0):  62%|██████▎   | 125/200 [03:42<10:01,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56975, Requested 3240. Please try again in 215ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56975, Requested 3240. Please try again in 215ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56703, Requested 4843. Please try again in 1.546s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56703, Requested 4843. Please try again in 1.546s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57910, Requested 4511. Please try again in 2.421s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57910, Requested 4511. Please try again in 2.421s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57492, Requested 4511. Please try again in 2.003s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57492, Requested 4511. Please try again in 2.003s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56833, Requested 4843. Please try again in 1.676s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 24.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56833, Requested 4843. Please try again in 1.676s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 24.2 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56656, Requested 4511. Please try again in 1.167s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56656, Requested 4511. Please try again in 1.167s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 126  (67.5):  63%|██████▎   | 126/200 [03:51<10:12,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56851, Requested 4891. Please try again in 1.742s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56851, Requested 4891. Please try again in 1.742s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56811, Requested 4704. Please try again in 1.515s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 110.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56811, Requested 4704. Please try again in 1.515s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 110.2 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56195, Requested 4891. Please try again in 1.086s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56195, Requested 4891. Please try again in 1.086s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58978, Requested 4891. Please try again in 3.869s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58978, Requested 4891. Please try again in 3.869s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 127  (67.7):  64%|██████▎   | 127/200 [03:57<09:06,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58031, Requested 4891. Please try again in 2.922s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58031, Requested 4891. Please try again in 2.922s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57530, Requested 4866. Please try again in 2.396s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57530, Requested 4866. Please try again in 2.396s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57485, Requested 4891. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57485, Requested 4891. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56864, Requested 4866. Please try again in 1.73s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56864, Requested 4866. Please try again in 1.73s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56232, Requested 4866. Please try again in 1.098s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56232, Requested 4866. Please try again in 1.098s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55303, Requested 4891. Please try again in 194ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55303, Requested 4891. Please try again in 194ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.6 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 128  (67.2):  64%|██████▍   | 128/200 [04:06<09:36,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55884, Requested 4891. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 51.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55884, Requested 4891. Please try again in 775ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 51.9 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55335, Requested 4824. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55335, Requested 4824. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58900, Requested 4843. Please try again in 3.743s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58900, Requested 4843. Please try again in 3.743s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 129  (66.7):  64%|██████▍   | 129/200 [04:11<08:40,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56975, Requested 4843. Please try again in 1.818s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 72.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56975, Requested 4843. Please try again in 1.818s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 72.9 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56751, Requested 3276. Please try again in 27ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56751, Requested 3276. Please try again in 27ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56942, Requested 4705. Please try again in 1.647s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56942, Requested 4705. Please try again in 1.647s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56395, Requested 4705. Please try again in 1.1s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56395, Requested 4705. Please try again in 1.1s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 130  (66.2):  65%|██████▌   | 130/200 [04:19<08:34,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57658, Requested 4628. Please try again in 2.286s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57658, Requested 4628. Please try again in 2.286s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56708, Requested 4628. Please try again in 1.336s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56708, Requested 4628. Please try again in 1.336s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 131  (65.6):  66%|██████▌   | 131/200 [04:25<08:09,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57694, Requested 4323. Please try again in 2.017s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57694, Requested 4323. Please try again in 2.017s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57410, Requested 4323. Please try again in 1.733s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57410, Requested 4323. Please try again in 1.733s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56422, Requested 4323. Please try again in 745ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56422, Requested 4323. Please try again in 745ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 132  (65.2):  66%|██████▌   | 132/200 [04:35<08:46,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55719, Requested 4648. Please try again in 367ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55719, Requested 4648. Please try again in 367ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 133  (64.7):  66%|██████▋   | 133/200 [04:40<07:43,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57140, Requested 3219. Please try again in 359ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57140, Requested 3219. Please try again in 359ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57246, Requested 4670. Please try again in 1.916s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57246, Requested 4670. Please try again in 1.916s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56251, Requested 4670. Please try again in 921ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56251, Requested 4670. Please try again in 921ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55343, Requested 4670. Please try again in 13ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55343, Requested 4670. Please try again in 13ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 134  (64.9):  67%|██████▋   | 134/200 [04:48<07:56,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56594, Requested 4823. Please try again in 1.417s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56594, Requested 4823. Please try again in 1.417s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55643, Requested 4823. Please try again in 466ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55643, Requested 4823. Please try again in 466ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87 / 135  (64.4):  68%|██████▊   | 135/200 [04:54<07:41,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56894, Requested 3218. Please try again in 112ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56894, Requested 3218. Please try again in 112ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56569, Requested 4796. Please try again in 1.365s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56569, Requested 4796. Please try again in 1.365s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56026, Requested 4796. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56026, Requested 4796. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59187, Requested 4796. Please try again in 3.983s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59187, Requested 4796. Please try again in 3.983s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 136  (64.7):  68%|██████▊   | 136/200 [05:02<07:53,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56219, Requested 4796. Please try again in 1.015s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56219, Requested 4796. Please try again in 1.015s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58346, Requested 4796. Please try again in 3.142s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 14.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58346, Requested 4796. Please try again in 3.142s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 14.7 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 137  (64.2):  68%|██████▊   | 137/200 [05:10<07:56,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55808, Requested 4831. Please try again in 639ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55808, Requested 4831. Please try again in 639ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55216, Requested 4831. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55216, Requested 4831. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 138  (64.5):  69%|██████▉   | 138/200 [05:17<07:36,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57566, Requested 4796. Please try again in 2.362s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 31.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57566, Requested 4796. Please try again in 2.362s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 31.8 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56937, Requested 4675. Please try again in 1.612s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56937, Requested 4675. Please try again in 1.612s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56055, Requested 4675. Please try again in 730ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56055, Requested 4675. Please try again in 730ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 139  (64.7):  70%|██████▉   | 139/200 [05:24<07:18,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59697, Requested 4843. Please try again in 4.54s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 189.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59697, Requested 4843. Please try again in 4.54s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 189.1 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58132, Requested 4718. Please try again in 2.85s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58132, Requested 4718. Please try again in 2.85s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57193, Requested 4718. Please try again in 1.911s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57193, Requested 4718. Please try again in 1.911s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56559, Requested 4718. Please try again in 1.277s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56559, Requested 4718. Please try again in 1.277s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 140  (65.0):  70%|███████   | 140/200 [05:33<07:41,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55635, Requested 4816. Please try again in 451ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55635, Requested 4816. Please try again in 451ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 141  (65.2):  70%|███████   | 141/200 [05:38<06:51,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56907, Requested 3272. Please try again in 179ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56907, Requested 3272. Please try again in 179ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56572, Requested 4881. Please try again in 1.453s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56572, Requested 4881. Please try again in 1.453s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55458, Requested 4704. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 182.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55458, Requested 4704. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 182.3 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55400, Requested 4881. Please try again in 281ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55400, Requested 4881. Please try again in 281ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 142  (65.5):  71%|███████   | 142/200 [05:47<07:15,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56160, Requested 4528. Please try again in 688ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56160, Requested 4528. Please try again in 688ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59162, Requested 4796. Please try again in 3.958s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 28.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59162, Requested 4796. Please try again in 3.958s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 28.8 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 143  (65.7):  72%|███████▏  | 143/200 [05:53<06:38,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57504, Requested 4664. Please try again in 2.168s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57504, Requested 4664. Please try again in 2.168s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56567, Requested 4664. Please try again in 1.231s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56567, Requested 4664. Please try again in 1.231s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55943, Requested 4664. Please try again in 607ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55943, Requested 4664. Please try again in 607ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 144  (65.3):  72%|███████▏  | 144/200 [06:01<06:57,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56558, Requested 4799. Please try again in 1.357s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56558, Requested 4799. Please try again in 1.357s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55646, Requested 4799. Please try again in 445ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55646, Requested 4799. Please try again in 445ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 145  (64.8):  72%|███████▎  | 145/200 [06:08<06:44,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56160, Requested 4671. Please try again in 831ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56160, Requested 4671. Please try again in 831ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 146  (65.1):  73%|███████▎  | 146/200 [06:15<06:19,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57066, Requested 3231. Please try again in 297ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57066, Requested 3231. Please try again in 297ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58005, Requested 4664. Please try again in 2.669s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58005, Requested 4664. Please try again in 2.669s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57185, Requested 4664. Please try again in 1.849s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57185, Requested 4664. Please try again in 1.849s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59376, Requested 4796. Please try again in 4.172s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 89.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59376, Requested 4796. Please try again in 4.172s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 89.5 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 147  (64.6):  74%|███████▎  | 147/200 [06:22<06:16,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57093, Requested 3293. Please try again in 386ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57093, Requested 3293. Please try again in 386ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56513, Requested 4907. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56513, Requested 4907. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56236, Requested 4907. Please try again in 1.143s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56236, Requested 4907. Please try again in 1.143s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 148  (64.9):  74%|███████▍  | 148/200 [06:30<06:22,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57336, Requested 4661. Please try again in 1.997s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57336, Requested 4661. Please try again in 1.997s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56869, Requested 4661. Please try again in 1.53s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56869, Requested 4661. Please try again in 1.53s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 149  (65.1):  74%|███████▍  | 149/200 [06:37<06:04,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57026, Requested 4660. Please try again in 1.686s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57026, Requested 4660. Please try again in 1.686s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56499, Requested 4660. Please try again in 1.159s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56499, Requested 4660. Please try again in 1.159s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56237, Requested 4660. Please try again in 897ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56237, Requested 4660. Please try again in 897ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 98 / 150  (65.3):  75%|███████▌  | 150/200 [06:46<06:25,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55743, Requested 4830. Please try again in 573ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55743, Requested 4830. Please try again in 573ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55387, Requested 4830. Please try again in 217ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55387, Requested 4830. Please try again in 217ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 98 / 152  (64.5):  76%|███████▌  | 152/200 [07:00<06:03,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56434, Requested 4498. Please try again in 932ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56434, Requested 4498. Please try again in 932ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55826, Requested 4498. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55826, Requested 4498. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 153  (64.7):  76%|███████▋  | 153/200 [07:07<05:40,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56910, Requested 4819. Please try again in 1.729s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56910, Requested 4819. Please try again in 1.729s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56500, Requested 4819. Please try again in 1.319s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56500, Requested 4819. Please try again in 1.319s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56142, Requested 4819. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56142, Requested 4819. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 154  (64.3):  77%|███████▋  | 154/200 [07:15<05:51,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55505, Requested 5021. Please try again in 526ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 10.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55505, Requested 5021. Please try again in 526ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 10.4 seconds after 11 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55551, Requested 4876. Please try again in 427ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55551, Requested 4876. Please try again in 427ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 155  (63.9):  78%|███████▊  | 155/200 [07:21<05:20,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56839, Requested 3207. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56839, Requested 3207. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56892, Requested 4762. Please try again in 1.654s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56892, Requested 4762. Please try again in 1.654s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56288, Requested 4762. Please try again in 1.05s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56288, Requested 4762. Please try again in 1.05s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55021, Requested 5021. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 560.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55021, Requested 5021. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 560.2 seconds after 12 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 156  (64.1):  78%|███████▊  | 156/200 [07:28<05:11,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56794, Requested 3264. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56794, Requested 3264. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56961, Requested 4535. Please try again in 1.496s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56961, Requested 4535. Please try again in 1.496s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56495, Requested 4535. Please try again in 1.03s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56495, Requested 4535. Please try again in 1.03s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55963, Requested 4535. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55963, Requested 4535. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 157  (63.7):  78%|███████▊  | 157/200 [07:37<05:26,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56767, Requested 4685. Please try again in 1.452s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56767, Requested 4685. Please try again in 1.452s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56278, Requested 4685. Please try again in 962ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56278, Requested 4685. Please try again in 962ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55883, Requested 4685. Please try again in 568ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55883, Requested 4685. Please try again in 568ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 158  (63.3):  79%|███████▉  | 158/200 [07:45<05:18,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56712, Requested 4536. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56712, Requested 4536. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56446, Requested 4536. Please try again in 982ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56446, Requested 4536. Please try again in 982ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56088, Requested 4536. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56088, Requested 4536. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57523, Requested 4796. Please try again in 2.319s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 42.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57523, Requested 4796. Please try again in 2.319s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 159  (63.5):  80%|███████▉  | 159/200 [07:51<04:59,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 42.0 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56775, Requested 4787. Please try again in 1.562s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56775, Requested 4787. Please try again in 1.562s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55833, Requested 4787. Please try again in 620ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55833, Requested 4787. Please try again in 620ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55277, Requested 4787. Please try again in 64ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55277, Requested 4787. Please try again in 64ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 102 / 161  (63.4):  80%|████████  | 161/200 [08:05<04:33,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57484, Requested 4822. Please try again in 2.306s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57484, Requested 4822. Please try again in 2.306s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56447, Requested 4822. Please try again in 1.269s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56447, Requested 4822. Please try again in 1.269s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58928, Requested 4822. Please try again in 3.75s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58928, Requested 4822. Please try again in 3.75s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57320, Requested 4996. Please try again in 2.316s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57320, Requested 4996. Please try again in 2.316s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56963, Requested 4822. Please try again in 1.785s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56963, Requested 4822. Please try again in 1.785s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56564, Requested 4996. Please try again in 1.56s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56564, Requested 4996. Please try again in 1.56s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55686, Requested 4996. Please try again in 682ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55686, Requested 4996. Please try again in 682ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55166, Requested 4996. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55166, Requested 4996. Please try again in 162ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 162  (63.6):  81%|████████  | 162/200 [08:12<04:22,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56955, Requested 3222. Please try again in 177ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56955, Requested 3222. Please try again in 177ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56746, Requested 4996. Please try again in 1.742s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 10.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56746, Requested 4996. Please try again in 1.742s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 10.5 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56327, Requested 4853. Please try again in 1.18s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56327, Requested 4853. Please try again in 1.18s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55640, Requested 4853. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55640, Requested 4853. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 163  (63.8):  82%|████████▏ | 163/200 [08:19<04:25,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57183, Requested 4872. Please try again in 2.055s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57183, Requested 4872. Please try again in 2.055s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56912, Requested 4872. Please try again in 1.784s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56912, Requested 4872. Please try again in 1.784s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56096, Requested 4872. Please try again in 968ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56096, Requested 4872. Please try again in 968ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57935, Requested 4872. Please try again in 2.807s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57935, Requested 4872. Please try again in 2.807s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 164  (64.0):  82%|████████▏ | 164/200 [08:28<04:32,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57158, Requested 4758. Please try again in 1.916s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57158, Requested 4758. Please try again in 1.916s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56379, Requested 4758. Please try again in 1.137s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56379, Requested 4758. Please try again in 1.137s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55401, Requested 4758. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55401, Requested 4758. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 106 / 165  (64.2):  82%|████████▎ | 165/200 [08:34<04:14,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57240, Requested 4843. Please try again in 2.083s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 201.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57240, Requested 4843. Please try again in 2.083s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 201.0 seconds after 10 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57090, Requested 4758. Please try again in 1.848s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57077, Requested 4872. Please try again in 1.949s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57090, Requested 4758. Please try again in 1.848s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "_log_backoff - INFO - Backing off request(...) for 7.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57077, Requested 4872. Please try again in 1.949s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.7 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57254, Requested 4861. Please try again in 2.115s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57254, Requested 4861. Please try again in 2.115s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56760, Requested 4861. Please try again in 1.621s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56760, Requested 4861. Please try again in 1.621s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56228, Requested 4758. Please try again in 986ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 11.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56228, Requested 4758. Please try again in 986ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 11.5 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55298, Requested 4861. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55298, Requested 4861. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 107 / 166  (64.5):  83%|████████▎ | 166/200 [08:42<04:13,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59613, Requested 4872. Please try again in 4.485s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 19.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59613, Requested 4872. Please try again in 4.485s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 19.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57711, Requested 4783. Please try again in 2.494s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57711, Requested 4783. Please try again in 2.494s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57253, Requested 4783. Please try again in 2.036s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57253, Requested 4783. Please try again in 2.036s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55861, Requested 4704. Please try again in 565ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 436.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55861, Requested 4704. Please try again in 565ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 436.1 seconds after 10 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55694, Requested 4783. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55694, Requested 4783. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56773, Requested 4758. Please try again in 1.531s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 12.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56773, Requested 4758. Please try again in 1.531s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 12.9 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 109 / 168  (64.9):  84%|████████▍ | 168/200 [08:56<03:37,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57480, Requested 4527. Please try again in 2.007s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57480, Requested 4527. Please try again in 2.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56328, Requested 4527. Please try again in 855ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56328, Requested 4527. Please try again in 855ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58666, Requested 4872. Please try again in 3.538s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58666, Requested 4872. Please try again in 3.538s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.9 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58162, Requested 4758. Please try again in 2.92s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 17.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58162, Requested 4758. Please try again in 2.92s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 169  (65.1):  84%|████████▍ | 169/200 [09:04<03:44,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 17.2 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58043, Requested 4506. Please try again in 2.549s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58043, Requested 4506. Please try again in 2.549s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57751, Requested 4506. Please try again in 2.257s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57751, Requested 4506. Please try again in 2.257s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56060, Requested 4506. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56060, Requested 4506. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 171  (64.9):  86%|████████▌ | 171/200 [09:18<03:18,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56974, Requested 3230. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56974, Requested 3230. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56646, Requested 4872. Please try again in 1.518s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 74.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56646, Requested 4872. Please try again in 1.518s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 74.4 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57706, Requested 4758. Please try again in 2.464s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 119.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57706, Requested 4758. Please try again in 2.464s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 119.4 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56951, Requested 4649. Please try again in 1.6s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56951, Requested 4649. Please try again in 1.6s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56590, Requested 4649. Please try again in 1.239s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56590, Requested 4649. Please try again in 1.239s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 173  (64.7):  86%|████████▋ | 173/200 [09:33<03:12,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57339, Requested 4840. Please try again in 2.179s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57339, Requested 4840. Please try again in 2.179s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56643, Requested 4840. Please try again in 1.483s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56643, Requested 4840. Please try again in 1.483s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56098, Requested 4840. Please try again in 938ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56098, Requested 4840. Please try again in 938ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 174  (64.4):  87%|████████▋ | 174/200 [09:42<03:19,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56226, Requested 4488. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56226, Requested 4488. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 113 / 175  (64.6):  88%|████████▊ | 175/200 [09:46<02:49,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57066, Requested 3262. Please try again in 328ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57066, Requested 3262. Please try again in 328ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57421, Requested 4698. Please try again in 2.119s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57421, Requested 4698. Please try again in 2.119s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56889, Requested 4698. Please try again in 1.587s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56889, Requested 4698. Please try again in 1.587s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55885, Requested 4698. Please try again in 583ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55885, Requested 4698. Please try again in 583ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 176  (64.8):  88%|████████▊ | 176/200 [09:53<02:44,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57462, Requested 3217. Please try again in 679ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57462, Requested 3217. Please try again in 679ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57048, Requested 3217. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57048, Requested 3217. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56358, Requested 4645. Please try again in 1.003s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56358, Requested 4645. Please try again in 1.003s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56070, Requested 4645. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56070, Requested 4645. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55413, Requested 4645. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55413, Requested 4645. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 182  (63.2):  91%|█████████ | 182/200 [10:45<01:33,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55811, Requested 4668. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55811, Requested 4668. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 116 / 183  (63.4):  92%|█████████▏| 183/200 [10:49<01:23,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58461, Requested 3181. Please try again in 1.642s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58461, Requested 3181. Please try again in 1.642s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 184  (63.6):  92%|█████████▏| 184/200 [10:51<01:03,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57265, Requested 3181. Please try again in 446ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57265, Requested 3181. Please try again in 446ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59387, Requested 3235. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59387, Requested 3235. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57915, Requested 3235. Please try again in 1.15s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57915, Requested 3235. Please try again in 1.15s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57675, Requested 3235. Please try again in 910ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57675, Requested 3235. Please try again in 910ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57469, Requested 4762. Please try again in 2.231s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57469, Requested 4762. Please try again in 2.231s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56552, Requested 4762. Please try again in 1.314s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56552, Requested 4762. Please try again in 1.314s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55348, Requested 4762. Please try again in 110ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55348, Requested 4762. Please try again in 110ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55668, Requested 4762. Please try again in 430ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55668, Requested 4762. Please try again in 430ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 185  (63.8):  92%|█████████▎| 185/200 [11:00<01:23,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57022, Requested 4835. Please try again in 1.857s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57022, Requested 4835. Please try again in 1.857s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56935, Requested 4762. Please try again in 1.697s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56935, Requested 4762. Please try again in 1.697s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.1 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55932, Requested 4835. Please try again in 767ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55932, Requested 4835. Please try again in 767ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 186  (63.4):  93%|█████████▎| 186/200 [11:08<01:28,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57317, Requested 4852. Please try again in 2.169s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57317, Requested 4852. Please try again in 2.169s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57108, Requested 4762. Please try again in 1.87s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 19.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57108, Requested 4762. Please try again in 1.87s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 19.6 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56806, Requested 4852. Please try again in 1.658s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56806, Requested 4852. Please try again in 1.658s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56262, Requested 4852. Please try again in 1.114s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56262, Requested 4852. Please try again in 1.114s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 187  (63.6):  94%|█████████▎| 187/200 [11:14<01:22,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57276, Requested 3269. Please try again in 545ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57276, Requested 3269. Please try again in 545ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56840, Requested 3269. Please try again in 109ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56840, Requested 3269. Please try again in 109ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56463, Requested 4539. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56463, Requested 4539. Please try again in 1.002s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55504, Requested 4539. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55504, Requested 4539. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 188  (63.3):  94%|█████████▍| 188/200 [11:22<01:20,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57987, Requested 4539. Please try again in 2.526s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57987, Requested 4539. Please try again in 2.526s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57367, Requested 3294. Please try again in 661ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57367, Requested 3294. Please try again in 661ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56749, Requested 4539. Please try again in 1.288s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56749, Requested 4539. Please try again in 1.288s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56709, Requested 3294. Please try again in 3ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56709, Requested 3294. Please try again in 3ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56383, Requested 4909. Please try again in 1.292s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56383, Requested 4909. Please try again in 1.292s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55686, Requested 4909. Please try again in 595ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55686, Requested 4909. Please try again in 595ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59825, Requested 4539. Please try again in 4.364s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59825, Requested 4539. Please try again in 4.364s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.9 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 189  (63.0):  94%|█████████▍| 189/200 [11:30<01:18,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56988, Requested 4762. Please try again in 1.75s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56988, Requested 4762. Please try again in 1.75s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.1 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55359, Requested 4757. Please try again in 116ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55359, Requested 4757. Please try again in 116ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58960, Requested 4539. Please try again in 3.499s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58960, Requested 4539. Please try again in 3.499s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 190  (62.6):  95%|█████████▌| 190/200 [11:38<01:12,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56899, Requested 4762. Please try again in 1.661s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56899, Requested 4762. Please try again in 1.661s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55934, Requested 4539. Please try again in 472ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55934, Requested 4539. Please try again in 472ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59864, Requested 3203. Please try again in 3.067s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59864, Requested 3203. Please try again in 3.067s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59179, Requested 3203. Please try again in 2.382s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59179, Requested 3203. Please try again in 2.382s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59097, Requested 4762. Please try again in 3.858s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 217.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59097, Requested 4762. Please try again in 3.858s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 217.1 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 191  (62.3):  96%|█████████▌| 191/200 [11:41<00:55,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57030, Requested 3203. Please try again in 233ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57030, Requested 3203. Please try again in 233ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56822, Requested 3259. Please try again in 81ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56822, Requested 3259. Please try again in 81ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58951, Requested 3203. Please try again in 2.154s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58951, Requested 3203. Please try again in 2.154s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56922, Requested 3203. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 13.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56922, Requested 3203. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 13.2 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56799, Requested 4856. Please try again in 1.655s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56799, Requested 4856. Please try again in 1.655s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55935, Requested 4856. Please try again in 791ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55935, Requested 4856. Please try again in 791ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 192  (62.0):  96%|█████████▌| 192/200 [11:50<00:54,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58031, Requested 4843. Please try again in 2.874s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 31.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58031, Requested 4843. Please try again in 2.874s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 31.2 seconds after 11 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 193  (62.2):  96%|█████████▋| 193/200 [11:57<00:49,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58395, Requested 3270. Please try again in 1.665s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58395, Requested 3270. Please try again in 1.665s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57748, Requested 3270. Please try again in 1.018s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57748, Requested 3270. Please try again in 1.018s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56698, Requested 4473. Please try again in 1.171s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56698, Requested 4473. Please try again in 1.171s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55933, Requested 4473. Please try again in 406ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55933, Requested 4473. Please try again in 406ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57859, Requested 4473. Please try again in 2.332s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57859, Requested 4473. Please try again in 2.332s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56604, Requested 4473. Please try again in 1.077s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56604, Requested 4473. Please try again in 1.077s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59290, Requested 4724. Please try again in 4.014s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59290, Requested 4724. Please try again in 4.014s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 121 / 194  (62.4):  97%|█████████▋| 194/200 [12:06<00:44,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58436, Requested 4724. Please try again in 3.16s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58436, Requested 4724. Please try again in 3.16s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57435, Requested 4724. Please try again in 2.159s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57435, Requested 4724. Please try again in 2.159s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57300, Requested 3223. Please try again in 523ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57300, Requested 3223. Please try again in 523ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57164, Requested 4724. Please try again in 1.887s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57164, Requested 4724. Please try again in 1.887s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56685, Requested 4987. Please try again in 1.672s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56685, Requested 4987. Please try again in 1.672s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56327, Requested 4987. Please try again in 1.314s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56327, Requested 4987. Please try again in 1.314s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55468, Requested 4724. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 12.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 55468, Requested 4724. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 12.5 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 124 / 200  (62.0): 100%|██████████| 200/200 [16:49<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 124 / 200  (62.0%)\n",
      "Score: 62.0 for set: [5, 5, 5, 5]\n",
      "New best score: 62.0 for seed 0\n",
      "Scores so far: [60.0, 60.0, 59.0, 62.0]\n",
      "Best score: 62.0\n",
      "Average of max per entry across top 1 scores: 0.62\n",
      "Average of max per entry across top 2 scores: 0.86\n",
      "Average of max per entry across top 3 scores: 0.915\n",
      "Average of max per entry across top 5 scores: 0.945\n",
      "Average of max per entry across top 8 scores: 0.945\n",
      "Average of max per entry across top 9999 scores: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:02<03:52,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 12  (50.0):   6%|▌         | 12/200 [00:11<02:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58541, Requested 3366. Please try again in 1.906s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58541, Requested 3366. Please try again in 1.906s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58403, Requested 2164. Please try again in 567ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58403, Requested 2164. Please try again in 567ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 13  (53.8):   6%|▋         | 13/200 [00:14<03:29,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56988, Requested 3082. Please try again in 70ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56988, Requested 3082. Please try again in 70ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 14  (57.1):   7%|▋         | 14/200 [00:14<02:37,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56653, Requested 3349. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56653, Requested 3349. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58958, Requested 3366. Please try again in 2.324s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58958, Requested 3366. Please try again in 2.324s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58895, Requested 3349. Please try again in 2.244s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58895, Requested 3349. Please try again in 2.244s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58505, Requested 3082. Please try again in 1.587s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58505, Requested 3082. Please try again in 1.587s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58204, Requested 3366. Please try again in 1.57s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58204, Requested 3366. Please try again in 1.57s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57637, Requested 3082. Please try again in 719ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57637, Requested 3082. Please try again in 719ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58925, Requested 2171. Please try again in 1.096s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58925, Requested 2171. Please try again in 1.096s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58494, Requested 3349. Please try again in 1.843s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58494, Requested 3349. Please try again in 1.843s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58473, Requested 2171. Please try again in 644ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58473, Requested 2171. Please try again in 644ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58516, Requested 3284. Please try again in 1.8s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58516, Requested 3284. Please try again in 1.8s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57329, Requested 3284. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57329, Requested 3284. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57310, Requested 3082. Please try again in 392ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57310, Requested 3082. Please try again in 392ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57122, Requested 3366. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57122, Requested 3366. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56718, Requested 3349. Please try again in 67ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56718, Requested 3349. Please try again in 67ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59777, Requested 2171. Please try again in 1.947s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59777, Requested 2171. Please try again in 1.947s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59188, Requested 3284. Please try again in 2.472s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59188, Requested 3284. Please try again in 2.472s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 15  (60.0):   8%|▊         | 15/200 [00:18<05:51,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58416, Requested 3366. Please try again in 1.782s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58416, Requested 3366. Please try again in 1.782s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.5 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58489, Requested 2171. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58489, Requested 2171. Please try again in 660ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58112, Requested 3284. Please try again in 1.396s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58112, Requested 3284. Please try again in 1.396s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58081, Requested 3349. Please try again in 1.43s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58081, Requested 3349. Please try again in 1.43s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58229, Requested 3082. Please try again in 1.311s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 11.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58229, Requested 3082. Please try again in 1.311s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 11.4 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 16  (62.5):   8%|▊         | 16/200 [00:24<09:12,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57639, Requested 3284. Please try again in 923ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57639, Requested 3284. Please try again in 923ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58098, Requested 2171. Please try again in 269ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 14.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58098, Requested 2171. Please try again in 269ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 17  (58.8):   8%|▊         | 17/200 [00:28<10:21,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.7 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57978, Requested 3349. Please try again in 1.327s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57978, Requested 3349. Please try again in 1.327s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.2 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58253, Requested 3349. Please try again in 1.602s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 17.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58253, Requested 3349. Please try again in 1.602s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 17.1 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11 / 18  (61.1):   9%|▉         | 18/200 [00:33<11:29,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59150, Requested 3284. Please try again in 2.434s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 19.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59150, Requested 3284. Please try again in 2.434s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 19.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58822, Requested 2179. Please try again in 1.001s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58822, Requested 2179. Please try again in 1.001s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58633, Requested 3082. Please try again in 1.715s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58633, Requested 3082. Please try again in 1.715s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.3 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 19  (63.2):  10%|▉         | 19/200 [00:35<09:47,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59101, Requested 2133. Please try again in 1.234s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59101, Requested 2133. Please try again in 1.234s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58734, Requested 2133. Please try again in 867ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58734, Requested 2133. Please try again in 867ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58364, Requested 2133. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58364, Requested 2133. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57924, Requested 2133. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57924, Requested 2133. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57821, Requested 3082. Please try again in 903ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 27.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57821, Requested 3082. Please try again in 903ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 27.4 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58737, Requested 2133. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58737, Requested 2133. Please try again in 870ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 20  (65.0):  10%|█         | 20/200 [00:39<10:40,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58991, Requested 2182. Please try again in 1.173s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58991, Requested 2182. Please try again in 1.173s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58174, Requested 2182. Please try again in 356ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58174, Requested 2182. Please try again in 356ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57292, Requested 3238. Please try again in 530ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57292, Requested 3238. Please try again in 530ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59372, Requested 2171. Please try again in 1.543s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 16.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59372, Requested 2171. Please try again in 1.543s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 16.0 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58952, Requested 2182. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58952, Requested 2182. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 21  (66.7):  10%|█         | 21/200 [00:44<11:28,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58079, Requested 2182. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58079, Requested 2182. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.5 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59480, Requested 3349. Please try again in 2.829s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 16.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59480, Requested 3349. Please try again in 2.829s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 16.2 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58703, Requested 2975. Please try again in 1.678s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58703, Requested 2975. Please try again in 1.678s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 22  (63.6):  11%|█         | 22/200 [00:50<13:36,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57681, Requested 2975. Please try again in 656ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57681, Requested 2975. Please try again in 656ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59200, Requested 2146. Please try again in 1.346s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59200, Requested 2146. Please try again in 1.346s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 15 / 23  (65.2):  12%|█▏        | 23/200 [00:52<11:30,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59222, Requested 2177. Please try again in 1.399s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59222, Requested 2177. Please try again in 1.399s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58530, Requested 3284. Please try again in 1.814s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 57.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58530, Requested 3284. Please try again in 1.814s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 57.5 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58271, Requested 2177. Please try again in 448ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58271, Requested 2177. Please try again in 448ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57247, Requested 3238. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57247, Requested 3238. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58492, Requested 3238. Please try again in 1.73s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58492, Requested 3238. Please try again in 1.73s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57709, Requested 3238. Please try again in 947ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57709, Requested 3238. Please try again in 947ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59267, Requested 3238. Please try again in 2.505s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59267, Requested 3238. Please try again in 2.505s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 24  (66.7):  12%|█▏        | 24/200 [00:59<13:50,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58150, Requested 3238. Please try again in 1.388s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58150, Requested 3238. Please try again in 1.388s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.8 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58106, Requested 2123. Please try again in 229ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58106, Requested 2123. Please try again in 229ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59405, Requested 2123. Please try again in 1.528s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59405, Requested 2123. Please try again in 1.528s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59109, Requested 2123. Please try again in 1.232s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59109, Requested 2123. Please try again in 1.232s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 25  (68.0):  12%|█▎        | 25/200 [01:02<12:44,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59530, Requested 2123. Please try again in 1.653s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59530, Requested 2123. Please try again in 1.653s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57647, Requested 3082. Please try again in 729ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 33.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57647, Requested 3082. Please try again in 729ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 33.3 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57293, Requested 3139. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57293, Requested 3139. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56833, Requested 3238. Please try again in 71ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56833, Requested 3238. Please try again in 71ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59816, Requested 3349. Please try again in 3.165s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 173.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59816, Requested 3349. Please try again in 3.165s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 173.5 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 26  (65.4):  13%|█▎        | 26/200 [01:07<12:44,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59686, Requested 3238. Please try again in 2.924s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59686, Requested 3238. Please try again in 2.924s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.0 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58305, Requested 2953. Please try again in 1.258s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58305, Requested 2953. Please try again in 1.258s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59293, Requested 2910. Please try again in 2.203s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59293, Requested 2910. Please try again in 2.203s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58609, Requested 2910. Please try again in 1.519s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58609, Requested 2910. Please try again in 1.519s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 27  (63.0):  14%|█▎        | 27/200 [01:13<14:04,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57589, Requested 2910. Please try again in 499ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57589, Requested 2910. Please try again in 499ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59163, Requested 3355. Please try again in 2.518s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59163, Requested 3355. Please try again in 2.518s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 28  (64.3):  14%|█▍        | 28/200 [01:17<13:21,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58249, Requested 2910. Please try again in 1.159s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58249, Requested 2910. Please try again in 1.159s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58210, Requested 3355. Please try again in 1.565s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58210, Requested 3355. Please try again in 1.565s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57640, Requested 3355. Please try again in 994ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57640, Requested 3355. Please try again in 994ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57575, Requested 3371. Please try again in 945ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57575, Requested 3371. Please try again in 945ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57248, Requested 3371. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57248, Requested 3371. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58394, Requested 3355. Please try again in 1.749s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58394, Requested 3355. Please try again in 1.749s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 29  (62.1):  14%|█▍        | 29/200 [01:22<13:22,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57366, Requested 3371. Please try again in 737ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57366, Requested 3371. Please try again in 737ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57336, Requested 3371. Please try again in 707ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57336, Requested 3371. Please try again in 707ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58275, Requested 3355. Please try again in 1.63s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 9.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58275, Requested 3355. Please try again in 1.63s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 30  (60.0):  15%|█▌        | 30/200 [01:26<13:03,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.3 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 31  (58.1):  16%|█▌        | 31/200 [01:31<13:09,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57047, Requested 3371. Please try again in 418ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57047, Requested 3371. Please try again in 418ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.3 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57356, Requested 3355. Please try again in 711ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57356, Requested 3355. Please try again in 711ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 32  (59.4):  16%|█▌        | 32/200 [01:36<12:59,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57934, Requested 3355. Please try again in 1.289s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 62.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57934, Requested 3355. Please try again in 1.289s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 62.7 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58285, Requested 3224. Please try again in 1.509s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58285, Requested 3224. Please try again in 1.509s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 33  (60.6):  16%|█▋        | 33/200 [01:39<12:11,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56955, Requested 3371. Please try again in 326ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 23.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56955, Requested 3371. Please try again in 326ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 23.8 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56840, Requested 3224. Please try again in 64ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56840, Requested 3224. Please try again in 64ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59101, Requested 2187. Please try again in 1.288s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59101, Requested 2187. Please try again in 1.288s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58495, Requested 2187. Please try again in 682ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58495, Requested 2187. Please try again in 682ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 34  (61.8):  17%|█▋        | 34/200 [01:42<10:30,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58194, Requested 2184. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58194, Requested 2184. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58807, Requested 3307. Please try again in 2.114s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58807, Requested 3307. Please try again in 2.114s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58481, Requested 3307. Please try again in 1.788s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58481, Requested 3307. Please try again in 1.788s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58146, Requested 3307. Please try again in 1.453s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58146, Requested 3307. Please try again in 1.453s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56978, Requested 3161. Please try again in 139ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56978, Requested 3161. Please try again in 139ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59252, Requested 3161. Please try again in 2.413s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59252, Requested 3161. Please try again in 2.413s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 35  (62.9):  18%|█▊        | 35/200 [01:48<12:16,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57612, Requested 3161. Please try again in 773ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57612, Requested 3161. Please try again in 773ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57792, Requested 3161. Please try again in 953ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57792, Requested 3161. Please try again in 953ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 36  (63.9):  18%|█▊        | 36/200 [01:53<12:26,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57106, Requested 3161. Please try again in 267ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57106, Requested 3161. Please try again in 267ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.4 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57218, Requested 3148. Please try again in 366ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57218, Requested 3148. Please try again in 366ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "warn - WARNING - [MemorizedFunc(func=<function colbertv2_get_request_v2 at 0x7fc1ed3e5360>, location=/home/michael/cachedir_joblib/joblib)]: Exception while loading results for colbertv2_get_request_v2('http://index.contextual.ai:8893/api/search', 'Ancestry of white immigrants in Florida', 3)\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/michael/.cache/pypoetry/virtualenvs/cs224u-projects-GPC47Gm_-py3.10/lib/python3.10/site-packages/joblib/memory.py\", line 568, in _cached_call\n",
      "    out = self.store_backend.load_item(\n",
      "  File \"/home/michael/.cache/pypoetry/virtualenvs/cs224u-projects-GPC47Gm_-py3.10/lib/python3.10/site-packages/joblib/_store_backends.py\", line 176, in load_item\n",
      "    item = numpy_pickle.load(f)\n",
      "  File \"/home/michael/.cache/pypoetry/virtualenvs/cs224u-projects-GPC47Gm_-py3.10/lib/python3.10/site-packages/joblib/numpy_pickle.py\", line 648, in load\n",
      "    obj = _unpickle(fobj)\n",
      "  File \"/home/michael/.cache/pypoetry/virtualenvs/cs224u-projects-GPC47Gm_-py3.10/lib/python3.10/site-packages/joblib/numpy_pickle.py\", line 577, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"/usr/lib/python3.10/pickle.py\", line 1211, in load\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58591, Requested 2201. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58591, Requested 2201. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 37  (64.9):  18%|█▊        | 37/200 [01:55<10:39,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58136, Requested 2235. Please try again in 371ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58136, Requested 2235. Please try again in 371ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57917, Requested 2235. Please try again in 152ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57917, Requested 2235. Please try again in 152ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57704, Requested 3161. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 10.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57704, Requested 3161. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 10.1 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58751, Requested 3145. Please try again in 1.896s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58751, Requested 3145. Please try again in 1.896s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57818, Requested 3145. Please try again in 962ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57818, Requested 3145. Please try again in 962ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58555, Requested 3145. Please try again in 1.7s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58555, Requested 3145. Please try again in 1.7s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 38  (65.8):  19%|█▉        | 38/200 [02:01<12:07,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57771, Requested 3145. Please try again in 916ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57771, Requested 3145. Please try again in 916ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59440, Requested 3278. Please try again in 2.718s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59440, Requested 3278. Please try again in 2.718s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 39  (66.7):  20%|█▉        | 39/200 [02:05<11:30,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58486, Requested 3278. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58486, Requested 3278. Please try again in 1.764s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57385, Requested 3278. Please try again in 663ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57385, Requested 3278. Please try again in 663ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58334, Requested 3145. Please try again in 1.479s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 11.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58334, Requested 3145. Please try again in 1.479s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 11.9 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57758, Requested 3161. Please try again in 919ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 24.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57758, Requested 3161. Please try again in 919ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 24.4 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57678, Requested 3278. Please try again in 956ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57678, Requested 3278. Please try again in 956ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 40  (67.5):  20%|██        | 40/200 [02:10<12:16,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57149, Requested 3278. Please try again in 427ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57149, Requested 3278. Please try again in 427ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 42  (69.0):  21%|██        | 42/200 [02:17<10:22,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58080, Requested 2230. Please try again in 310ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58080, Requested 2230. Please try again in 310ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57265, Requested 3145. Please try again in 410ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57265, Requested 3145. Please try again in 410ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58884, Requested 3340. Please try again in 2.224s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58884, Requested 3340. Please try again in 2.224s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58633, Requested 3340. Please try again in 1.973s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58633, Requested 3340. Please try again in 1.973s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57514, Requested 3145. Please try again in 659ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 54.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57514, Requested 3145. Please try again in 659ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 54.6 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57450, Requested 3340. Please try again in 790ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57450, Requested 3340. Please try again in 790ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 43  (69.8):  22%|██▏       | 43/200 [02:23<11:20,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57912, Requested 3340. Please try again in 1.252s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57912, Requested 3340. Please try again in 1.252s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58215, Requested 3340. Please try again in 1.555s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 9.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58215, Requested 3340. Please try again in 1.555s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 9.2 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32 / 45  (71.1):  22%|██▎       | 45/200 [02:33<12:25,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56971, Requested 3108. Please try again in 79ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56971, Requested 3108. Please try again in 79ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58471, Requested 3340. Please try again in 1.811s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 31.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58471, Requested 3340. Please try again in 1.811s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 31.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 33 / 46  (71.7):  23%|██▎       | 46/200 [02:34<09:39,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59059, Requested 2959. Please try again in 2.018s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59059, Requested 2959. Please try again in 2.018s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58072, Requested 2959. Please try again in 1.031s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58072, Requested 2959. Please try again in 1.031s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59772, Requested 2959. Please try again in 2.731s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59772, Requested 2959. Please try again in 2.731s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59003, Requested 3355. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 76.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59003, Requested 3355. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 47  (72.3):  24%|██▎       | 47/200 [02:40<10:43,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 76.6 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58013, Requested 2959. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58013, Requested 2959. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.7 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57056, Requested 2959. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57056, Requested 2959. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.1 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 49  (69.4):  24%|██▍       | 49/200 [02:49<11:15,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57588, Requested 2959. Please try again in 547ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57588, Requested 2959. Please try again in 547ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58458, Requested 2979. Please try again in 1.437s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58458, Requested 2979. Please try again in 1.437s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57807, Requested 2979. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57807, Requested 2979. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57157, Requested 2979. Please try again in 136ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57157, Requested 2979. Please try again in 136ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 52  (67.3):  26%|██▌       | 52/200 [03:01<08:55,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59701, Requested 3129. Please try again in 2.83s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59701, Requested 3129. Please try again in 2.83s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59362, Requested 3129. Please try again in 2.491s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59362, Requested 3129. Please try again in 2.491s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 53  (66.0):  26%|██▋       | 53/200 [03:06<09:36,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58270, Requested 3340. Please try again in 1.61s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 60.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58270, Requested 3340. Please try again in 1.61s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 60.1 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59301, Requested 3129. Please try again in 2.43s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59301, Requested 3129. Please try again in 2.43s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57014, Requested 3169. Please try again in 183ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57014, Requested 3169. Please try again in 183ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59124, Requested 3169. Please try again in 2.293s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59124, Requested 3169. Please try again in 2.293s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 54  (64.8):  27%|██▋       | 54/200 [03:12<11:02,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58341, Requested 2155. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58341, Requested 2155. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36 / 55  (65.5):  28%|██▊       | 55/200 [03:14<09:01,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58688, Requested 2231. Please try again in 919ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58688, Requested 2231. Please try again in 919ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59720, Requested 3145. Please try again in 2.865s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 26.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59720, Requested 3145. Please try again in 2.865s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 26.2 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57206, Requested 3247. Please try again in 453ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57206, Requested 3247. Please try again in 453ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56937, Requested 3247. Please try again in 184ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56937, Requested 3247. Please try again in 184ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 56  (66.1):  28%|██▊       | 56/200 [03:19<10:01,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58380, Requested 3247. Please try again in 1.627s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58380, Requested 3247. Please try again in 1.627s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57647, Requested 3247. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57647, Requested 3247. Please try again in 894ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 57  (66.7):  28%|██▊       | 57/200 [03:24<10:30,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57204, Requested 3136. Please try again in 340ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57204, Requested 3136. Please try again in 340ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 59  (67.8):  30%|██▉       | 59/200 [03:31<09:10,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57872, Requested 2193. Please try again in 65ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57872, Requested 2193. Please try again in 65ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58798, Requested 3311. Please try again in 2.109s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58798, Requested 3311. Please try again in 2.109s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57716, Requested 3311. Please try again in 1.027s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57716, Requested 3311. Please try again in 1.027s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59442, Requested 3311. Please try again in 2.753s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59442, Requested 3311. Please try again in 2.753s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 41 / 60  (68.3):  30%|███       | 60/200 [03:37<10:21,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59012, Requested 3311. Please try again in 2.323s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59012, Requested 3311. Please try again in 2.323s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.7 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 42 / 61  (68.9):  30%|███       | 61/200 [03:42<10:22,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57240, Requested 3145. Please try again in 385ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 230.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57240, Requested 3145. Please try again in 385ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 230.4 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58382, Requested 3311. Please try again in 1.693s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58382, Requested 3311. Please try again in 1.693s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.8 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56910, Requested 3256. Please try again in 166ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56910, Requested 3256. Please try again in 166ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 63  (68.3):  32%|███▏      | 63/200 [03:51<10:37,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57299, Requested 3311. Please try again in 610ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57299, Requested 3311. Please try again in 610ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.0 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56996, Requested 3355. Please try again in 351ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 51.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56996, Requested 3355. Please try again in 351ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 51.3 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 65  (69.2):  32%|███▎      | 65/200 [04:00<09:34,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58355, Requested 3349. Please try again in 1.704s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 252.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58355, Requested 3349. Please try again in 1.704s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 252.7 seconds after 10 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58248, Requested 3287. Please try again in 1.535s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58248, Requested 3287. Please try again in 1.535s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59320, Requested 3113. Please try again in 2.433s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59320, Requested 3113. Please try again in 2.433s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 66  (68.2):  33%|███▎      | 66/200 [04:04<09:29,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58145, Requested 3113. Please try again in 1.258s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58145, Requested 3113. Please try again in 1.258s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57443, Requested 3113. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57443, Requested 3113. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57815, Requested 3113. Please try again in 928ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57815, Requested 3113. Please try again in 928ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57717, Requested 3340. Please try again in 1.057s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 24.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57717, Requested 3340. Please try again in 1.057s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 24.2 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 68  (66.2):  34%|███▍      | 68/200 [04:14<10:12,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57011, Requested 3113. Please try again in 124ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57011, Requested 3113. Please try again in 124ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.7 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 69  (65.2):  34%|███▍      | 69/200 [04:18<10:00,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57789, Requested 3504. Please try again in 1.293s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57789, Requested 3504. Please try again in 1.293s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57466, Requested 3504. Please try again in 970ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57466, Requested 3504. Please try again in 970ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 70  (64.3):  35%|███▌      | 70/200 [04:23<09:49,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57254, Requested 3504. Please try again in 758ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57254, Requested 3504. Please try again in 758ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 71  (63.4):  36%|███▌      | 71/200 [04:27<09:21,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57436, Requested 3504. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57436, Requested 3504. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 46 / 72  (63.9):  36%|███▌      | 72/200 [04:31<09:07,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57312, Requested 3340. Please try again in 652ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57312, Requested 3340. Please try again in 652ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58289, Requested 3504. Please try again in 1.793s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58289, Requested 3504. Please try again in 1.793s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.5 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59459, Requested 3385. Please try again in 2.844s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59459, Requested 3385. Please try again in 2.844s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 73  (64.4):  36%|███▋      | 73/200 [04:34<08:28,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58445, Requested 3385. Please try again in 1.83s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58445, Requested 3385. Please try again in 1.83s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58450, Requested 3385. Please try again in 1.835s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58450, Requested 3385. Please try again in 1.835s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57183, Requested 3385. Please try again in 568ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57183, Requested 3385. Please try again in 568ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57069, Requested 3184. Please try again in 252ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57069, Requested 3184. Please try again in 252ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 48 / 74  (64.9):  37%|███▋      | 74/200 [04:39<08:43,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58264, Requested 3504. Please try again in 1.768s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 18.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58264, Requested 3504. Please try again in 1.768s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 18.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59691, Requested 3137. Please try again in 2.828s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59691, Requested 3137. Please try again in 2.828s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59038, Requested 3137. Please try again in 2.175s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59038, Requested 3137. Please try again in 2.175s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 75  (65.3):  38%|███▊      | 75/200 [04:43<08:48,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57715, Requested 3137. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57715, Requested 3137. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50 / 76  (65.8):  38%|███▊      | 76/200 [04:48<09:07,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57558, Requested 3137. Please try again in 695ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57558, Requested 3137. Please try again in 695ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57771, Requested 3355. Please try again in 1.126s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 491.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57771, Requested 3355. Please try again in 1.126s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 491.8 seconds after 10 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57729, Requested 3137. Please try again in 866ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 11.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57729, Requested 3137. Please try again in 866ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 11.1 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 78  (66.7):  39%|███▉      | 78/200 [04:57<08:48,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56799, Requested 3504. Please try again in 303ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 41.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56799, Requested 3504. Please try again in 303ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 41.1 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59588, Requested 3105. Please try again in 2.693s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59588, Requested 3105. Please try again in 2.693s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 53 / 79  (67.1):  40%|███▉      | 79/200 [05:01<08:35,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58043, Requested 3105. Please try again in 1.148s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58043, Requested 3105. Please try again in 1.148s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58673, Requested 3105. Please try again in 1.778s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58673, Requested 3105. Please try again in 1.778s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59411, Requested 3105. Please try again in 2.516s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59411, Requested 3105. Please try again in 2.516s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 81  (66.7):  40%|████      | 81/200 [05:11<09:36,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57356, Requested 3105. Please try again in 461ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57356, Requested 3105. Please try again in 461ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.0 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 84  (66.7):  42%|████▏     | 84/200 [05:21<06:53,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58265, Requested 2202. Please try again in 467ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58265, Requested 2202. Please try again in 467ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58337, Requested 3299. Please try again in 1.636s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58337, Requested 3299. Please try again in 1.636s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57497, Requested 3299. Please try again in 796ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57497, Requested 3299. Please try again in 796ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 85  (65.9):  42%|████▎     | 85/200 [05:28<08:50,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57224, Requested 3299. Please try again in 523ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57224, Requested 3299. Please try again in 523ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58314, Requested 3299. Please try again in 1.613s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58314, Requested 3299. Please try again in 1.613s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 57 / 86  (66.3):  43%|████▎     | 86/200 [05:32<08:41,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57042, Requested 3299. Please try again in 341ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57042, Requested 3299. Please try again in 341ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.0 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 58 / 88  (65.9):  44%|████▍     | 88/200 [05:42<08:02,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57763, Requested 3442. Please try again in 1.205s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57763, Requested 3442. Please try again in 1.205s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56634, Requested 3442. Please try again in 76ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56634, Requested 3442. Please try again in 76ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58373, Requested 3442. Please try again in 1.815s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58373, Requested 3442. Please try again in 1.815s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 58 / 89  (65.2):  44%|████▍     | 89/200 [05:46<08:19,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57602, Requested 3299. Please try again in 901ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 18.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57602, Requested 3299. Please try again in 901ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 18.6 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57420, Requested 3442. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57420, Requested 3442. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 59 / 91  (64.8):  46%|████▌     | 91/200 [05:53<06:51,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58909, Requested 2165. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58909, Requested 2165. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58583, Requested 2165. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58583, Requested 2165. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59025, Requested 3355. Please try again in 2.38s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59025, Requested 3355. Please try again in 2.38s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58705, Requested 3355. Please try again in 2.06s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58705, Requested 3355. Please try again in 2.06s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56780, Requested 3418. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56780, Requested 3418. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58971, Requested 3418. Please try again in 2.389s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58971, Requested 3418. Please try again in 2.389s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57985, Requested 3418. Please try again in 1.403s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57985, Requested 3418. Please try again in 1.403s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56861, Requested 3418. Please try again in 279ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56861, Requested 3418. Please try again in 279ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 60 / 92  (65.2):  46%|████▌     | 92/200 [06:00<08:30,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 60 / 93  (64.5):  46%|████▋     | 93/200 [06:04<08:09,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57358, Requested 3458. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57358, Requested 3458. Please try again in 816ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 94  (64.9):  47%|████▋     | 94/200 [06:06<06:34,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58286, Requested 2170. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58286, Requested 2170. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58467, Requested 2170. Please try again in 637ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58467, Requested 2170. Please try again in 637ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57463, Requested 3299. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 18.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57463, Requested 3299. Please try again in 762ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 18.0 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59019, Requested 2184. Please try again in 1.203s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59019, Requested 2184. Please try again in 1.203s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59161, Requested 3131. Please try again in 2.292s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59161, Requested 3131. Please try again in 2.292s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57705, Requested 3131. Please try again in 836ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57705, Requested 3131. Please try again in 836ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57462, Requested 3131. Please try again in 593ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57462, Requested 3131. Please try again in 593ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57082, Requested 3469. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57082, Requested 3469. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56899, Requested 3131. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56899, Requested 3131. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56755, Requested 3469. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56755, Requested 3469. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59131, Requested 3469. Please try again in 2.6s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59131, Requested 3469. Please try again in 2.6s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 95  (64.2):  48%|████▊     | 95/200 [06:12<07:44,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57304, Requested 3469. Please try again in 773ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57304, Requested 3469. Please try again in 773ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 96  (63.5):  48%|████▊     | 96/200 [06:17<07:47,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57702, Requested 3469. Please try again in 1.171s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 10.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57702, Requested 3469. Please try again in 1.171s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 10.2 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 97  (63.9):  48%|████▊     | 97/200 [06:22<07:57,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58820, Requested 3270. Please try again in 2.09s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58820, Requested 3270. Please try again in 2.09s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 98  (64.3):  49%|████▉     | 98/200 [06:26<07:43,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57401, Requested 3270. Please try again in 671ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57401, Requested 3270. Please try again in 671ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57715, Requested 3270. Please try again in 985ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57715, Requested 3270. Please try again in 985ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58821, Requested 3469. Please try again in 2.29s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 25.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58821, Requested 3469. Please try again in 2.29s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 25.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58772, Requested 3270. Please try again in 2.042s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58772, Requested 3270. Please try again in 2.042s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 99  (64.6):  50%|████▉     | 99/200 [06:30<07:32,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58566, Requested 3171. Please try again in 1.737s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58566, Requested 3171. Please try again in 1.737s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 100  (64.0):  50%|█████     | 100/200 [06:35<07:32,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57876, Requested 3171. Please try again in 1.047s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57876, Requested 3171. Please try again in 1.047s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57379, Requested 3171. Please try again in 550ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57379, Requested 3171. Please try again in 550ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 65 / 101  (64.4):  50%|█████     | 101/200 [06:39<07:23,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57423, Requested 3171. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57423, Requested 3171. Please try again in 594ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.5 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 102  (64.7):  51%|█████     | 102/200 [06:45<07:51,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57103, Requested 3171. Please try again in 274ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57103, Requested 3171. Please try again in 274ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.9 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 103  (64.1):  52%|█████▏    | 103/200 [06:49<07:34,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57419, Requested 3131. Please try again in 550ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57419, Requested 3131. Please try again in 550ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57100, Requested 3131. Please try again in 231ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57100, Requested 3131. Please try again in 231ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 67 / 104  (64.4):  52%|█████▏    | 104/200 [06:54<07:29,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57081, Requested 3131. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57081, Requested 3131. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 68 / 105  (64.8):  52%|█████▎    | 105/200 [06:57<06:29,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57806, Requested 2992. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57806, Requested 2992. Please try again in 798ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57061, Requested 2992. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57061, Requested 2992. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57726, Requested 3131. Please try again in 857ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57726, Requested 3131. Please try again in 857ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57166, Requested 2992. Please try again in 158ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57166, Requested 2992. Please try again in 158ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58200, Requested 2992. Please try again in 1.192s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58200, Requested 2992. Please try again in 1.192s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58155, Requested 3131. Please try again in 1.286s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58155, Requested 3131. Please try again in 1.286s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.4 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 68 / 106  (64.2):  53%|█████▎    | 106/200 [07:02<07:06,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57473, Requested 2992. Please try again in 465ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 14.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57473, Requested 2992. Please try again in 465ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 14.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 108  (64.8):  54%|█████▍    | 108/200 [07:08<05:25,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58096, Requested 2175. Please try again in 271ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58096, Requested 2175. Please try again in 271ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59660, Requested 2156. Please try again in 1.816s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59660, Requested 2156. Please try again in 1.816s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58635, Requested 2156. Please try again in 791ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58635, Requested 2156. Please try again in 791ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57325, Requested 2961. Please try again in 286ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57325, Requested 2961. Please try again in 286ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59002, Requested 2156. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59002, Requested 2156. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 71 / 109  (65.1):  55%|█████▍    | 109/200 [07:13<05:46,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58743, Requested 2196. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58743, Requested 2196. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58493, Requested 2196. Please try again in 689ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58493, Requested 2196. Please try again in 689ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57902, Requested 2196. Please try again in 98ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57902, Requested 2196. Please try again in 98ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58006, Requested 2943. Please try again in 949ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58006, Requested 2943. Please try again in 949ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59292, Requested 3509. Please try again in 2.801s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59292, Requested 3509. Please try again in 2.801s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72 / 110  (65.5):  55%|█████▌    | 110/200 [07:18<06:26,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58303, Requested 3509. Please try again in 1.812s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58303, Requested 3509. Please try again in 1.812s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57811, Requested 3509. Please try again in 1.32s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57811, Requested 3509. Please try again in 1.32s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59833, Requested 2992. Please try again in 2.825s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59833, Requested 2992. Please try again in 2.825s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.2 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57156, Requested 3130. Please try again in 286ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57156, Requested 3130. Please try again in 286ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59315, Requested 3509. Please try again in 2.824s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59315, Requested 3509. Please try again in 2.824s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59101, Requested 2992. Please try again in 2.093s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59101, Requested 2992. Please try again in 2.093s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58737, Requested 2992. Please try again in 1.729s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 54.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58737, Requested 2992. Please try again in 1.729s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 54.7 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72 / 111  (64.9):  56%|█████▌    | 111/200 [07:23<06:38,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57267, Requested 3509. Please try again in 776ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57267, Requested 3509. Please try again in 776ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.3 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73 / 113  (64.6):  56%|█████▋    | 113/200 [07:32<06:38,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59280, Requested 2170. Please try again in 1.45s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59280, Requested 2170. Please try again in 1.45s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59046, Requested 2170. Please try again in 1.216s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59046, Requested 2170. Please try again in 1.216s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 114  (64.9):  57%|█████▋    | 114/200 [07:34<05:20,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58182, Requested 2170. Please try again in 352ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58182, Requested 2170. Please try again in 352ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58389, Requested 2170. Please try again in 559ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58389, Requested 2170. Please try again in 559ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58287, Requested 3343. Please try again in 1.63s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58287, Requested 3343. Please try again in 1.63s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57358, Requested 3122. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57358, Requested 3122. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56937, Requested 3343. Please try again in 280ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56937, Requested 3343. Please try again in 280ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56513, Requested 3509. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 21.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56513, Requested 3509. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 21.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58407, Requested 3343. Please try again in 1.75s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58407, Requested 3343. Please try again in 1.75s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 75 / 115  (65.2):  57%|█████▊    | 115/200 [07:41<06:34,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59113, Requested 3343. Please try again in 2.456s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59113, Requested 3343. Please try again in 2.456s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 116  (65.5):  58%|█████▊    | 116/200 [07:44<06:01,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57523, Requested 3106. Please try again in 629ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57523, Requested 3106. Please try again in 629ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 117  (65.0):  58%|█████▊    | 117/200 [07:49<06:02,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59024, Requested 3343. Please try again in 2.367s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 11.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59024, Requested 3343. Please try again in 2.367s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 11.0 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 76 / 119  (63.9):  60%|█████▉    | 119/200 [07:59<06:18,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57928, Requested 3343. Please try again in 1.271s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57928, Requested 3343. Please try again in 1.271s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 122  (63.9):  61%|██████    | 122/200 [08:09<04:40,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57909, Requested 2195. Please try again in 104ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57909, Requested 2195. Please try again in 104ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58478, Requested 3347. Please try again in 1.825s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58478, Requested 3347. Please try again in 1.825s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57548, Requested 3347. Please try again in 895ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57548, Requested 3347. Please try again in 895ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57277, Requested 3349. Please try again in 626ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 219.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57277, Requested 3349. Please try again in 626ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 219.4 seconds after 11 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57257, Requested 3347. Please try again in 604ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57257, Requested 3347. Please try again in 604ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 79 / 123  (64.2):  62%|██████▏   | 123/200 [08:15<05:30,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56844, Requested 3347. Please try again in 191ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56844, Requested 3347. Please try again in 191ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57261, Requested 2992. Please try again in 252ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 31.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57261, Requested 2992. Please try again in 252ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 31.7 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80 / 124  (64.5):  62%|██████▏   | 124/200 [08:20<05:56,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58446, Requested 3283. Please try again in 1.729s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58446, Requested 3283. Please try again in 1.729s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81 / 125  (64.8):  62%|██████▎   | 125/200 [08:24<05:24,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57466, Requested 3283. Please try again in 749ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57466, Requested 3283. Please try again in 749ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57910, Requested 3283. Please try again in 1.193s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57910, Requested 3283. Please try again in 1.193s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58216, Requested 3283. Please try again in 1.499s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58216, Requested 3283. Please try again in 1.499s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 82 / 127  (64.6):  64%|██████▎   | 127/200 [08:32<05:06,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57877, Requested 3141. Please try again in 1.018s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57877, Requested 3141. Please try again in 1.018s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57061, Requested 3141. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57061, Requested 3141. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58671, Requested 2187. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58671, Requested 2187. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58114, Requested 2187. Please try again in 301ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58114, Requested 2187. Please try again in 301ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 128  (64.8):  64%|██████▍   | 128/200 [08:36<04:44,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58038, Requested 2192. Please try again in 230ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58038, Requested 2192. Please try again in 230ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57564, Requested 3324. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57564, Requested 3324. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57161, Requested 3324. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57161, Requested 3324. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58738, Requested 3142. Please try again in 1.879s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58738, Requested 3142. Please try again in 1.879s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 129  (64.3):  64%|██████▍   | 129/200 [08:41<05:12,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57374, Requested 3142. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57374, Requested 3142. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57297, Requested 3142. Please try again in 439ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57297, Requested 3142. Please try again in 439ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 130  (63.8):  65%|██████▌   | 130/200 [08:47<05:28,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59733, Requested 415. Please try again in 148ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59733, Requested 415. Please try again in 148ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 131  (63.4):  66%|██████▌   | 131/200 [08:47<04:00,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58027, Requested 2174. Please try again in 201ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58027, Requested 2174. Please try again in 201ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58780, Requested 2992. Please try again in 1.772s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 414.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58780, Requested 2992. Please try again in 1.772s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 414.8 seconds after 10 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58359, Requested 2141. Please try again in 500ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58359, Requested 2141. Please try again in 500ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58385, Requested 3133. Please try again in 1.518s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58385, Requested 3133. Please try again in 1.518s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56913, Requested 3133. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56913, Requested 3133. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 132  (62.9):  66%|██████▌   | 132/200 [08:54<05:06,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57684, Requested 3133. Please try again in 817ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57684, Requested 3133. Please try again in 817ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 133  (62.4):  66%|██████▋   | 133/200 [08:58<04:59,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57293, Requested 3095. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57293, Requested 3095. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56998, Requested 3095. Please try again in 93ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56998, Requested 3095. Please try again in 93ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57309, Requested 3095. Please try again in 404ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57309, Requested 3095. Please try again in 404ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 134  (62.7):  67%|██████▋   | 134/200 [09:04<05:14,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58575, Requested 2190. Please try again in 765ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58575, Requested 2190. Please try again in 765ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84 / 135  (62.2):  68%|██████▊   | 135/200 [09:05<04:07,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57439, Requested 3450. Please try again in 889ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57439, Requested 3450. Please try again in 889ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58502, Requested 3450. Please try again in 1.951s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58502, Requested 3450. Please try again in 1.951s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59560, Requested 3233. Please try again in 2.793s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59560, Requested 3233. Please try again in 2.793s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59311, Requested 3233. Please try again in 2.544s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59311, Requested 3233. Please try again in 2.544s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85 / 136  (62.5):  68%|██████▊   | 136/200 [09:11<04:45,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57414, Requested 3233. Please try again in 647ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57414, Requested 3233. Please try again in 647ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58215, Requested 3233. Please try again in 1.448s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58215, Requested 3233. Please try again in 1.448s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86 / 138  (62.3):  69%|██████▉   | 138/200 [09:21<04:47,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57327, Requested 3233. Please try again in 560ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57327, Requested 3233. Please try again in 560ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57511, Requested 3233. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 16.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57511, Requested 3233. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 16.3 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 143  (63.6):  72%|███████▏  | 143/200 [09:41<03:29,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57869, Requested 2185. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57869, Requested 2185. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58501, Requested 2201. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58501, Requested 2201. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58080, Requested 2201. Please try again in 281ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58080, Requested 2201. Please try again in 281ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58207, Requested 3146. Please try again in 1.353s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58207, Requested 3146. Please try again in 1.353s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56985, Requested 3146. Please try again in 131ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56985, Requested 3146. Please try again in 131ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59268, Requested 3146. Please try again in 2.414s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59268, Requested 3146. Please try again in 2.414s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 144  (63.2):  72%|███████▏  | 144/200 [09:47<04:03,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58209, Requested 3146. Please try again in 1.355s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58209, Requested 3146. Please try again in 1.355s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 145  (62.8):  72%|███████▎  | 145/200 [09:52<04:16,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57340, Requested 3294. Please try again in 634ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57340, Requested 3294. Please try again in 634ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57035, Requested 3294. Please try again in 329ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57035, Requested 3294. Please try again in 329ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 146  (63.0):  73%|███████▎  | 146/200 [09:57<04:19,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56854, Requested 3294. Please try again in 148ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56854, Requested 3294. Please try again in 148ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57239, Requested 3294. Please try again in 533ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57239, Requested 3294. Please try again in 533ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 147  (62.6):  74%|███████▎  | 147/200 [10:02<04:03,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 150  (63.3):  75%|███████▌  | 150/200 [10:12<02:55,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57885, Requested 2175. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57885, Requested 2175. Please try again in 60ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59274, Requested 2173. Please try again in 1.447s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59274, Requested 2173. Please try again in 1.447s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58562, Requested 2173. Please try again in 735ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58562, Requested 2173. Please try again in 735ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57000, Requested 3303. Please try again in 303ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57000, Requested 3303. Please try again in 303ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59240, Requested 3303. Please try again in 2.543s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59240, Requested 3303. Please try again in 2.543s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 151  (62.9):  76%|███████▌  | 151/200 [10:18<03:31,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57724, Requested 3303. Please try again in 1.027s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57724, Requested 3303. Please try again in 1.027s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57144, Requested 3303. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57144, Requested 3303. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96 / 152  (63.2):  76%|███████▌  | 152/200 [10:23<03:35,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57368, Requested 3303. Please try again in 671ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57368, Requested 3303. Please try again in 671ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.8 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58567, Requested 3308. Please try again in 1.875s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58567, Requested 3308. Please try again in 1.875s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 153  (63.4):  76%|███████▋  | 153/200 [10:27<03:24,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57239, Requested 3308. Please try again in 547ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57239, Requested 3308. Please try again in 547ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57616, Requested 3308. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57616, Requested 3308. Please try again in 924ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 98 / 154  (63.6):  77%|███████▋  | 154/200 [10:32<03:29,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57135, Requested 3308. Please try again in 443ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57135, Requested 3308. Please try again in 443ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58172, Requested 3308. Please try again in 1.48s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58172, Requested 3308. Please try again in 1.48s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99 / 155  (63.9):  78%|███████▊  | 155/200 [10:37<03:30,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58298, Requested 2126. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58298, Requested 2126. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 156  (64.1):  78%|███████▊  | 156/200 [10:39<02:58,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58566, Requested 2913. Please try again in 1.479s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58566, Requested 2913. Please try again in 1.479s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57837, Requested 2913. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57837, Requested 2913. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59174, Requested 3393. Please try again in 2.567s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59174, Requested 3393. Please try again in 2.567s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 157  (64.3):  78%|███████▊  | 157/200 [10:44<02:58,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57900, Requested 3393. Please try again in 1.293s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57900, Requested 3393. Please try again in 1.293s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57177, Requested 3393. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57177, Requested 3393. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59235, Requested 3393. Please try again in 2.628s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59235, Requested 3393. Please try again in 2.628s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 158  (63.9):  79%|███████▉  | 158/200 [10:48<03:01,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58216, Requested 3393. Please try again in 1.609s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58216, Requested 3393. Please try again in 1.609s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.7 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 102 / 161  (63.4):  80%|████████  | 161/200 [11:02<02:44,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59438, Requested 2191. Please try again in 1.629s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59438, Requested 2191. Please try again in 1.629s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 162  (63.6):  81%|████████  | 162/200 [11:04<02:14,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58269, Requested 2191. Please try again in 460ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58269, Requested 2191. Please try again in 460ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58507, Requested 2174. Please try again in 681ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58507, Requested 2174. Please try again in 681ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58504, Requested 3446. Please try again in 1.95s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58504, Requested 3446. Please try again in 1.95s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58061, Requested 3446. Please try again in 1.507s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58061, Requested 3446. Please try again in 1.507s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59536, Requested 3446. Please try again in 2.982s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59536, Requested 3446. Please try again in 2.982s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 163  (63.8):  82%|████████▏ | 163/200 [11:10<02:40,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57635, Requested 3446. Please try again in 1.081s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57635, Requested 3446. Please try again in 1.081s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59445, Requested 3168. Please try again in 2.613s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59445, Requested 3168. Please try again in 2.613s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59058, Requested 3168. Please try again in 2.226s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59058, Requested 3168. Please try again in 2.226s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 164  (63.4):  82%|████████▏ | 164/200 [11:15<02:39,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58237, Requested 3168. Please try again in 1.405s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58237, Requested 3168. Please try again in 1.405s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57292, Requested 3168. Please try again in 460ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57292, Requested 3168. Please try again in 460ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56817, Requested 3214. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56817, Requested 3214. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 165  (63.0):  82%|████████▎ | 165/200 [11:19<02:39,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58070, Requested 3168. Please try again in 1.238s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58070, Requested 3168. Please try again in 1.238s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.9 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 166  (63.3):  83%|████████▎ | 166/200 [11:25<02:42,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57327, Requested 3168. Please try again in 495ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 10.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57327, Requested 3168. Please try again in 495ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 10.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 107 / 169  (63.3):  84%|████████▍ | 169/200 [11:38<02:18,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58755, Requested 2176. Please try again in 931ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58755, Requested 2176. Please try again in 931ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 108 / 170  (63.5):  85%|████████▌ | 170/200 [11:40<01:47,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58852, Requested 2179. Please try again in 1.031s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58852, Requested 2179. Please try again in 1.031s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59068, Requested 3472. Please try again in 2.54s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59068, Requested 3472. Please try again in 2.54s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57500, Requested 3472. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57500, Requested 3472. Please try again in 972ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56907, Requested 3438. Please try again in 345ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56907, Requested 3438. Please try again in 345ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56630, Requested 3472. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56630, Requested 3472. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58745, Requested 3472. Please try again in 2.217s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58745, Requested 3472. Please try again in 2.217s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 108 / 172  (62.8):  86%|████████▌ | 172/200 [11:50<02:01,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57571, Requested 3472. Please try again in 1.043s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 13.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57571, Requested 3472. Please try again in 1.043s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 13.8 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57729, Requested 3349. Please try again in 1.078s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 301.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57729, Requested 3349. Please try again in 1.078s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 301.0 seconds after 12 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 175  (62.9):  88%|████████▊ | 175/200 [12:04<01:51,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59041, Requested 2214. Please try again in 1.255s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59041, Requested 2214. Please try again in 1.255s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 176  (63.1):  88%|████████▊ | 176/200 [12:06<01:31,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58911, Requested 2163. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58911, Requested 2163. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58352, Requested 2163. Please try again in 515ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58352, Requested 2163. Please try again in 515ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59083, Requested 3167. Please try again in 2.25s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59083, Requested 3167. Please try again in 2.25s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58531, Requested 3167. Please try again in 1.698s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58531, Requested 3167. Please try again in 1.698s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58077, Requested 3167. Please try again in 1.244s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58077, Requested 3167. Please try again in 1.244s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 177  (62.7):  88%|████████▊ | 177/200 [12:13<01:46,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58916, Requested 2151. Please try again in 1.067s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58916, Requested 2151. Please try again in 1.067s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 178  (62.9):  89%|████████▉ | 178/200 [12:15<01:25,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59928, Requested 421. Please try again in 349ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59928, Requested 421. Please try again in 349ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57891, Requested 2179. Please try again in 70ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57891, Requested 2179. Please try again in 70ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57846, Requested 3252. Please try again in 1.098s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57846, Requested 3252. Please try again in 1.098s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57562, Requested 3252. Please try again in 814ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57562, Requested 3252. Please try again in 814ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57031, Requested 3252. Please try again in 283ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57031, Requested 3252. Please try again in 283ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56958, Requested 3463. Please try again in 421ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56958, Requested 3463. Please try again in 421ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 179  (62.6):  90%|████████▉ | 179/200 [12:21<01:33,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58282, Requested 3252. Please try again in 1.534s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58282, Requested 3252. Please try again in 1.534s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56519, Requested 3511. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56519, Requested 3511. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59326, Requested 3252. Please try again in 2.578s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59326, Requested 3252. Please try again in 2.578s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 180  (62.2):  90%|█████████ | 180/200 [12:26<01:35,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57488, Requested 3252. Please try again in 740ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 29.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57488, Requested 3252. Please try again in 740ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 29.6 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 116 / 187  (62.0):  94%|█████████▎| 187/200 [12:58<00:47,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56656, Requested 3355. Please try again in 11ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 296.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 56656, Requested 3355. Please try again in 11ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 296.3 seconds after 11 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 188  (62.2):  94%|█████████▍| 188/200 [13:02<00:45,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57329, Requested 2996. Please try again in 325ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57329, Requested 2996. Please try again in 325ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 189  (61.9):  94%|█████████▍| 189/200 [13:04<00:35,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57934, Requested 2202. Please try again in 136ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57934, Requested 2202. Please try again in 136ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58687, Requested 2232. Please try again in 919ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58687, Requested 2232. Please try again in 919ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58402, Requested 2232. Please try again in 634ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58402, Requested 2232. Please try again in 634ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58278, Requested 3341. Please try again in 1.619s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58278, Requested 3341. Please try again in 1.619s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58060, Requested 3341. Please try again in 1.401s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58060, Requested 3341. Please try again in 1.401s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59030, Requested 3341. Please try again in 2.371s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59030, Requested 3341. Please try again in 2.371s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 190  (62.1):  95%|█████████▌| 190/200 [13:10<00:43,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58797, Requested 3079. Please try again in 1.876s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58797, Requested 3079. Please try again in 1.876s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 191  (61.8):  96%|█████████▌| 191/200 [13:14<00:37,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58065, Requested 3079. Please try again in 1.144s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58065, Requested 3079. Please try again in 1.144s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57809, Requested 3079. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57809, Requested 3079. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 193  (61.7):  96%|█████████▋| 193/200 [13:21<00:25,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58721, Requested 2210. Please try again in 931ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58721, Requested 2210. Please try again in 931ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57912, Requested 3285. Please try again in 1.197s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57912, Requested 3285. Please try again in 1.197s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57120, Requested 3285. Please try again in 405ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57120, Requested 3285. Please try again in 405ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 194  (61.3):  97%|█████████▋| 194/200 [13:27<00:25,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57939, Requested 3285. Please try again in 1.224s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57939, Requested 3285. Please try again in 1.224s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58665, Requested 3285. Please try again in 1.95s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58665, Requested 3285. Please try again in 1.95s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57737, Requested 3285. Please try again in 1.022s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 9.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57737, Requested 3285. Please try again in 1.022s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 9.2 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 122.0 / 200  (61.0): 100%|██████████| 200/200 [17:59<00:00,  5.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "Average Metric: 122.0 / 200  (61.0%)\n",
      "Score: 61.0 for set: [5, 5, 5, 5]\n",
      "Scores so far: [60.0, 60.0, 59.0, 62.0, 61.0]\n",
      "Best score: 62.0\n",
      "Average of max per entry across top 1 scores: 0.62\n",
      "Average of max per entry across top 2 scores: 0.785\n",
      "Average of max per entry across top 3 scores: 0.91\n",
      "Average of max per entry across top 5 scores: 0.965\n",
      "Average of max per entry across top 8 scores: 0.965\n",
      "Average of max per entry across top 9999 scores: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:01<05:42,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 25  (76.0):  12%|█▎        | 25/200 [00:22<01:32,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59918, Requested 360. Please try again in 278ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59918, Requested 360. Please try again in 278ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59838, Requested 362. Please try again in 200ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59838, Requested 362. Please try again in 200ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59316, Requested 1944. Please try again in 1.26s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59316, Requested 1944. Please try again in 1.26s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59054, Requested 1302. Please try again in 356ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59054, Requested 1302. Please try again in 356ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58911, Requested 1332. Please try again in 243ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58911, Requested 1332. Please try again in 243ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58347, Requested 1944. Please try again in 291ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58347, Requested 1944. Please try again in 291ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59146, Requested 1957. Please try again in 1.103s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59146, Requested 1957. Please try again in 1.103s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59053, Requested 1335. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59053, Requested 1335. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58915, Requested 1944. Please try again in 859ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58915, Requested 1944. Please try again in 859ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58865, Requested 1302. Please try again in 167ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58865, Requested 1302. Please try again in 167ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58752, Requested 1335. Please try again in 87ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58752, Requested 1335. Please try again in 87ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58545, Requested 1957. Please try again in 502ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58545, Requested 1957. Please try again in 502ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59281, Requested 1335. Please try again in 616ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59281, Requested 1335. Please try again in 616ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59258, Requested 1293. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59258, Requested 1293. Please try again in 551ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58839, Requested 1293. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58839, Requested 1293. Please try again in 132ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58297, Requested 2096. Please try again in 393ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58297, Requested 2096. Please try again in 393ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59707, Requested 1335. Please try again in 1.042s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59707, Requested 1335. Please try again in 1.042s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59545, Requested 1957. Please try again in 1.502s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59545, Requested 1957. Please try again in 1.502s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59494, Requested 1293. Please try again in 787ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59494, Requested 1293. Please try again in 787ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59234, Requested 1944. Please try again in 1.178s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59234, Requested 1944. Please try again in 1.178s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59090, Requested 2096. Please try again in 1.186s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59090, Requested 2096. Please try again in 1.186s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 26  (76.9):  13%|█▎        | 26/200 [00:27<04:55,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58662, Requested 1957. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58662, Requested 1957. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58582, Requested 2096. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58582, Requested 2096. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58508, Requested 2096. Please try again in 604ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58508, Requested 2096. Please try again in 604ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59148, Requested 1293. Please try again in 441ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59148, Requested 1293. Please try again in 441ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58638, Requested 2026. Please try again in 664ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58638, Requested 2026. Please try again in 664ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 27  (74.1):  14%|█▎        | 27/200 [00:31<06:56,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57995, Requested 2026. Please try again in 21ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57995, Requested 2026. Please try again in 21ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58597, Requested 2026. Please try again in 623ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58597, Requested 2026. Please try again in 623ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58447, Requested 2096. Please try again in 543ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58447, Requested 2096. Please try again in 543ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.1 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 28  (71.4):  14%|█▍        | 28/200 [00:34<07:08,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58135, Requested 1957. Please try again in 92ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58135, Requested 1957. Please try again in 92ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58748, Requested 1293. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58748, Requested 1293. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59734, Requested 2353. Please try again in 2.087s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59734, Requested 2353. Please try again in 2.087s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58982, Requested 2353. Please try again in 1.335s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58982, Requested 2353. Please try again in 1.335s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 29  (69.0):  14%|█▍        | 29/200 [00:37<07:35,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58480, Requested 1957. Please try again in 437ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 26.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58480, Requested 1957. Please try again in 437ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 26.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59674, Requested 363. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59674, Requested 363. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59098, Requested 1976. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59098, Requested 1976. Please try again in 1.074s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58292, Requested 2353. Please try again in 645ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58292, Requested 2353. Please try again in 645ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59795, Requested 1877. Please try again in 1.672s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59795, Requested 1877. Please try again in 1.672s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59143, Requested 1877. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59143, Requested 1877. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 30  (70.0):  15%|█▌        | 30/200 [00:40<07:55,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59320, Requested 1877. Please try again in 1.197s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59320, Requested 1877. Please try again in 1.197s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59458, Requested 2096. Please try again in 1.554s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 25.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59458, Requested 2096. Please try again in 1.554s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 25.4 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58871, Requested 1877. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58871, Requested 1877. Please try again in 748ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57899, Requested 2353. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57899, Requested 2353. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.2 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59133, Requested 1360. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59133, Requested 1360. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 31  (67.7):  16%|█▌        | 31/200 [00:43<08:02,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59670, Requested 1371. Please try again in 1.041s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59670, Requested 1371. Please try again in 1.041s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59352, Requested 2141. Please try again in 1.493s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59352, Requested 2141. Please try again in 1.493s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59338, Requested 1371. Please try again in 709ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59338, Requested 1371. Please try again in 709ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58883, Requested 2141. Please try again in 1.024s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58883, Requested 2141. Please try again in 1.024s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 32  (65.6):  16%|█▌        | 32/200 [00:47<08:18,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58706, Requested 2141. Please try again in 847ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58706, Requested 2141. Please try again in 847ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59547, Requested 1877. Please try again in 1.424s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59547, Requested 1877. Please try again in 1.424s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58758, Requested 1980. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58758, Requested 1980. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58557, Requested 1980. Please try again in 537ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58557, Requested 1980. Please try again in 537ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58474, Requested 1980. Please try again in 454ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58474, Requested 1980. Please try again in 454ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22 / 33  (66.7):  16%|█▋        | 33/200 [00:51<09:33,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59336, Requested 2141. Please try again in 1.477s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59336, Requested 2141. Please try again in 1.477s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 34  (67.6):  17%|█▋        | 34/200 [00:53<07:49,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59118, Requested 1779. Please try again in 897ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59118, Requested 1779. Please try again in 897ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59424, Requested 1969. Please try again in 1.393s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59424, Requested 1969. Please try again in 1.393s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59119, Requested 1969. Please try again in 1.088s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59119, Requested 1969. Please try again in 1.088s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58874, Requested 1969. Please try again in 843ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58874, Requested 1969. Please try again in 843ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 35  (68.6):  18%|█▊        | 35/200 [00:57<08:50,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58910, Requested 1969. Please try again in 879ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58910, Requested 1969. Please try again in 879ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58843, Requested 2141. Please try again in 984ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58843, Requested 2141. Please try again in 984ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 36  (66.7):  18%|█▊        | 36/200 [00:58<07:13,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.4 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59447, Requested 1979. Please try again in 1.426s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59447, Requested 1979. Please try again in 1.426s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58883, Requested 1979. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58883, Requested 1979. Please try again in 862ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58542, Requested 2141. Please try again in 683ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 14.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58542, Requested 2141. Please try again in 683ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 14.8 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 37  (67.6):  18%|█▊        | 37/200 [01:03<08:54,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59643, Requested 1969. Please try again in 1.612s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59643, Requested 1969. Please try again in 1.612s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59112, Requested 1957. Please try again in 1.069s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 49.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59112, Requested 1957. Please try again in 1.069s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 49.9 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 38  (68.4):  19%|█▉        | 38/200 [01:05<07:39,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59153, Requested 1969. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 20.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59153, Requested 1969. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 20.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59067, Requested 2096. Please try again in 1.163s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 44.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59067, Requested 2096. Please try again in 1.163s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 44.6 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59028, Requested 1829. Please try again in 857ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59028, Requested 1829. Please try again in 857ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58999, Requested 2243. Please try again in 1.242s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58999, Requested 2243. Please try again in 1.242s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 39  (69.2):  20%|█▉        | 39/200 [01:09<08:49,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58064, Requested 2243. Please try again in 307ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58064, Requested 2243. Please try again in 307ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 40  (70.0):  20%|██        | 40/200 [01:12<08:33,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59762, Requested 361. Please try again in 123ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59762, Requested 361. Please try again in 123ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 41  (70.7):  20%|██        | 41/200 [01:13<06:38,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58932, Requested 1359. Please try again in 291ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58932, Requested 1359. Please try again in 291ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59858, Requested 1359. Please try again in 1.217s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59858, Requested 1359. Please try again in 1.217s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 42  (71.4):  21%|██        | 42/200 [01:17<07:38,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59205, Requested 2141. Please try again in 1.346s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 50.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59205, Requested 2141. Please try again in 1.346s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 50.1 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58974, Requested 1973. Please try again in 947ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58974, Requested 1973. Please try again in 947ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59805, Requested 2178. Please try again in 1.983s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59805, Requested 2178. Please try again in 1.983s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58632, Requested 2178. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58632, Requested 2178. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32 / 44  (72.7):  22%|██▏       | 44/200 [01:23<07:29,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59120, Requested 1316. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59120, Requested 1316. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59556, Requested 1969. Please try again in 1.525s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 44.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59556, Requested 1969. Please try again in 1.525s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 44.6 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 33 / 45  (73.3):  22%|██▎       | 45/200 [01:27<08:01,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59285, Requested 1328. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59285, Requested 1328. Please try again in 613ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 46  (73.9):  23%|██▎       | 46/200 [01:29<07:30,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59303, Requested 1330. Please try again in 633ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59303, Requested 1330. Please try again in 633ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58385, Requested 2111. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58385, Requested 2111. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58090, Requested 2111. Please try again in 201ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58090, Requested 2111. Please try again in 201ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 48  (72.9):  24%|██▍       | 48/200 [01:37<07:54,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58139, Requested 2290. Please try again in 429ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58139, Requested 2290. Please try again in 429ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36 / 50  (72.0):  25%|██▌       | 50/200 [01:42<07:03,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58806, Requested 1355. Please try again in 161ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58806, Requested 1355. Please try again in 161ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 51  (72.5):  26%|██▌       | 51/200 [01:44<06:35,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58932, Requested 2262. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58932, Requested 2262. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58705, Requested 2262. Please try again in 967ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58705, Requested 2262. Please try again in 967ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58751, Requested 2262. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58751, Requested 2262. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 52  (73.1):  26%|██▌       | 52/200 [01:49<07:52,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59208, Requested 2096. Please try again in 1.304s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 93.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59208, Requested 2096. Please try again in 1.304s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 93.1 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 53  (71.7):  26%|██▋       | 53/200 [01:52<07:39,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58361, Requested 1954. Please try again in 315ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58361, Requested 1954. Please try again in 315ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58982, Requested 1358. Please try again in 340ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58982, Requested 1358. Please try again in 340ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 54  (70.4):  27%|██▋       | 54/200 [01:54<06:49,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59478, Requested 1957. Please try again in 1.435s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 115.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59478, Requested 1957. Please try again in 1.435s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 115.0 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59118, Requested 1315. Please try again in 433ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59118, Requested 1315. Please try again in 433ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 55  (70.9):  28%|██▊       | 55/200 [01:57<07:08,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58416, Requested 2087. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58416, Requested 2087. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58657, Requested 1982. Please try again in 639ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58657, Requested 1982. Please try again in 639ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58049, Requested 1982. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58049, Requested 1982. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 42 / 58  (72.4):  29%|██▉       | 58/200 [02:06<06:42,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58266, Requested 2108. Please try again in 374ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58266, Requested 2108. Please try again in 374ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59629, Requested 1351. Please try again in 979ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59629, Requested 1351. Please try again in 979ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59319, Requested 2108. Please try again in 1.427s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59319, Requested 2108. Please try again in 1.427s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59108, Requested 1351. Please try again in 459ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59108, Requested 1351. Please try again in 459ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 59  (72.9):  30%|██▉       | 59/200 [02:10<07:06,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58677, Requested 2108. Please try again in 785ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58677, Requested 2108. Please try again in 785ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58545, Requested 2119. Please try again in 664ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58545, Requested 2119. Please try again in 664ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58179, Requested 2119. Please try again in 298ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58179, Requested 2119. Please try again in 298ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59156, Requested 2119. Please try again in 1.275s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59156, Requested 2119. Please try again in 1.275s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59044, Requested 1379. Please try again in 423ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59044, Requested 1379. Please try again in 423ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 60  (73.3):  30%|███       | 60/200 [02:12<06:42,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58185, Requested 2119. Please try again in 304ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58185, Requested 2119. Please try again in 304ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59323, Requested 2108. Please try again in 1.431s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59323, Requested 2108. Please try again in 1.431s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58742, Requested 1976. Please try again in 718ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58742, Requested 1976. Please try again in 718ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59255, Requested 1903. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59255, Requested 1903. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 61  (73.8):  30%|███       | 61/200 [02:16<07:31,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58237, Requested 1903. Please try again in 140ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58237, Requested 1903. Please try again in 140ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58019, Requested 2119. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 9.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58019, Requested 2119. Please try again in 138ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 9.3 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58542, Requested 2108. Please try again in 650ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58542, Requested 2108. Please try again in 650ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.7 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 46 / 62  (74.2):  31%|███       | 62/200 [02:18<06:41,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58718, Requested 1368. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58718, Requested 1368. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 63  (74.6):  32%|███▏      | 63/200 [02:21<06:34,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58627, Requested 2339. Please try again in 966ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58627, Requested 2339. Please try again in 966ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57807, Requested 2339. Please try again in 146ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57807, Requested 2339. Please try again in 146ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57996, Requested 2108. Please try again in 104ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 12.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57996, Requested 2108. Please try again in 104ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 12.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59549, Requested 2339. Please try again in 1.887s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59549, Requested 2339. Please try again in 1.887s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 65  (75.4):  32%|███▎      | 65/200 [02:27<06:13,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58217, Requested 2339. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58217, Requested 2339. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58561, Requested 2339. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 15.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58561, Requested 2339. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 15.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58245, Requested 1914. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58245, Requested 1914. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58117, Requested 2095. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58117, Requested 2095. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59569, Requested 2095. Please try again in 1.664s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59569, Requested 2095. Please try again in 1.664s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 66  (74.2):  33%|███▎      | 66/200 [02:32<07:10,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58074, Requested 2095. Please try again in 169ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58074, Requested 2095. Please try again in 169ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 68  (72.1):  34%|███▍      | 68/200 [02:37<06:19,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59922, Requested 1334. Please try again in 1.256s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59922, Requested 1334. Please try again in 1.256s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59154, Requested 1334. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59154, Requested 1334. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50 / 69  (72.5):  34%|███▍      | 69/200 [02:40<05:59,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58306, Requested 2118. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58306, Requested 2118. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59123, Requested 2118. Please try again in 1.241s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59123, Requested 2118. Please try again in 1.241s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58912, Requested 1936. Please try again in 848ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58912, Requested 1936. Please try again in 848ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58280, Requested 1936. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58280, Requested 1936. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58156, Requested 2118. Please try again in 274ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58156, Requested 2118. Please try again in 274ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59345, Requested 2315. Please try again in 1.66s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59345, Requested 2315. Please try again in 1.66s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59132, Requested 1936. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59132, Requested 1936. Please try again in 1.068s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58661, Requested 2315. Please try again in 975ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58661, Requested 2315. Please try again in 975ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58235, Requested 2315. Please try again in 550ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58235, Requested 2315. Please try again in 550ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57987, Requested 2315. Please try again in 302ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57987, Requested 2315. Please try again in 302ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59263, Requested 2339. Please try again in 1.602s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 25.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59263, Requested 2339. Please try again in 1.602s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50 / 70  (71.4):  35%|███▌      | 70/200 [02:46<07:49,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 25.6 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 71  (71.8):  36%|███▌      | 71/200 [02:46<05:53,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59069, Requested 2315. Please try again in 1.384s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 10.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59069, Requested 2315. Please try again in 1.384s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 10.4 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58617, Requested 1771. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58617, Requested 1771. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59140, Requested 1771. Please try again in 911ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59140, Requested 1771. Please try again in 911ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52 / 73  (71.2):  36%|███▋      | 73/200 [02:52<05:53,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58551, Requested 2170. Please try again in 721ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58551, Requested 2170. Please try again in 721ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59812, Requested 1991. Please try again in 1.803s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59812, Requested 1991. Please try again in 1.803s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59076, Requested 1991. Please try again in 1.067s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59076, Requested 1991. Please try again in 1.067s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 53 / 74  (71.6):  37%|███▋      | 74/200 [02:56<06:21,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58444, Requested 1991. Please try again in 435ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58444, Requested 1991. Please try again in 435ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58927, Requested 2290. Please try again in 1.217s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58927, Requested 2290. Please try again in 1.217s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58575, Requested 2290. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58575, Requested 2290. Please try again in 865ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 76  (71.1):  38%|███▊      | 76/200 [03:02<05:51,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58235, Requested 1991. Please try again in 226ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58235, Requested 1991. Please try again in 226ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58778, Requested 1991. Please try again in 769ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58778, Requested 1991. Please try again in 769ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.1 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58668, Requested 1352. Please try again in 20ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58668, Requested 1352. Please try again in 20ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58556, Requested 2284. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58556, Requested 2284. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59521, Requested 1971. Please try again in 1.492s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59521, Requested 1971. Please try again in 1.492s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58632, Requested 1971. Please try again in 603ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58632, Requested 1971. Please try again in 603ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 77  (70.1):  38%|███▊      | 77/200 [03:06<07:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58744, Requested 1971. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58744, Requested 1971. Please try again in 715ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 55 / 78  (70.5):  39%|███▉      | 78/200 [03:08<05:46,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58934, Requested 1971. Please try again in 905ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58934, Requested 1971. Please try again in 905ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59759, Requested 1314. Please try again in 1.073s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59759, Requested 1314. Please try again in 1.073s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 79  (70.9):  40%|███▉      | 79/200 [03:11<05:37,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59438, Requested 2339. Please try again in 1.777s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 34.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59438, Requested 2339. Please try again in 1.777s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 34.8 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59329, Requested 2133. Please try again in 1.462s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59329, Requested 2133. Please try again in 1.462s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58916, Requested 1971. Please try again in 887ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58916, Requested 1971. Please try again in 887ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.8 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58890, Requested 2133. Please try again in 1.023s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58890, Requested 2133. Please try again in 1.023s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58127, Requested 2133. Please try again in 260ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58127, Requested 2133. Please try again in 260ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 57 / 80  (71.2):  40%|████      | 80/200 [03:15<06:40,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 57 / 81  (70.4):  40%|████      | 81/200 [03:17<05:53,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59588, Requested 1351. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59588, Requested 1351. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58756, Requested 1351. Please try again in 107ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58756, Requested 1351. Please try again in 107ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 58 / 82  (70.7):  41%|████      | 82/200 [03:20<05:54,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58563, Requested 1971. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 17.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58563, Requested 1971. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 17.2 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58384, Requested 1954. Please try again in 338ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58384, Requested 1954. Please try again in 338ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59144, Requested 1939. Please try again in 1.083s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59144, Requested 1939. Please try again in 1.083s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58785, Requested 1939. Please try again in 724ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58785, Requested 1939. Please try again in 724ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58136, Requested 2096. Please try again in 232ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58136, Requested 2096. Please try again in 232ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 59 / 83  (71.1):  42%|████▏     | 83/200 [03:25<06:42,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.5 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 59 / 84  (70.2):  42%|████▏     | 84/200 [03:26<05:32,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58171, Requested 2149. Please try again in 320ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58171, Requested 2149. Please try again in 320ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 59 / 85  (69.4):  42%|████▎     | 85/200 [03:31<06:13,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58161, Requested 2096. Please try again in 257ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 120.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58161, Requested 2096. Please try again in 257ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 120.7 seconds after 10 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58279, Requested 1908. Please try again in 187ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58279, Requested 1908. Please try again in 187ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 60 / 86  (69.8):  43%|████▎     | 86/200 [03:32<05:12,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59658, Requested 367. Please try again in 25ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59658, Requested 367. Please try again in 25ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58426, Requested 1950. Please try again in 376ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58426, Requested 1950. Please try again in 376ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 87  (70.1):  44%|████▎     | 87/200 [03:35<05:05,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58781, Requested 1337. Please try again in 117ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58781, Requested 1337. Please try again in 117ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58699, Requested 2240. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58699, Requested 2240. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59768, Requested 2240. Please try again in 2.008s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59768, Requested 2240. Please try again in 2.008s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59108, Requested 1971. Please try again in 1.079s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 4.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59108, Requested 1971. Please try again in 1.079s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 4.9 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 61 / 88  (69.3):  44%|████▍     | 88/200 [03:40<06:15,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58996, Requested 1338. Please try again in 334ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58996, Requested 1338. Please try again in 334ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62 / 89  (69.7):  44%|████▍     | 89/200 [03:42<05:41,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59769, Requested 1326. Please try again in 1.095s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59769, Requested 1326. Please try again in 1.095s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59188, Requested 1971. Please try again in 1.159s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 72.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59188, Requested 1971. Please try again in 1.159s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 72.6 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59119, Requested 1326. Please try again in 445ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59119, Requested 1326. Please try again in 445ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58821, Requested 1326. Please try again in 147ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58821, Requested 1326. Please try again in 147ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 90  (70.0):  45%|████▌     | 90/200 [03:45<05:25,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58170, Requested 2100. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58170, Requested 2100. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57931, Requested 2339. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 104.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57931, Requested 2339. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 104.3 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59531, Requested 1382. Please try again in 913ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59531, Requested 1382. Please try again in 913ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59311, Requested 1382. Please try again in 693ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59311, Requested 1382. Please try again in 693ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 91  (70.3):  46%|████▌     | 91/200 [03:48<05:21,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58154, Requested 1957. Please try again in 111ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 199.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58154, Requested 1957. Please try again in 111ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 199.0 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58100, Requested 2138. Please try again in 238ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58100, Requested 2138. Please try again in 238ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59778, Requested 2138. Please try again in 1.916s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59778, Requested 2138. Please try again in 1.916s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 92  (69.6):  46%|████▌     | 92/200 [03:52<05:59,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57892, Requested 2138. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57892, Requested 2138. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88 / 126  (69.8):  62%|██████▎   | 125/200 [05:38<01:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59156, Requested 1336. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59156, Requested 1336. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 127  (70.1):  64%|██████▎   | 127/200 [05:39<01:23,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58835, Requested 1325. Please try again in 160ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58835, Requested 1325. Please try again in 160ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58866, Requested 1336. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58866, Requested 1336. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58951, Requested 1929. Please try again in 880ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58951, Requested 1929. Please try again in 880ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58782, Requested 1946. Please try again in 728ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58782, Requested 1946. Please try again in 728ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59158, Requested 1929. Please try again in 1.087s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59158, Requested 1929. Please try again in 1.087s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59061, Requested 1946. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59061, Requested 1946. Please try again in 1.007s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58973, Requested 1351. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58973, Requested 1351. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59564, Requested 1775. Please try again in 1.339s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59564, Requested 1775. Please try again in 1.339s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59541, Requested 1351. Please try again in 892ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59541, Requested 1351. Please try again in 892ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59246, Requested 1929. Please try again in 1.175s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59246, Requested 1929. Please try again in 1.175s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58836, Requested 1775. Please try again in 611ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58836, Requested 1775. Please try again in 611ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 128  (69.5):  64%|██████▍   | 128/200 [05:43<02:16,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58142, Requested 1946. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58142, Requested 1946. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58333, Requested 1775. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58333, Requested 1775. Please try again in 108ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58642, Requested 1946. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58642, Requested 1946. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.4 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58588, Requested 1929. Please try again in 517ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58588, Requested 1929. Please try again in 517ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58555, Requested 2142. Please try again in 697ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58555, Requested 2142. Please try again in 697ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59861, Requested 2142. Please try again in 2.003s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59861, Requested 2142. Please try again in 2.003s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59116, Requested 2142. Please try again in 1.258s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59116, Requested 2142. Please try again in 1.258s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89 / 129  (69.0):  64%|██████▍   | 129/200 [05:47<02:48,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58385, Requested 1950. Please try again in 335ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58385, Requested 1950. Please try again in 335ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58491, Requested 1950. Please try again in 441ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58491, Requested 1950. Please try again in 441ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59527, Requested 1950. Please try again in 1.477s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59527, Requested 1950. Please try again in 1.477s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 130  (69.2):  65%|██████▌   | 130/200 [05:49<02:36,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59407, Requested 2142. Please try again in 1.549s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59407, Requested 2142. Please try again in 1.549s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58765, Requested 2288. Please try again in 1.053s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58765, Requested 2288. Please try again in 1.053s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58334, Requested 2288. Please try again in 622ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58334, Requested 2288. Please try again in 622ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58112, Requested 2142. Please try again in 254ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 9.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58112, Requested 2142. Please try again in 254ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 9.0 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59092, Requested 2288. Please try again in 1.38s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59092, Requested 2288. Please try again in 1.38s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58892, Requested 2049. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58892, Requested 2049. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58839, Requested 2288. Please try again in 1.127s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58839, Requested 2288. Please try again in 1.127s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58599, Requested 1946. Please try again in 545ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58599, Requested 1946. Please try again in 545ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 131  (68.7):  66%|██████▌   | 131/200 [05:53<03:15,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58724, Requested 1329. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58724, Requested 1329. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 132  (68.2):  66%|██████▌   | 132/200 [05:55<02:58,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59806, Requested 1946. Please try again in 1.752s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 18.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59806, Requested 1946. Please try again in 1.752s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 18.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59811, Requested 1316. Please try again in 1.127s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59811, Requested 1316. Please try again in 1.127s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59010, Requested 1316. Please try again in 326ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59010, Requested 1316. Please try again in 326ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 133  (67.7):  66%|██████▋   | 133/200 [05:58<02:53,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58202, Requested 2288. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 11.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58202, Requested 2288. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 11.5 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59813, Requested 2083. Please try again in 1.896s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59813, Requested 2083. Please try again in 1.896s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59722, Requested 1902. Please try again in 1.624s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59722, Requested 1902. Please try again in 1.624s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59379, Requested 2083. Please try again in 1.462s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59379, Requested 2083. Please try again in 1.462s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59288, Requested 1902. Please try again in 1.19s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59288, Requested 1902. Please try again in 1.19s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 90 / 134  (67.2):  67%|██████▋   | 134/200 [06:02<03:28,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58247, Requested 2083. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58247, Requested 2083. Please try again in 330ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59715, Requested 1902. Please try again in 1.617s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59715, Requested 1902. Please try again in 1.617s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 135  (67.4):  68%|██████▊   | 135/200 [06:04<03:05,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58649, Requested 1928. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58649, Requested 1928. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58305, Requested 1928. Please try again in 233ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58305, Requested 1928. Please try again in 233ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58899, Requested 1895. Please try again in 794ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58899, Requested 1895. Please try again in 794ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58671, Requested 1895. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58671, Requested 1895. Please try again in 566ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 136  (66.9):  68%|██████▊   | 136/200 [06:08<03:25,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58259, Requested 1928. Please try again in 187ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58259, Requested 1928. Please try again in 187ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 137  (66.4):  68%|██████▊   | 137/200 [06:10<02:58,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58323, Requested 1928. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58323, Requested 1928. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58537, Requested 1928. Please try again in 465ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 9.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58537, Requested 1928. Please try again in 465ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 9.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59043, Requested 2288. Please try again in 1.331s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 21.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59043, Requested 2288. Please try again in 1.331s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 21.5 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57903, Requested 2321. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57903, Requested 2321. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59079, Requested 1754. Please try again in 833ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59079, Requested 1754. Please try again in 833ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91 / 138  (65.9):  69%|██████▉   | 138/200 [06:15<03:35,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59463, Requested 1946. Please try again in 1.409s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 54.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59463, Requested 1946. Please try again in 1.409s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 54.4 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 92 / 139  (66.2):  70%|██████▉   | 139/200 [06:17<02:52,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58378, Requested 1937. Please try again in 315ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58378, Requested 1937. Please try again in 315ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58456, Requested 2142. Please try again in 598ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58456, Requested 2142. Please try again in 598ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 140  (66.4):  70%|███████   | 140/200 [06:21<03:12,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58128, Requested 2142. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58128, Requested 2142. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 141  (66.7):  70%|███████   | 141/200 [06:22<02:39,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58435, Requested 2142. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58435, Requested 2142. Please try again in 577ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59055, Requested 2142. Please try again in 1.197s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59055, Requested 2142. Please try again in 1.197s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59002, Requested 2109. Please try again in 1.111s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59002, Requested 2109. Please try again in 1.111s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58635, Requested 2109. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58635, Requested 2109. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59476, Requested 2198. Please try again in 1.674s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59476, Requested 2198. Please try again in 1.674s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59131, Requested 2198. Please try again in 1.329s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59131, Requested 2198. Please try again in 1.329s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95 / 142  (66.9):  71%|███████   | 142/200 [06:27<03:14,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57982, Requested 2198. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57982, Requested 2198. Please try again in 180ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57976, Requested 2142. Please try again in 117ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 8.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57976, Requested 2142. Please try again in 117ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 8.2 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 144  (67.4):  72%|███████▏  | 144/200 [06:32<02:27,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58759, Requested 2288. Please try again in 1.047s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 19.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58759, Requested 2288. Please try again in 1.047s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 19.1 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58502, Requested 2209. Please try again in 711ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58502, Requested 2209. Please try again in 711ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97 / 146  (66.4):  73%|███████▎  | 146/200 [06:38<02:24,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58831, Requested 2142. Please try again in 973ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58831, Requested 2142. Please try again in 973ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59822, Requested 1332. Please try again in 1.154s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59822, Requested 1332. Please try again in 1.154s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59682, Requested 2142. Please try again in 1.824s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 39.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59682, Requested 2142. Please try again in 1.824s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 39.8 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58829, Requested 1332. Please try again in 161ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58829, Requested 1332. Please try again in 161ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 98 / 147  (66.7):  74%|███████▎  | 147/200 [06:41<02:29,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59033, Requested 1945. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59033, Requested 1945. Please try again in 977ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58143, Requested 1945. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58143, Requested 1945. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58070, Requested 2181. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58070, Requested 2181. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59261, Requested 1945. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59261, Requested 1945. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58869, Requested 1945. Please try again in 814ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58869, Requested 1945. Please try again in 814ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100 / 151  (66.2):  76%|███████▌  | 151/200 [06:55<02:27,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58274, Requested 2094. Please try again in 368ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58274, Requested 2094. Please try again in 368ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 101 / 152  (66.4):  76%|███████▌  | 152/200 [06:57<02:07,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59506, Requested 1944. Please try again in 1.45s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59506, Requested 1944. Please try again in 1.45s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59090, Requested 1944. Please try again in 1.034s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59090, Requested 1944. Please try again in 1.034s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58716, Requested 1763. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58716, Requested 1763. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58107, Requested 1944. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58107, Requested 1944. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58996, Requested 1944. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58996, Requested 1944. Please try again in 939ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.5 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58509, Requested 1762. Please try again in 271ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58509, Requested 1762. Please try again in 271ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103 / 154  (66.9):  77%|███████▋  | 154/200 [07:03<02:06,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58486, Requested 1944. Please try again in 430ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 11.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58486, Requested 1944. Please try again in 430ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 11.9 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58868, Requested 2087. Please try again in 955ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58868, Requested 2087. Please try again in 955ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104 / 155  (67.1):  78%|███████▊  | 155/200 [07:07<02:23,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59852, Requested 364. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59852, Requested 364. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105 / 156  (67.3):  78%|███████▊  | 156/200 [07:08<01:51,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58812, Requested 1957. Please try again in 769ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 467.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58812, Requested 1957. Please try again in 769ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 467.0 seconds after 10 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58439, Requested 1946. Please try again in 385ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 126.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58439, Requested 1946. Please try again in 385ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 126.2 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59045, Requested 2304. Please try again in 1.349s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59045, Requested 2304. Please try again in 1.349s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58630, Requested 2304. Please try again in 934ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58630, Requested 2304. Please try again in 934ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 107 / 159  (67.3):  80%|███████▉  | 159/200 [07:17<01:46,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59134, Requested 1328. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59134, Requested 1328. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58491, Requested 1801. Please try again in 292ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58491, Requested 1801. Please try again in 292ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58751, Requested 1801. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58751, Requested 1801. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58650, Requested 2142. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 74.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58650, Requested 2142. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 74.0 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58301, Requested 2083. Please try again in 384ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58301, Requested 2083. Please try again in 384ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59344, Requested 2083. Please try again in 1.427s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59344, Requested 2083. Please try again in 1.427s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58874, Requested 1801. Please try again in 675ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58874, Requested 1801. Please try again in 675ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 108 / 161  (67.1):  80%|████████  | 161/200 [07:24<01:51,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58994, Requested 1801. Please try again in 795ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 7.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58994, Requested 1801. Please try again in 795ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59007, Requested 2148. Please try again in 1.155s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59007, Requested 2148. Please try again in 1.155s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58249, Requested 2148. Please try again in 397ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58249, Requested 2148. Please try again in 397ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58773, Requested 2148. Please try again in 921ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58773, Requested 2148. Please try again in 921ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 110 / 163  (67.5):  82%|████████▏ | 163/200 [07:32<01:58,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58164, Requested 2154. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58164, Requested 2154. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58944, Requested 1801. Please try again in 745ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58944, Requested 1801. Please try again in 745ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 111 / 164  (67.7):  82%|████████▏ | 164/200 [07:34<01:41,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59438, Requested 1801. Please try again in 1.239s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 5.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59438, Requested 1801. Please try again in 1.239s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 5.4 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58679, Requested 2122. Please try again in 801ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58679, Requested 2122. Please try again in 801ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59506, Requested 2122. Please try again in 1.628s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59506, Requested 2122. Please try again in 1.628s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 112 / 165  (67.9):  82%|████████▎ | 165/200 [07:38<01:49,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58321, Requested 2122. Please try again in 443ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58321, Requested 2122. Please try again in 443ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58453, Requested 2122. Please try again in 575ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58453, Requested 2122. Please try again in 575ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58270, Requested 2142. Please try again in 412ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58270, Requested 2142. Please try again in 412ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 114 / 167  (68.3):  84%|████████▎ | 167/200 [07:43<01:28,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58413, Requested 2122. Please try again in 535ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 10.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58413, Requested 2122. Please try again in 535ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 10.6 seconds after 5 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59597, Requested 1384. Please try again in 981ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59597, Requested 1384. Please try again in 981ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59007, Requested 1384. Please try again in 391ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59007, Requested 1384. Please try again in 391ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 168  (68.5):  84%|████████▍ | 168/200 [07:46<01:31,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58093, Requested 2170. Please try again in 263ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58093, Requested 2170. Please try again in 263ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58973, Requested 2170. Please try again in 1.143s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 1.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58973, Requested 2170. Please try again in 1.143s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 117 / 170  (68.8):  85%|████████▌ | 170/200 [07:53<01:27,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58153, Requested 2122. Please try again in 275ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 6.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58153, Requested 2122. Please try again in 275ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 6.0 seconds after 6 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58014, Requested 2280. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58014, Requested 2280. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59300, Requested 1331. Please try again in 631ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59300, Requested 1331. Please try again in 631ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 171  (69.0):  86%|████████▌ | 171/200 [07:55<01:20,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59054, Requested 1944. Please try again in 998ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.5s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59054, Requested 1944. Please try again in 998ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58354, Requested 1944. Please try again in 298ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58354, Requested 1944. Please try again in 298ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59067, Requested 1944. Please try again in 1.011s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59067, Requested 1944. Please try again in 1.011s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58111, Requested 2122. Please try again in 233ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 52.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58111, Requested 2122. Please try again in 233ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 172  (68.6):  86%|████████▌ | 172/200 [08:00<01:34,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 52.6 seconds after 7 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57962, Requested 2100. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57962, Requested 2100. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 118 / 173  (68.2):  86%|████████▋ | 173/200 [08:03<01:29,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 119 / 174  (68.4):  87%|████████▋ | 174/200 [08:05<01:12,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58865, Requested 2104. Please try again in 969ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58865, Requested 2104. Please try again in 969ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58379, Requested 2104. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58379, Requested 2104. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58033, Requested 2104. Please try again in 137ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 3.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58033, Requested 2104. Please try again in 137ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 120 / 176  (68.2):  88%|████████▊ | 176/200 [08:11<01:12,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58113, Requested 1925. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58113, Requested 1925. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 121 / 178  (68.0):  89%|████████▉ | 178/200 [08:17<01:01,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58420, Requested 2059. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58420, Requested 2059. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58826, Requested 2274. Please try again in 1.1s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.2s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58826, Requested 2274. Please try again in 1.1s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58444, Requested 2274. Please try again in 718ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58444, Requested 2274. Please try again in 718ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57901, Requested 2274. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57901, Requested 2274. Please try again in 175ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 122 / 182  (67.0):  91%|█████████ | 182/200 [08:30<00:49,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58120, Requested 2250. Please try again in 370ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58120, Requested 2250. Please try again in 370ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58968, Requested 1943. Please try again in 911ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58968, Requested 1943. Please try again in 911ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58399, Requested 1943. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58399, Requested 1943. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 123 / 183  (67.2):  92%|█████████▏| 183/200 [08:34<00:54,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59417, Requested 2142. Please try again in 1.559s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 59.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 59417, Requested 2142. Please try again in 1.559s. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 59.6 seconds after 9 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 124 / 185  (67.0):  92%|█████████▎| 185/200 [08:39<00:43,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58008, Requested 2242. Please try again in 250ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.7s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58008, Requested 2242. Please try again in 250ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 126 / 187  (67.4):  94%|█████████▎| 187/200 [08:45<00:36,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58528, Requested 2114. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.6s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58528, Requested 2114. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58478, Requested 1803. Please try again in 281ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.8s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58478, Requested 1803. Please try again in 281ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 127 / 188  (67.6):  94%|█████████▍| 188/200 [08:49<00:39,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 127 / 189  (67.2):  94%|█████████▍| 189/200 [08:51<00:31,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57901, Requested 2122. Please try again in 23ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 126.0s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57901, Requested 2122. Please try again in 23ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 126.0 seconds after 8 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57880, Requested 2159. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.3s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57880, Requested 2159. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58595, Requested 2348. Please try again in 943ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58595, Requested 2348. Please try again in 943ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58349, Requested 2348. Please try again in 697ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.1s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58349, Requested 2348. Please try again in 697ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 127 / 190  (66.8):  95%|█████████▌| 190/200 [08:55<00:32,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57670, Requested 2348. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 2.4s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 57670, Requested 2348. Please try again in 18ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n",
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58354, Requested 1898. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58354, Requested 1898. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 129 / 192  (67.2):  96%|█████████▌| 192/200 [09:01<00:22,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58190, Requested 1914. Please try again in 104ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58190, Requested 1914. Please try again in 104ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 130 / 194  (67.0):  97%|█████████▋| 194/200 [09:07<00:17,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_info - INFO - error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58594, Requested 1937. Please try again in 531ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "_log_backoff - INFO - Backing off request(...) for 0.9s (openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-VjuFA3ZuxujWIoGp9RVspxfT on tokens per min (TPM): Limit 60000, Used 58594, Requested 1937. Please try again in 531ms. Visit https://platform.openai.com/account/rate-limits to learn more.)\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x7fc1ed3c7f40> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 200  (67.0): 100%|██████████| 200/200 [14:58<00:00,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 134 / 200  (67.0%)\n",
      "Score: 67.0 for set: [5, 5, 5, 5]\n",
      "New best score: 67.0 for seed 2\n",
      "Scores so far: [60.0, 60.0, 59.0, 62.0, 61.0, 67.0]\n",
      "Best score: 67.0\n",
      "Average of max per entry across top 1 scores: 0.67\n",
      "Average of max per entry across top 2 scores: 0.845\n",
      "Average of max per entry across top 3 scores: 0.895\n",
      "Average of max per entry across top 5 scores: 0.97\n",
      "Average of max per entry across top 8 scores: 0.98\n",
      "Average of max per entry across top 9999 scores: 0.98\n",
      "6 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
    "#   1) Textual description of your system.\n",
    "#   2) The code for your original system.\n",
    "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
    "\n",
    "# START COMMENT: Enter your system description in this cell.\n",
    "\n",
    "# 1) Textual description\n",
    "# I implemented a more flexible version of the system defined so far with the following characteristics:\n",
    "#     - I used gpt-3.5-turbo from OpenAI with default parameters where I implemented a retry mechanism since I experienced frequent read timeouts with the OpenAI API.\n",
    "#     - Multi-hop with two hops as default and generation of retrieval query with extended context for each consecutive hop. \n",
    "#     - Ability to individually define each involved module (search query, summary, answer).\n",
    "#     - Ability to select summarizing the whole context and/or summarizing each individual passage in the context.\n",
    "#           Summarizing the whole context did not work well for me in my initial experiments so did not include it in the grid search.\n",
    "#           I thought summarizing each individual passage in the context might help generating a good answer but that also proved inferior to delivering the whole context (see scores of grid search given below).\n",
    "#     - I used BootstrapFewShotWithRandomSearch for optimization. \n",
    "#     - I stayed with the ColBERTv2 retriever since doing a basic grid search over the already configurable options took quite some time.\n",
    "#     - I adapted the signature for summarization slightly based on some initial experiments. \n",
    "#     - Intially I wanted to do a full grid search over all available options and also including ReAct as a module. In my initial experiments, using ReAct had the downsides of a) taking longer and b) sometimes getting on a completely irrelevant track.\n",
    "#       Therefore, I did not include ReAct in the grid search and narrowed down the options to \n",
    "        # a) Check, if summarizing individual passages in the context helps generating the answer.\n",
    "        # b) Using Predict or ChainOfThought for generating the answer.\n",
    "        # c) Always using Predict for summarization.\n",
    "        # d) Alway using ChainOfThought for generating the queries for retrieving the context.\n",
    "# Please find below the scores of my grid search using the dev evaluator already given in the notebook and 30 samples for optimization where the pattern for the identifier is as follows:\n",
    "    # <summarize_retrieved_passages_per_hop>_<module_gen_answer>_<module_summarize>_<module_gen_query>. \n",
    "# The first element is a boolean indicating whether to summarize individual passages in the context and the remainder are the modules used for generating the answer, summarization, and generating the query for each hop.\n",
    "# I used answer_passage_match as metric to not be too strict in the evaluation.\n",
    "\n",
    "# True_<class 'dspy.predict.predict.Predict'>_<class 'dspy.predict.predict.Predict'>_<class 'dspy.predict.chain_of_thought.ChainOfThought'>: 50.5\n",
    "# True_<class 'dspy.predict.chain_of_thought.ChainOfThought'>_<class 'dspy.predict.predict.Predict'>_<class 'dspy.predict.chain_of_thought.ChainOfThought'>: 49.5\n",
    "# False_<class 'dspy.predict.predict.Predict'>_<class 'dspy.predict.predict.Predict'>_<class 'dspy.predict.chain_of_thought.ChainOfThought'>: 57.0\n",
    "# False_<class 'dspy.predict.chain_of_thought.ChainOfThought'>_<class 'dspy.predict.predict.Predict'>_<class 'dspy.predict.chain_of_thought.ChainOfThought'>: 57.5\n",
    "\n",
    "# Therefore, I used ChainOfThought for generating the queries as well as the answer and did not use summarization in the end. \n",
    "# I used this set of parameters to do another optimization with BootstrapFewShotWithRandomSearch using 200 samples insteach of 30 as in the grid search. \n",
    "\n",
    "# 2) Code\n",
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "from random import sample \n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "from dspy.evaluate import answer_passage_match\n",
    "from dsp.utils import deduplicate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch\n",
    "\n",
    "def flexible_optimize(model, config_optimizer=None, optimizer=BootstrapFewShotWithRandomSearch, metric=answer_passage_match, trainset=squad_train, devset=squad_dev, n_samples=30):\n",
    "    if config_optimizer is None:\n",
    "        config_optimizer = {}\n",
    "    return optimizer(metric=metric, **config_optimizer).compile(model, trainset=sample(trainset, n_samples))\n",
    "\n",
    "log_format = '%(funcName)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(format=log_format, level=logging.INFO, stream=sys.stdout, force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a short and concise search query that will help answer a complex question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()\n",
    "    \n",
    "class SummarizeSignature(dspy.Signature):\n",
    "    # __doc__ = \"\"\"Reply with a concise summary of the key facts and statements from the following text.\"\"\"\n",
    "    __doc__ = \"\"\"Summarize the following text in one paragraph focusing on key facts and statements.\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    summary = dspy.OutputField()\n",
    "    \n",
    "class ContextQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "    \n",
    "class FlexibleRAG(dspy.Module):\n",
    "    def __init__(self, \n",
    "                 passages_per_hop=3, \n",
    "                 max_hops=2,\n",
    "                 summarize_retrieved_passages_per_hop=True,\n",
    "                 summarize_whole_context=False,\n",
    "                 module_gen_answer=dspy.Predict, \n",
    "                 signature_gen_answer=ContextQASignature,\n",
    "                 module_summarize=dspy.Predict,\n",
    "                 signature_summarize=SummarizeSignature,\n",
    "                 module_gen_query=dspy.Predict,\n",
    "                 signature_gen_query=GenerateSearchQuery,\n",
    "                 loglevel=logging.INFO):\n",
    "        super().__init__()    \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(loglevel)    \n",
    "        self.max_hops = max_hops\n",
    "        self.summarize_retrieved_passages_per_hop = summarize_retrieved_passages_per_hop\n",
    "        self.summarize_whole_context = summarize_whole_context\n",
    "        self.summarize = None\n",
    "        self.generate_query = None\n",
    "        if module_summarize is not None and signature_summarize is not None:\n",
    "            self.summarize = module_summarize(signature_summarize)\n",
    "        if module_gen_query is not None and signature_gen_query is not None:\n",
    "            self.generate_query = [module_gen_query(signature_gen_query) for _ in range(max_hops)]            \n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = module_gen_answer(signature_gen_answer)\n",
    "    \n",
    "    def get_context(self, question):\n",
    "        if self.generate_query is not None:\n",
    "            context = []\n",
    "            for hop in range(self.max_hops):\n",
    "                self.logger.debug(f'{hop=}')\n",
    "                query = self.generate_query[hop](context=context, question=question).query            \n",
    "                self.logger.debug(f'{query=}')\n",
    "                passages = self.retrieve(query).passages\n",
    "                if self.summarize_retrieved_passages_per_hop and self.summarize is not None:\n",
    "                    # Summarize every passage to ease generation of answer and reduce context size\n",
    "                    passages = [self.get_summary(passage) for passage in passages]                   \n",
    "                context = deduplicate(context + passages)\n",
    "                self.logger.debug(f'{context=}')\n",
    "        else:\n",
    "            context = self.retrieve(question).passages\n",
    "        return context\n",
    "            \n",
    "    def get_summary(self, context):\n",
    "        if self.summarize is not None:\n",
    "            summary = self.summarize(context=context).summary\n",
    "            self.logger.debug(f'{context=}')\n",
    "            self.logger.debug(f'{summary=}')\n",
    "            return summary\n",
    "        else:\n",
    "            return context        \n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.get_context(question=question)  \n",
    "        if self.summarize_whole_context and self.summarize is not None:  \n",
    "            summary = self.get_summary(context=context)\n",
    "        else:\n",
    "            summary = context\n",
    "        prediction = self.generate_answer(context=summary, question=question)        \n",
    "        self.logger.debug(f'{question=}')\n",
    "        self.logger.debug(f'{context=}')\n",
    "        self.logger.debug(f'{summary=}')\n",
    "        self.logger.debug(f'{prediction.answer=}')\n",
    "        return dspy.Prediction(context=summary, answer=prediction.answer)    \n",
    "    \n",
    "model_selection = False\n",
    "config_optimizer = dict(max_bootstrapped_demos=5, max_labeled_demos=5, max_rounds=1, num_candidate_programs=3)\n",
    "\n",
    "if model_selection:\n",
    "    n_retries = 50    \n",
    "    # options_module_gen_answer=[dspy.Predict, dspy.ReAct, dspy.ChainOfThought]\n",
    "    # options_module_summarize=[dspy.Predict, dspy.ReAct, dspy.ChainOfThought]\n",
    "    # options_module_gen_query=[dspy.Predict, dspy.ReAct, dspy.ChainOfThought]\n",
    "    options_summarize_retrieved_passages_per_hop=[True, False]\n",
    "    options_module_gen_answer=[dspy.Predict, dspy.ChainOfThought]\n",
    "    options_module_summarize=[dspy.Predict]\n",
    "    options_module_gen_query=[dspy.ChainOfThought]\n",
    "    grid = itertools.product(options_summarize_retrieved_passages_per_hop, options_module_gen_answer, options_module_summarize, options_module_gen_query)\n",
    "    \n",
    "    if os.path.exists('models.pkl'):\n",
    "        with open('models.pkl', 'rb') as file:\n",
    "            models = pickle.load(file)\n",
    "    else:\n",
    "        models = {}\n",
    "    if os.path.exists('results.pkl'):\n",
    "        with open('results.pkl', 'rb') as file:\n",
    "            results = pickle.load(file)\n",
    "    else:\n",
    "        results = {}\n",
    "    def grid_search(grid, models, results):\n",
    "        try:    \n",
    "            for summarize_retrieved_passages_per_hop, module_gen_answer, module_summarize, module_gen_query in tqdm(grid):\n",
    "                logger.info(f'Optimizing model with settings\\n{summarize_retrieved_passages_per_hop=}, {module_gen_answer=}, {module_summarize=}, {module_gen_query=}')\n",
    "                id = f'{str(summarize_retrieved_passages_per_hop)}_{str(module_gen_answer)}_{str(module_summarize)}_{str(module_gen_query)}'\n",
    "                if id not in models:\n",
    "                    models[id] = flexible_optimize(model=FlexibleRAG(summarize_retrieved_passages_per_hop=summarize_retrieved_passages_per_hop, \n",
    "                                                                    module_gen_answer=module_gen_answer,\n",
    "                                                                    module_gen_query=module_gen_query,\n",
    "                                                                    module_summarize=module_summarize,\n",
    "                                                                    passages_per_hop=3),\n",
    "                                                optimizer=BootstrapFewShotWithRandomSearch,\n",
    "                                                config_optimizer=config_optimizer,\n",
    "                                                n_samples=30,\n",
    "                                                metric=answer_passage_match,)\n",
    "                    \n",
    "                    with open('models.pkl', 'wb') as file:\n",
    "                        pickle.dump(models, file)\n",
    "                logger.info('Evaluating model')\n",
    "                if id not in results:\n",
    "                    results[id] = dev_evaluater(models[id], metric=answer_passage_match, display=True, display_table=10, return_outputs=True)\n",
    "                    logger.info(f'Current results\\n{results}')\n",
    "                    with open('results.pkl', 'wb') as file:\n",
    "                        pickle.dump(results, file)\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "            n_retries = n_retries - 1\n",
    "            logger.info(f'Retrying... {n_retries} remaining')\n",
    "            if n_retries >=0:\n",
    "                grid_search(grid, models, results)\n",
    "            else:\n",
    "                raise e\n",
    "    grid_search(grid, models, results)\n",
    "        \n",
    "best_set_of_parameters = {\n",
    "    'summarize_retrieved_passages_per_hop': False, \n",
    "    'module_gen_answer': dspy.ChainOfThought, \n",
    "    'module_summarize': dspy.Predict, \n",
    "    'module_gen_query': dspy.ChainOfThought\n",
    "}\n",
    "resulting_model = flexible_optimize(model=FlexibleRAG(summarize_retrieved_passages_per_hop=best_set_of_parameters['summarize_retrieved_passages_per_hop'], \n",
    "                                                                    module_gen_answer=best_set_of_parameters['module_gen_answer'],\n",
    "                                                                    module_gen_query=best_set_of_parameters['module_gen_query'],\n",
    "                                                                    module_summarize=best_set_of_parameters['module_summarize'],\n",
    "                                                                    passages_per_hop=3),\n",
    "                                                optimizer=BootstrapFewShotWithRandomSearch,\n",
    "                                                config_optimizer=config_optimizer,\n",
    "                                                n_samples=200,\n",
    "                                                metric=answer_passage_match,)\n",
    "with open('resulting_model.pkl', 'wb') as file:\n",
    "    pickle.dump(resulting_model, file)\n",
    "        \n",
    "    \n",
    "# STOP COMMENT: Please do not remove this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b39c60-7494-46a6-b450-42b7e9fe3aad",
   "metadata": {},
   "source": [
    "## Question 5: Bakeoff entry [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff871c1-cc38-4e2f-af38-45b3619e8329",
   "metadata": {},
   "source": [
    "For the bake-off, you simply need to be able to run your system on the file \n",
    "\n",
    "```data/openqa/cs224u-openqa-test-unlabeled.txt```\n",
    "\n",
    "The following code should download it for you if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ca87f81-556b-46eb-904f-a3df70fdacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")):\n",
    "    os.makedirs(os.path.join('data', 'openqa'), exist_ok=True)\n",
    "    wget.download('https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt', out='data/openqa/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0024b-9af7-4e3b-930e-1e7603d4d85c",
   "metadata": {},
   "source": [
    "If the above fails, you can just download https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt and place it in `data/openqa`.\n",
    "\n",
    "This file contains only questions. The starter code below will help you structure this. It writes a file \"cs224u-openqa-bakeoff-entry.json\" to the current directory. That file should be uploaded as-is. Please do not change its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "403b0000-5bc0-4657-91e4-5a6e87f2f899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tqdm\n",
    "\n",
    "def create_bakeoff_submission(model):\n",
    "    \"\"\"\"\n",
    "    The argument `model` is a `dspy.Module`. The return value of its\n",
    "    `forward` method must have an `answer` attribute.\n",
    "    \"\"\"\n",
    "\n",
    "    filename = os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")\n",
    "\n",
    "    # This should become a mapping from questions (str) to response\n",
    "    # dicts from your system.\n",
    "    gens = {}\n",
    "\n",
    "    with open(filename) as f:\n",
    "        questions = f.read().splitlines()\n",
    "\n",
    "    # Here we loop over the questions, run the system `model`, and\n",
    "    # store its `answer` value as the prediction:\n",
    "    for question in tqdm.tqdm(questions):\n",
    "        gens[question] = model(question=question).answer\n",
    "\n",
    "    # Quick tests we advise you to run:\n",
    "    # 1. Make sure `gens` is a dict with the questions as the keys:\n",
    "    assert all(question in gens for q in questions)\n",
    "    # 2. Make sure the values are str:\n",
    "    assert all(isinstance(d, str) for d in gens.values())\n",
    "\n",
    "    # And finally the output file:\n",
    "    with open(\"cs224u-openqa-bakeoff-entry.json\", \"wt\") as f:\n",
    "        json.dump(gens, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f32a8-547e-4a2c-8283-44adf69657ed",
   "metadata": {},
   "source": [
    "Here's what it looks like to evaluate our first program, `basic_qa_model`, on the bakeoff data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce20e9ae-bb82-4dff-896f-aad7f150177d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create_bakeoff_submission(basic_qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "629d6b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [26:27<00:00,  3.97s/it]\n"
     ]
    }
   ],
   "source": [
    "create_bakeoff_submission(resulting_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ddac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
